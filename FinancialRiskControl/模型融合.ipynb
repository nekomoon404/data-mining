{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "知识补充：\n",
    "* 学习模型融合的几种方式：\n",
    "1. 模型结果层面的融合技术：回归任务中加权融合；分类任务中的voting\n",
    "2. 从样本集的角度考虑把多个弱模型集成起来：Boosting; Bagging （一般用于集成学习）；Boosting和Bagging的区别\n",
    "3. 构建多层模型：stacking；blending\n",
    "\n",
    "* 学习使用heamy模块进行模型在线融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.feature_selection import SelectKBest\n",
    "#from sklearn.feature_selection import chi2\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce_mem_usage 函数通过调整数据类型，帮助我们减少数据在内存中占用的空间\n",
    "def reduce_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() \n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() \n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 723200128.00 MB\n",
      "Memory usage after optimization is: 128800128.00 MB\n",
      "Decreased by 82.2%\n",
      "Memory usage of dataframe is 179200128.00 MB\n",
      "Memory usage after optimization is: 32000128.00 MB\n",
      "Decreased by 82.1%\n"
     ]
    }
   ],
   "source": [
    "#训练数据/测试数据准备\n",
    "\n",
    "data_train = pd.read_csv('data_train_for_model-09-27.csv')\n",
    "data_train = reduce_mem_usage(data_train)\n",
    "\n",
    "data_test = pd.read_csv('data_test_for_model-09-27.csv')\n",
    "data_test = reduce_mem_usage(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f for f in data_train.columns if f not in ['id','isDefault']]\n",
    "\n",
    "X_train = data_train[features]\n",
    "X_test = data_test[features]\n",
    "\n",
    "y_train = data_train['isDefault']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立模型\n",
    "\n",
    "def xgb_model(X_train, y_train, X_test, y_test=None):\n",
    "    X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "    train_matrix = xgb.DMatrix(X_train_split , label=y_train_split)\n",
    "    valid_matrix = xgb.DMatrix(X_val , label=y_val)\n",
    "    test_matrix = xgb.DMatrix(X_test)\n",
    "\n",
    "    params = {\n",
    "        'booster': 'gbtree',\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'tree_method': 'exact',\n",
    "        'seed': 2020,\n",
    "        'n_jobs': -1,\n",
    "        \"silent\": True,\n",
    "        \n",
    "        'gamma': 1,\n",
    "        'min_child_weight': 1.5,\n",
    "        'max_depth': 5,\n",
    "        'lambda': 10,\n",
    "        'subsample': 0.7,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'colsample_bylevel': 0.7,\n",
    "        'eta': 0.04,\n",
    "        \n",
    "        'scale_pos_weight': 1,\n",
    "    }\n",
    "    watchlist = [(train_matrix, 'train'),(valid_matrix, 'eval')]\n",
    "    \n",
    "    model = xgb.train(params, train_matrix, num_boost_round=50000, evals=watchlist, verbose_eval=200, early_stopping_rounds=200)\n",
    "    \"\"\"计算在验证集上的得分\"\"\"\n",
    "    val_pred  = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_val, val_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print('调参后xgboost单模型在验证集上的AUC：{}'.format(roc_auc))\n",
    "    \"\"\"对测试集进行预测\"\"\"\n",
    "    test_pred = model.predict(test_matrix, ntree_limit=model.best_ntree_limit)\n",
    "    \n",
    "    return test_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model(X_train, y_train, X_test, y_test=None):\n",
    "    X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "    train_matrix = lgb.Dataset(X_train_split, label=y_train_split)\n",
    "    valid_matrix = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    # 调参后的最优参数\n",
    "    params = {'objective' : 'binary',\n",
    "         'metric' : 'auc',\n",
    "         'max_depth' : 5,\n",
    "         'num_leaves' : 31,\n",
    "          \n",
    "         'learning_rate' : 0.01,    #0.005\n",
    "          \n",
    "         'feature_fraction' : 0.8,\n",
    "         'bagging_fraction' : 0.8,\n",
    "         'bagging_freq': 2, \n",
    "          \n",
    "         'min_child_samples' : 23,     \n",
    "         'min_child_weight': 0.001,    \n",
    "         \n",
    "         'reg_alpha': 0.5,      \n",
    "         'reg_lambda' : 0.3,     \n",
    "         'min_split_gain' : 0.0,\n",
    "         'n_jobs' : -1\n",
    "         }\n",
    "    \n",
    "    model = lgb.train(params, train_matrix, 50000, valid_sets=[train_matrix, valid_matrix], verbose_eval=500, early_stopping_rounds=500)\n",
    "    \"\"\"计算在验证集上的得分\"\"\"\n",
    "    val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_val, val_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print('调参后lightgbm单模型在验证集上的AUC：{}'.format(roc_auc))\n",
    "    \"\"\"对测试集进行预测\"\"\"\n",
    "    test_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    \n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于模型层面的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heamy.dataset import Dataset\n",
    "from heamy.estimator import Classifier\n",
    "\n",
    "model_dataset = Dataset(X_train=X_train, y_train=y_train, X_test=X_test)\n",
    "model_xgb = Classifier(dataset=model_dataset, estimator=xgb_model, name='xgb', use_cache=False)\n",
    "model_lgb = Classifier(dataset=model_dataset, estimator=lgb_model, name='lgb', use_cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用stacking方法进行模型融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<heamy.pipeline.ModelsPipeline at 0x23da5a698c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from heamy.pipeline import ModelsPipeline\n",
    "\n",
    "pipeline = ModelsPipeline(model_xgb, model_lgb)\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建第一层新特征，其中k默认是5， 表示5折交叉验证，full_test=True，对全部训练集进行训练得到基学习器，然后用基学习器对测试集预测得到新特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.696657\teval-auc:0.696166\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.733379\teval-auc:0.728716\n",
      "[400]\ttrain-auc:0.74129\teval-auc:0.7324\n",
      "[600]\ttrain-auc:0.747017\teval-auc:0.73413\n",
      "[800]\ttrain-auc:0.751733\teval-auc:0.735151\n",
      "[1000]\ttrain-auc:0.75597\teval-auc:0.735989\n",
      "[1200]\ttrain-auc:0.759709\teval-auc:0.736376\n",
      "[1400]\ttrain-auc:0.763337\teval-auc:0.736583\n",
      "[1600]\ttrain-auc:0.766822\teval-auc:0.736894\n",
      "[1800]\ttrain-auc:0.770133\teval-auc:0.736917\n",
      "[2000]\ttrain-auc:0.773363\teval-auc:0.736932\n",
      "[2200]\ttrain-auc:0.776598\teval-auc:0.736961\n",
      "Stopping. Best iteration:\n",
      "[2106]\ttrain-auc:0.775138\teval-auc:0.737024\n",
      "\n",
      "调参后xgboost单模型在验证集上的AUC：0.7370245110462428\n",
      "[0]\ttrain-auc:0.696861\teval-auc:0.698827\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.733417\teval-auc:0.732033\n",
      "[400]\ttrain-auc:0.741514\teval-auc:0.736025\n",
      "[600]\ttrain-auc:0.74723\teval-auc:0.737857\n",
      "[800]\ttrain-auc:0.752176\teval-auc:0.739016\n",
      "[1000]\ttrain-auc:0.756322\teval-auc:0.739605\n",
      "[1200]\ttrain-auc:0.759968\teval-auc:0.740083\n",
      "[1400]\ttrain-auc:0.763738\teval-auc:0.740333\n",
      "[1600]\ttrain-auc:0.767194\teval-auc:0.740608\n",
      "[1800]\ttrain-auc:0.770534\teval-auc:0.740811\n",
      "[2000]\ttrain-auc:0.773845\teval-auc:0.740869\n",
      "[2200]\ttrain-auc:0.777013\teval-auc:0.740871\n",
      "[2400]\ttrain-auc:0.78011\teval-auc:0.740904\n",
      "Stopping. Best iteration:\n",
      "[2250]\ttrain-auc:0.777819\teval-auc:0.740953\n",
      "\n",
      "调参后xgboost单模型在验证集上的AUC：0.740953325047689\n",
      "[0]\ttrain-auc:0.696728\teval-auc:0.698858\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.733418\teval-auc:0.729431\n",
      "[400]\ttrain-auc:0.741513\teval-auc:0.732759\n",
      "[600]\ttrain-auc:0.747274\teval-auc:0.734221\n",
      "[800]\ttrain-auc:0.75203\teval-auc:0.735103\n",
      "[1000]\ttrain-auc:0.756076\teval-auc:0.735548\n",
      "[1200]\ttrain-auc:0.759913\teval-auc:0.735948\n",
      "[1400]\ttrain-auc:0.763699\teval-auc:0.736286\n",
      "[1600]\ttrain-auc:0.76719\teval-auc:0.736498\n",
      "[1800]\ttrain-auc:0.770616\teval-auc:0.736562\n",
      "[2000]\ttrain-auc:0.773859\teval-auc:0.736537\n",
      "Stopping. Best iteration:\n",
      "[1806]\ttrain-auc:0.770705\teval-auc:0.73657\n",
      "\n",
      "调参后xgboost单模型在验证集上的AUC：0.7365696520839353\n",
      "[0]\ttrain-auc:0.69662\teval-auc:0.697597\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.733701\teval-auc:0.729431\n",
      "[400]\ttrain-auc:0.741366\teval-auc:0.732782\n",
      "[600]\ttrain-auc:0.747059\teval-auc:0.734377\n",
      "[800]\ttrain-auc:0.751863\teval-auc:0.73524\n",
      "[1000]\ttrain-auc:0.755982\teval-auc:0.735714\n",
      "[1200]\ttrain-auc:0.75983\teval-auc:0.736081\n",
      "[1400]\ttrain-auc:0.763477\teval-auc:0.736368\n",
      "[1600]\ttrain-auc:0.766934\teval-auc:0.736427\n",
      "Stopping. Best iteration:\n",
      "[1567]\ttrain-auc:0.766315\teval-auc:0.73647\n",
      "\n",
      "调参后xgboost单模型在验证集上的AUC：0.7364695087433702\n",
      "[0]\ttrain-auc:0.697499\teval-auc:0.693686\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.7345\teval-auc:0.725806\n",
      "[400]\ttrain-auc:0.742229\teval-auc:0.729702\n",
      "[600]\ttrain-auc:0.747846\teval-auc:0.731469\n",
      "[800]\ttrain-auc:0.752286\teval-auc:0.73241\n",
      "[1000]\ttrain-auc:0.75636\teval-auc:0.733108\n",
      "[1200]\ttrain-auc:0.760281\teval-auc:0.733537\n",
      "[1400]\ttrain-auc:0.763911\teval-auc:0.733759\n",
      "[1600]\ttrain-auc:0.767437\teval-auc:0.733989\n",
      "[1800]\ttrain-auc:0.770653\teval-auc:0.734055\n",
      "[2000]\ttrain-auc:0.773961\teval-auc:0.734129\n",
      "[2200]\ttrain-auc:0.777004\teval-auc:0.73408\n",
      "Stopping. Best iteration:\n",
      "[2029]\ttrain-auc:0.774386\teval-auc:0.734157\n",
      "\n",
      "调参后xgboost单模型在验证集上的AUC：0.7341565948427469\n",
      "[0]\ttrain-auc:0.697372\teval-auc:0.696061\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.732902\teval-auc:0.728723\n",
      "[400]\ttrain-auc:0.74013\teval-auc:0.732595\n",
      "[600]\ttrain-auc:0.745181\teval-auc:0.734545\n",
      "[800]\ttrain-auc:0.749276\teval-auc:0.735738\n",
      "[1000]\ttrain-auc:0.752909\teval-auc:0.736521\n",
      "[1200]\ttrain-auc:0.756324\teval-auc:0.737076\n",
      "[1400]\ttrain-auc:0.759443\teval-auc:0.7375\n",
      "[1600]\ttrain-auc:0.762372\teval-auc:0.73789\n",
      "[1800]\ttrain-auc:0.765295\teval-auc:0.738045\n",
      "[2000]\ttrain-auc:0.767985\teval-auc:0.738177\n",
      "[2200]\ttrain-auc:0.770662\teval-auc:0.738339\n",
      "[2400]\ttrain-auc:0.773215\teval-auc:0.738413\n",
      "[2600]\ttrain-auc:0.775722\teval-auc:0.738524\n",
      "Stopping. Best iteration:\n",
      "[2572]\ttrain-auc:0.775391\teval-auc:0.738544\n",
      "\n",
      "调参后xgboost单模型在验证集上的AUC：0.7385435702007002\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's auc: 0.730926\tvalid_1's auc: 0.722846\n",
      "[1000]\ttraining's auc: 0.738321\tvalid_1's auc: 0.727217\n",
      "[1500]\ttraining's auc: 0.743482\tvalid_1's auc: 0.729432\n",
      "[2000]\ttraining's auc: 0.7478\tvalid_1's auc: 0.730827\n",
      "[2500]\ttraining's auc: 0.751647\tvalid_1's auc: 0.73182\n",
      "[3000]\ttraining's auc: 0.754974\tvalid_1's auc: 0.732458\n",
      "[3500]\ttraining's auc: 0.758186\tvalid_1's auc: 0.73295\n",
      "[4000]\ttraining's auc: 0.761157\tvalid_1's auc: 0.73328\n",
      "[4500]\ttraining's auc: 0.763999\tvalid_1's auc: 0.733525\n",
      "[5000]\ttraining's auc: 0.766785\tvalid_1's auc: 0.733813\n",
      "[5500]\ttraining's auc: 0.769401\tvalid_1's auc: 0.733981\n",
      "[6000]\ttraining's auc: 0.771966\tvalid_1's auc: 0.734123\n",
      "[6500]\ttraining's auc: 0.774565\tvalid_1's auc: 0.734253\n",
      "[7000]\ttraining's auc: 0.777036\tvalid_1's auc: 0.734329\n",
      "[7500]\ttraining's auc: 0.779487\tvalid_1's auc: 0.734425\n",
      "[8000]\ttraining's auc: 0.781907\tvalid_1's auc: 0.734489\n",
      "[8500]\ttraining's auc: 0.784247\tvalid_1's auc: 0.734475\n",
      "Early stopping, best iteration is:\n",
      "[8143]\ttraining's auc: 0.782598\tvalid_1's auc: 0.734504\n",
      "调参后lightgbm单模型在验证集上的AUC：0.7345040668688224\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's auc: 0.73146\tvalid_1's auc: 0.726263\n",
      "[1000]\ttraining's auc: 0.739038\tvalid_1's auc: 0.730243\n",
      "[1500]\ttraining's auc: 0.74425\tvalid_1's auc: 0.732107\n",
      "[2000]\ttraining's auc: 0.748478\tvalid_1's auc: 0.733169\n",
      "[2500]\ttraining's auc: 0.752291\tvalid_1's auc: 0.733939\n",
      "[3000]\ttraining's auc: 0.755746\tvalid_1's auc: 0.734499\n",
      "[3500]\ttraining's auc: 0.758955\tvalid_1's auc: 0.734926\n",
      "[4000]\ttraining's auc: 0.762011\tvalid_1's auc: 0.735204\n",
      "[4500]\ttraining's auc: 0.764884\tvalid_1's auc: 0.735467\n",
      "[5000]\ttraining's auc: 0.767704\tvalid_1's auc: 0.735647\n",
      "[5500]\ttraining's auc: 0.770398\tvalid_1's auc: 0.735827\n",
      "[6000]\ttraining's auc: 0.772948\tvalid_1's auc: 0.735948\n",
      "[6500]\ttraining's auc: 0.775576\tvalid_1's auc: 0.736067\n",
      "[7000]\ttraining's auc: 0.778038\tvalid_1's auc: 0.736121\n",
      "[7500]\ttraining's auc: 0.780562\tvalid_1's auc: 0.736238\n",
      "[8000]\ttraining's auc: 0.782985\tvalid_1's auc: 0.736246\n",
      "[8500]\ttraining's auc: 0.785383\tvalid_1's auc: 0.736315\n",
      "[9000]\ttraining's auc: 0.787711\tvalid_1's auc: 0.736372\n",
      "Early stopping, best iteration is:\n",
      "[8892]\ttraining's auc: 0.787217\tvalid_1's auc: 0.736385\n",
      "调参后lightgbm单模型在验证集上的AUC：0.7363852803756853\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's auc: 0.729669\tvalid_1's auc: 0.728752\n",
      "[1000]\ttraining's auc: 0.737434\tvalid_1's auc: 0.732909\n",
      "[1500]\ttraining's auc: 0.742622\tvalid_1's auc: 0.734831\n",
      "[2000]\ttraining's auc: 0.746874\tvalid_1's auc: 0.735995\n",
      "[2500]\ttraining's auc: 0.750681\tvalid_1's auc: 0.73689\n",
      "[3000]\ttraining's auc: 0.754052\tvalid_1's auc: 0.737582\n",
      "[3500]\ttraining's auc: 0.757264\tvalid_1's auc: 0.738049\n",
      "[4000]\ttraining's auc: 0.760241\tvalid_1's auc: 0.738383\n",
      "[4500]\ttraining's auc: 0.76304\tvalid_1's auc: 0.738679\n",
      "[5000]\ttraining's auc: 0.765814\tvalid_1's auc: 0.738887\n",
      "[5500]\ttraining's auc: 0.768505\tvalid_1's auc: 0.739071\n",
      "[6000]\ttraining's auc: 0.771174\tvalid_1's auc: 0.739211\n",
      "[6500]\ttraining's auc: 0.773728\tvalid_1's auc: 0.73931\n",
      "[7000]\ttraining's auc: 0.776222\tvalid_1's auc: 0.73939\n",
      "[7500]\ttraining's auc: 0.77878\tvalid_1's auc: 0.739468\n",
      "[8000]\ttraining's auc: 0.781216\tvalid_1's auc: 0.739496\n",
      "[8500]\ttraining's auc: 0.783677\tvalid_1's auc: 0.739522\n",
      "Early stopping, best iteration is:\n",
      "[8373]\ttraining's auc: 0.78308\tvalid_1's auc: 0.739545\n",
      "调参后lightgbm单模型在验证集上的AUC：0.7395450135090206\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's auc: 0.730324\tvalid_1's auc: 0.726859\n",
      "[1000]\ttraining's auc: 0.737902\tvalid_1's auc: 0.731507\n",
      "[1500]\ttraining's auc: 0.743017\tvalid_1's auc: 0.733716\n",
      "[2000]\ttraining's auc: 0.747186\tvalid_1's auc: 0.735055\n",
      "[2500]\ttraining's auc: 0.750898\tvalid_1's auc: 0.73606\n",
      "[3000]\ttraining's auc: 0.754323\tvalid_1's auc: 0.736776\n",
      "[3500]\ttraining's auc: 0.757534\tvalid_1's auc: 0.737351\n",
      "[4000]\ttraining's auc: 0.760496\tvalid_1's auc: 0.737728\n",
      "[4500]\ttraining's auc: 0.763374\tvalid_1's auc: 0.738059\n",
      "[5000]\ttraining's auc: 0.766202\tvalid_1's auc: 0.738313\n",
      "[5500]\ttraining's auc: 0.768876\tvalid_1's auc: 0.738515\n",
      "[6000]\ttraining's auc: 0.771505\tvalid_1's auc: 0.738711\n",
      "[6500]\ttraining's auc: 0.774026\tvalid_1's auc: 0.738796\n",
      "[7000]\ttraining's auc: 0.776573\tvalid_1's auc: 0.738888\n",
      "[7500]\ttraining's auc: 0.779098\tvalid_1's auc: 0.738992\n",
      "[8000]\ttraining's auc: 0.781533\tvalid_1's auc: 0.739079\n",
      "[8500]\ttraining's auc: 0.78389\tvalid_1's auc: 0.739109\n",
      "[9000]\ttraining's auc: 0.786184\tvalid_1's auc: 0.739108\n",
      "Early stopping, best iteration is:\n",
      "[8682]\ttraining's auc: 0.784759\tvalid_1's auc: 0.73912\n",
      "调参后lightgbm单模型在验证集上的AUC：0.7391198153284538\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's auc: 0.730902\tvalid_1's auc: 0.72634\n",
      "[1000]\ttraining's auc: 0.738355\tvalid_1's auc: 0.73032\n",
      "[1500]\ttraining's auc: 0.743494\tvalid_1's auc: 0.732266\n",
      "[2000]\ttraining's auc: 0.747827\tvalid_1's auc: 0.733472\n",
      "[2500]\ttraining's auc: 0.751609\tvalid_1's auc: 0.734226\n",
      "[3000]\ttraining's auc: 0.75504\tvalid_1's auc: 0.734787\n",
      "[3500]\ttraining's auc: 0.758284\tvalid_1's auc: 0.735131\n",
      "[4000]\ttraining's auc: 0.761236\tvalid_1's auc: 0.735373\n",
      "[4500]\ttraining's auc: 0.764105\tvalid_1's auc: 0.735587\n",
      "[5000]\ttraining's auc: 0.766952\tvalid_1's auc: 0.735722\n",
      "[5500]\ttraining's auc: 0.769692\tvalid_1's auc: 0.735854\n",
      "[6000]\ttraining's auc: 0.772274\tvalid_1's auc: 0.735976\n",
      "[6500]\ttraining's auc: 0.774834\tvalid_1's auc: 0.736071\n",
      "[7000]\ttraining's auc: 0.777379\tvalid_1's auc: 0.736114\n",
      "[7500]\ttraining's auc: 0.779867\tvalid_1's auc: 0.736189\n",
      "[8000]\ttraining's auc: 0.78233\tvalid_1's auc: 0.736241\n",
      "[8500]\ttraining's auc: 0.784684\tvalid_1's auc: 0.736288\n",
      "[9000]\ttraining's auc: 0.786978\tvalid_1's auc: 0.736283\n",
      "Early stopping, best iteration is:\n",
      "[8871]\ttraining's auc: 0.786383\tvalid_1's auc: 0.736315\n",
      "调参后lightgbm单模型在验证集上的AUC：0.7363154163450041\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's auc: 0.729848\tvalid_1's auc: 0.726938\n",
      "[1000]\ttraining's auc: 0.736683\tvalid_1's auc: 0.73116\n",
      "[1500]\ttraining's auc: 0.741287\tvalid_1's auc: 0.733302\n",
      "[2000]\ttraining's auc: 0.745115\tvalid_1's auc: 0.734753\n",
      "[2500]\ttraining's auc: 0.748355\tvalid_1's auc: 0.735602\n",
      "[3000]\ttraining's auc: 0.751347\tvalid_1's auc: 0.736297\n",
      "[3500]\ttraining's auc: 0.754044\tvalid_1's auc: 0.736822\n",
      "[4000]\ttraining's auc: 0.756653\tvalid_1's auc: 0.737239\n",
      "[4500]\ttraining's auc: 0.759082\tvalid_1's auc: 0.737548\n",
      "[5000]\ttraining's auc: 0.76144\tvalid_1's auc: 0.737799\n",
      "[5500]\ttraining's auc: 0.763777\tvalid_1's auc: 0.738066\n",
      "[6000]\ttraining's auc: 0.766025\tvalid_1's auc: 0.738292\n",
      "[6500]\ttraining's auc: 0.76823\tvalid_1's auc: 0.738477\n",
      "[7000]\ttraining's auc: 0.770409\tvalid_1's auc: 0.738622\n",
      "[7500]\ttraining's auc: 0.772454\tvalid_1's auc: 0.738766\n",
      "[8000]\ttraining's auc: 0.774488\tvalid_1's auc: 0.738888\n",
      "[8500]\ttraining's auc: 0.776457\tvalid_1's auc: 0.738974\n",
      "[9000]\ttraining's auc: 0.778406\tvalid_1's auc: 0.739059\n",
      "[9500]\ttraining's auc: 0.780356\tvalid_1's auc: 0.739149\n",
      "[10000]\ttraining's auc: 0.782243\tvalid_1's auc: 0.739212\n",
      "[10500]\ttraining's auc: 0.784133\tvalid_1's auc: 0.739279\n",
      "[11000]\ttraining's auc: 0.785968\tvalid_1's auc: 0.739342\n",
      "[11500]\ttraining's auc: 0.787798\tvalid_1's auc: 0.73933\n",
      "Early stopping, best iteration is:\n",
      "[11000]\ttraining's auc: 0.785968\tvalid_1's auc: 0.739342\n",
      "调参后lightgbm单模型在验证集上的AUC：0.7393424227574721\n"
     ]
    }
   ],
   "source": [
    "stack_ds = pipeline.stack(k=5, seed=2020, full_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第二层使用逻辑回归进行stack\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "LR(solver='lbfgs')\n",
    "stacker = Classifier(dataset=stack_ds, estimator=LR, parameters={'solver': 'lbfgs'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08887541, 0.27427777, 0.70083222, ..., 0.11649688, 0.25233517,\n",
       "       0.07192994])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#测试集的预测结果\n",
    "test_pred = stacker.predict()\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['isDefault'] = test_pred\n",
    "data_test[['id','isDefault']].to_csv('test_sub-09-27-stack.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提交到线上，分数反而降了，emmmm。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用blending方法进行模型融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建第一层新特征，将训练集切分成8:2，其中80%用于训练基学习器，20%用于构建新特征\n",
    "blend_ds = pipeline.blend(proportion=0.2,seed=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09120743, 0.28107113, 0.67114587, ..., 0.11950613, 0.26956718,\n",
       "       0.068617  ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第二层使用逻辑回归进行blend\n",
    "blender = Classifier(dataset=blend_ds, estimator=LR, parameters={'solver': 'lbfgs'})\n",
    "# 测试集的预测结果\n",
    "test_pred_1 = blender.predict()\n",
    "test_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['isDefault'] = test_pred\n",
    "data_test[['id','isDefault']].to_csv('test_sub-09-27-blending.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sklearn]",
   "language": "python",
   "name": "conda-env-sklearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
