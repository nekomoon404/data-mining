{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task05 排序模型与模型融合\n",
    "\n",
    "### 1.排序模型\n",
    "\n",
    "在Task3中，我们通过召回操作进行了推荐问题规模的缩减，对于每个用户，选择出了N篇文章作为候选集；在Task4中，我们基于召回的候选集构建与用户历史相关的特征，以及用户本身的属性特征，文章本身的属性特征，以及用户与文章之间的特征。本节将使用机器学习模型对构造好的特征进行学习，然后对测试集进行预测，得到测试集中的每个候选集用户点击的概率，返回点击概率最大的topk个文章，作为最终的结果。\n",
    "\n",
    "排序阶段选择三个比较有代表性的排序模型，分别是：\n",
    "1. LGB的排序模型\n",
    "2. LGB的分类模型\n",
    "3. 深度学习的分类模型DIN\n",
    "\n",
    "得到排序模型输出的结果之后，选择了两种比较经典的模型集成的方法：\n",
    "1. 输出结果加权融合\n",
    "2. Staking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import gc, os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.读取排序特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data_raw/'\n",
    "save_path = './tmp_results/'\n",
    "offline = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里使用的构造好的特征是task04中保存好的，先试一下只使用itemcf的召回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click_article_id是浮点数，这里将其转换为int\n",
    "trn_user_item_feats_df = pd.read_csv(save_path+'trn_user_item_feats_df.csv')\n",
    "trn_user_item_feats_df['click_article_id'] = trn_user_item_feats_df['click_article_id'].astype(int)\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df = pd.read_csv(save_path+'val_user_item_feats_df.csv')\n",
    "    val_user_item_feats_df['click_article_id'] = val_user_item_feats_df['click_article_id'].astype(int)\n",
    "else:\n",
    "    val_user_item_feats_df = None\n",
    "\n",
    "tst_user_item_feats_df = pd.read_csv(save_path+'tst_user_item_feats_df.csv')\n",
    "tst_user_item_feats_df['click_article_id'] = tst_user_item_feats_df['click_article_id'].astype(int)\n",
    "\n",
    "#做特征时给测试集打了无效的标签，这里直接删掉\n",
    "del tst_user_item_feats_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.返回排序后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(recall_df, topk=5, model_name=None):\n",
    "    recall_df = recall_df.sort_values(by=['user_id', 'pred_score'])\n",
    "    recall_df['rank'] = recall_df.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    \n",
    "    #判断是不是每个用户都至少有5篇文章\n",
    "    tmp = recall_df.groupby('user_id').apply(lambda x:x['rank'].max())\n",
    "    assert tmp.min() >= topk\n",
    "    \n",
    "    del recall_df['pred_score']\n",
    "    submit = recall_df[recall_df['rank'] <= topk].set_index(['user_id', 'rank']).unstack(-1).reset_index()\n",
    "    \n",
    "    submit.columns = [int(col) if isinstance(col, int) else col for col in submit.columns.droplevel(0)]\n",
    "    # 按照提交格式定义列名\n",
    "    submit = submit.rename(columns={'': 'user_id', 1: 'article_1', 2: 'article_2', \n",
    "                                                  3: 'article_3', 4: 'article_4', 5: 'article_5'})\n",
    "    \n",
    "    save_name = save_path + model_name + '_' + datetime.today().strftime('%m-%d') + '.csv'\n",
    "    submit.to_csv(save_name, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#排序结果归一化\n",
    "def norm_sim(sim_df, weight=0.0):\n",
    "    min_sim = sim_df.min()\n",
    "    max_sim = sim_df.max()\n",
    "    if max_sim == min_sim:\n",
    "        sim_df = sim_df.apply(lambda sim:1.0)\n",
    "    else:\n",
    "        sim_df = sim_df.apply(lambda sim:1.0 * (sim-min_sim) / (max_sim-min_sim))\n",
    "    sim_df = sim_df.apply(lambda sim: sim+weight)\n",
    "    return sim_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.LGB排序模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#防止中间出错之后重新读取数据\n",
    "trn_user_item_feats_df_rank_model = trn_user_item_feats_df.copy()\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df_rank_model = val_user_item_feats_df.copy()\n",
    "    \n",
    "tst_user_item_feats_df_rank_model = tst_user_item_feats_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义特征列\n",
    "lgb_cols = ['sim0', 'time_diff0', 'word_diff0','sim_max', 'sim_min', 'sim_sum', \n",
    "            'sim_mean', 'score','click_size', 'time_diff_mean', 'active_level',\n",
    "            'click_environment','click_deviceGroup', 'click_os', 'click_country', \n",
    "            'click_region','click_referrer_type', 'user_time_hob1', 'user_time_hob2',\n",
    "            'words_hbo', 'category_id', 'created_at_ts','words_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#排序模型分组\n",
    "trn_user_item_feats_df_rank_model.sort_values(by=['user_id'], inplace=True)\n",
    "g_train = trn_user_item_feats_df_rank_model.groupby(['user_id'], as_index=False).count()[\"label\"].values\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df_rank_model.sort_values(by=['user_id'], inplace=True)\n",
    "    g_val = val_user_item_feats_df_rank_model.groupby(['user_id'], as_index=False).count()[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#排序模型定义\n",
    "lgb_ranker = lgb.LGBMRanker(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=100, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=50, random_state=2018, n_jobs= 16)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#排序模型训练\n",
    "if offline:\n",
    "    lgb_ranker.fit(trn_user_item_feats_df_rank_model[lgb_cols], trn_user_item_feats_df_rank_model['label'], group=g_train,\n",
    "                eval_set=[(val_user_item_feats_df_rank_model[lgb_cols], val_user_item_feats_df_rank_model['label'])], \n",
    "                eval_group= [g_val], eval_at=[1, 2, 3, 4, 5], eval_metric=['ndcg', ], early_stopping_rounds=50, )\n",
    "else:\n",
    "    lgb_ranker.fit(trn_user_item_feats_df[lgb_cols], trn_user_item_feats_df['label'], group=g_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "tst_user_item_feats_df['pred_score'] = lgb_ranker.predict(tst_user_item_feats_df[lgb_cols], num_iteration=lgb_ranker.best_iteration_)\n",
    "\n",
    "# 将这里的排序结果保存一份，用户后面的模型融合\n",
    "tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']].to_csv(save_path + 'lgb_ranker_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "rank_results = tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results['click_article_id'] = rank_results['click_article_id'].astype(int)\n",
    "submit(rank_results, topk=5, model_name='lgb_ranker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's ndcg@1: 0.76685\tvalid_0's ndcg@2: 0.835211\tvalid_0's ndcg@3: 0.867524\tvalid_0's ndcg@4: 0.885106\tvalid_0's ndcg@5: 0.891741\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.776425\tvalid_0's ndcg@2: 0.844234\tvalid_0's ndcg@3: 0.874734\tvalid_0's ndcg@4: 0.890841\tvalid_0's ndcg@5: 0.896954\n",
      "[3]\tvalid_0's ndcg@1: 0.78325\tvalid_0's ndcg@2: 0.851154\tvalid_0's ndcg@3: 0.879979\tvalid_0's ndcg@4: 0.895429\tvalid_0's ndcg@5: 0.900816\n",
      "[4]\tvalid_0's ndcg@1: 0.787975\tvalid_0's ndcg@2: 0.853607\tvalid_0's ndcg@3: 0.882532\tvalid_0's ndcg@4: 0.897725\tvalid_0's ndcg@5: 0.902947\n",
      "[5]\tvalid_0's ndcg@1: 0.78855\tvalid_0's ndcg@2: 0.85464\tvalid_0's ndcg@3: 0.883202\tvalid_0's ndcg@4: 0.898201\tvalid_0's ndcg@5: 0.903375\n",
      "[6]\tvalid_0's ndcg@1: 0.78995\tvalid_0's ndcg@2: 0.855866\tvalid_0's ndcg@3: 0.884316\tvalid_0's ndcg@4: 0.899056\tvalid_0's ndcg@5: 0.904105\n",
      "[7]\tvalid_0's ndcg@1: 0.7911\tvalid_0's ndcg@2: 0.856449\tvalid_0's ndcg@3: 0.884961\tvalid_0's ndcg@4: 0.899529\tvalid_0's ndcg@5: 0.904558\n",
      "[8]\tvalid_0's ndcg@1: 0.7921\tvalid_0's ndcg@2: 0.857496\tvalid_0's ndcg@3: 0.885721\tvalid_0's ndcg@4: 0.900396\tvalid_0's ndcg@5: 0.905193\n",
      "[9]\tvalid_0's ndcg@1: 0.79195\tvalid_0's ndcg@2: 0.857661\tvalid_0's ndcg@3: 0.886186\tvalid_0's ndcg@4: 0.900474\tvalid_0's ndcg@5: 0.905271\n",
      "[10]\tvalid_0's ndcg@1: 0.791675\tvalid_0's ndcg@2: 0.857954\tvalid_0's ndcg@3: 0.886242\tvalid_0's ndcg@4: 0.9004\tvalid_0's ndcg@5: 0.905275\n",
      "[11]\tvalid_0's ndcg@1: 0.792575\tvalid_0's ndcg@2: 0.858728\tvalid_0's ndcg@3: 0.88704\tvalid_0's ndcg@4: 0.900984\tvalid_0's ndcg@5: 0.905742\n",
      "[12]\tvalid_0's ndcg@1: 0.792925\tvalid_0's ndcg@2: 0.858936\tvalid_0's ndcg@3: 0.887224\tvalid_0's ndcg@4: 0.900984\tvalid_0's ndcg@5: 0.905839\n",
      "[13]\tvalid_0's ndcg@1: 0.793175\tvalid_0's ndcg@2: 0.859218\tvalid_0's ndcg@3: 0.887568\tvalid_0's ndcg@4: 0.901489\tvalid_0's ndcg@5: 0.906093\n",
      "[14]\tvalid_0's ndcg@1: 0.793\tvalid_0's ndcg@2: 0.859169\tvalid_0's ndcg@3: 0.887644\tvalid_0's ndcg@4: 0.901565\tvalid_0's ndcg@5: 0.906043\n",
      "[15]\tvalid_0's ndcg@1: 0.79415\tvalid_0's ndcg@2: 0.859877\tvalid_0's ndcg@3: 0.888077\tvalid_0's ndcg@4: 0.902031\tvalid_0's ndcg@5: 0.906509\n",
      "[16]\tvalid_0's ndcg@1: 0.797175\tvalid_0's ndcg@2: 0.862019\tvalid_0's ndcg@3: 0.889881\tvalid_0's ndcg@4: 0.903555\tvalid_0's ndcg@5: 0.907946\n",
      "[17]\tvalid_0's ndcg@1: 0.797075\tvalid_0's ndcg@2: 0.861572\tvalid_0's ndcg@3: 0.889609\tvalid_0's ndcg@4: 0.903369\tvalid_0's ndcg@5: 0.907799\n",
      "[18]\tvalid_0's ndcg@1: 0.797375\tvalid_0's ndcg@2: 0.861903\tvalid_0's ndcg@3: 0.889703\tvalid_0's ndcg@4: 0.903507\tvalid_0's ndcg@5: 0.907907\n",
      "[19]\tvalid_0's ndcg@1: 0.798375\tvalid_0's ndcg@2: 0.863061\tvalid_0's ndcg@3: 0.890736\tvalid_0's ndcg@4: 0.904205\tvalid_0's ndcg@5: 0.908529\n",
      "[20]\tvalid_0's ndcg@1: 0.7987\tvalid_0's ndcg@2: 0.863149\tvalid_0's ndcg@3: 0.890799\tvalid_0's ndcg@4: 0.904323\tvalid_0's ndcg@5: 0.908636\n",
      "[21]\tvalid_0's ndcg@1: 0.80015\tvalid_0's ndcg@2: 0.864205\tvalid_0's ndcg@3: 0.89178\tvalid_0's ndcg@4: 0.905023\tvalid_0's ndcg@5: 0.909337\n",
      "[22]\tvalid_0's ndcg@1: 0.800825\tvalid_0's ndcg@2: 0.864454\tvalid_0's ndcg@3: 0.892317\tvalid_0's ndcg@4: 0.90542\tvalid_0's ndcg@5: 0.909666\n",
      "[23]\tvalid_0's ndcg@1: 0.800875\tvalid_0's ndcg@2: 0.864993\tvalid_0's ndcg@3: 0.892406\tvalid_0's ndcg@4: 0.905563\tvalid_0's ndcg@5: 0.90978\n",
      "[24]\tvalid_0's ndcg@1: 0.800525\tvalid_0's ndcg@2: 0.864643\tvalid_0's ndcg@3: 0.892218\tvalid_0's ndcg@4: 0.905311\tvalid_0's ndcg@5: 0.909586\n",
      "[25]\tvalid_0's ndcg@1: 0.8004\tvalid_0's ndcg@2: 0.864534\tvalid_0's ndcg@3: 0.892134\tvalid_0's ndcg@4: 0.905377\tvalid_0's ndcg@5: 0.909555\n",
      "[26]\tvalid_0's ndcg@1: 0.80105\tvalid_0's ndcg@2: 0.865626\tvalid_0's ndcg@3: 0.892676\tvalid_0's ndcg@4: 0.905951\tvalid_0's ndcg@5: 0.910023\n",
      "[27]\tvalid_0's ndcg@1: 0.8008\tvalid_0's ndcg@2: 0.865281\tvalid_0's ndcg@3: 0.892494\tvalid_0's ndcg@4: 0.905812\tvalid_0's ndcg@5: 0.909874\n",
      "[28]\tvalid_0's ndcg@1: 0.8016\tvalid_0's ndcg@2: 0.865986\tvalid_0's ndcg@3: 0.892974\tvalid_0's ndcg@4: 0.906196\tvalid_0's ndcg@5: 0.910229\n",
      "[29]\tvalid_0's ndcg@1: 0.80285\tvalid_0's ndcg@2: 0.867205\tvalid_0's ndcg@3: 0.89388\tvalid_0's ndcg@4: 0.906886\tvalid_0's ndcg@5: 0.9109\n",
      "[30]\tvalid_0's ndcg@1: 0.802525\tvalid_0's ndcg@2: 0.867258\tvalid_0's ndcg@3: 0.893821\tvalid_0's ndcg@4: 0.906827\tvalid_0's ndcg@5: 0.910831\n",
      "[31]\tvalid_0's ndcg@1: 0.80255\tvalid_0's ndcg@2: 0.86722\tvalid_0's ndcg@3: 0.893908\tvalid_0's ndcg@4: 0.906903\tvalid_0's ndcg@5: 0.91084\n",
      "[32]\tvalid_0's ndcg@1: 0.803175\tvalid_0's ndcg@2: 0.867624\tvalid_0's ndcg@3: 0.894037\tvalid_0's ndcg@4: 0.90714\tvalid_0's ndcg@5: 0.911077\n",
      "[33]\tvalid_0's ndcg@1: 0.8031\tvalid_0's ndcg@2: 0.867613\tvalid_0's ndcg@3: 0.893938\tvalid_0's ndcg@4: 0.907127\tvalid_0's ndcg@5: 0.911054\n",
      "[34]\tvalid_0's ndcg@1: 0.8021\tvalid_0's ndcg@2: 0.867054\tvalid_0's ndcg@3: 0.893517\tvalid_0's ndcg@4: 0.906642\tvalid_0's ndcg@5: 0.910665\n",
      "[35]\tvalid_0's ndcg@1: 0.8021\tvalid_0's ndcg@2: 0.866944\tvalid_0's ndcg@3: 0.893581\tvalid_0's ndcg@4: 0.906706\tvalid_0's ndcg@5: 0.910652\n",
      "[36]\tvalid_0's ndcg@1: 0.801725\tvalid_0's ndcg@2: 0.866585\tvalid_0's ndcg@3: 0.89341\tvalid_0's ndcg@4: 0.906502\tvalid_0's ndcg@5: 0.910477\n",
      "[37]\tvalid_0's ndcg@1: 0.802125\tvalid_0's ndcg@2: 0.866874\tvalid_0's ndcg@3: 0.893649\tvalid_0's ndcg@4: 0.906677\tvalid_0's ndcg@5: 0.910662\n",
      "[38]\tvalid_0's ndcg@1: 0.80315\tvalid_0's ndcg@2: 0.867268\tvalid_0's ndcg@3: 0.894106\tvalid_0's ndcg@4: 0.907112\tvalid_0's ndcg@5: 0.911068\n",
      "[39]\tvalid_0's ndcg@1: 0.803425\tvalid_0's ndcg@2: 0.86748\tvalid_0's ndcg@3: 0.894293\tvalid_0's ndcg@4: 0.907245\tvalid_0's ndcg@5: 0.911201\n",
      "[40]\tvalid_0's ndcg@1: 0.8039\tvalid_0's ndcg@2: 0.867797\tvalid_0's ndcg@3: 0.894722\tvalid_0's ndcg@4: 0.907492\tvalid_0's ndcg@5: 0.911419\n",
      "[41]\tvalid_0's ndcg@1: 0.806\tvalid_0's ndcg@2: 0.86933\tvalid_0's ndcg@3: 0.896017\tvalid_0's ndcg@4: 0.908517\tvalid_0's ndcg@5: 0.912405\n",
      "[42]\tvalid_0's ndcg@1: 0.80575\tvalid_0's ndcg@2: 0.869332\tvalid_0's ndcg@3: 0.895994\tvalid_0's ndcg@4: 0.908538\tvalid_0's ndcg@5: 0.912358\n",
      "[43]\tvalid_0's ndcg@1: 0.8059\tvalid_0's ndcg@2: 0.869435\tvalid_0's ndcg@3: 0.895947\tvalid_0's ndcg@4: 0.908555\tvalid_0's ndcg@5: 0.912385\n",
      "[44]\tvalid_0's ndcg@1: 0.80585\tvalid_0's ndcg@2: 0.869274\tvalid_0's ndcg@3: 0.895974\tvalid_0's ndcg@4: 0.908507\tvalid_0's ndcg@5: 0.912346\n",
      "[45]\tvalid_0's ndcg@1: 0.806675\tvalid_0's ndcg@2: 0.869847\tvalid_0's ndcg@3: 0.896397\tvalid_0's ndcg@4: 0.908951\tvalid_0's ndcg@5: 0.912713\n",
      "[46]\tvalid_0's ndcg@1: 0.806425\tvalid_0's ndcg@2: 0.86996\tvalid_0's ndcg@3: 0.896447\tvalid_0's ndcg@4: 0.908937\tvalid_0's ndcg@5: 0.912699\n",
      "[47]\tvalid_0's ndcg@1: 0.80615\tvalid_0's ndcg@2: 0.869637\tvalid_0's ndcg@3: 0.8962\tvalid_0's ndcg@4: 0.908754\tvalid_0's ndcg@5: 0.912536\n",
      "[48]\tvalid_0's ndcg@1: 0.8062\tvalid_0's ndcg@2: 0.86975\tvalid_0's ndcg@3: 0.89625\tvalid_0's ndcg@4: 0.908751\tvalid_0's ndcg@5: 0.912571\n",
      "[49]\tvalid_0's ndcg@1: 0.80685\tvalid_0's ndcg@2: 0.870038\tvalid_0's ndcg@3: 0.896638\tvalid_0's ndcg@4: 0.909106\tvalid_0's ndcg@5: 0.912849\n",
      "[50]\tvalid_0's ndcg@1: 0.807675\tvalid_0's ndcg@2: 0.87091\tvalid_0's ndcg@3: 0.897335\tvalid_0's ndcg@4: 0.909663\tvalid_0's ndcg@5: 0.913377\n",
      "[51]\tvalid_0's ndcg@1: 0.808375\tvalid_0's ndcg@2: 0.87131\tvalid_0's ndcg@3: 0.89791\tvalid_0's ndcg@4: 0.909991\tvalid_0's ndcg@5: 0.913695\n",
      "[52]\tvalid_0's ndcg@1: 0.8097\tvalid_0's ndcg@2: 0.872761\tvalid_0's ndcg@3: 0.899236\tvalid_0's ndcg@4: 0.911102\tvalid_0's ndcg@5: 0.914506\n",
      "[53]\tvalid_0's ndcg@1: 0.810025\tvalid_0's ndcg@2: 0.873086\tvalid_0's ndcg@3: 0.899386\tvalid_0's ndcg@4: 0.911338\tvalid_0's ndcg@5: 0.914674\n",
      "[54]\tvalid_0's ndcg@1: 0.8101\tvalid_0's ndcg@2: 0.873035\tvalid_0's ndcg@3: 0.89936\tvalid_0's ndcg@4: 0.911247\tvalid_0's ndcg@5: 0.914671\n",
      "[55]\tvalid_0's ndcg@1: 0.81\tvalid_0's ndcg@2: 0.873061\tvalid_0's ndcg@3: 0.899299\tvalid_0's ndcg@4: 0.911207\tvalid_0's ndcg@5: 0.91464\n",
      "[56]\tvalid_0's ndcg@1: 0.810625\tvalid_0's ndcg@2: 0.873418\tvalid_0's ndcg@3: 0.899518\tvalid_0's ndcg@4: 0.911545\tvalid_0's ndcg@5: 0.914891\n",
      "[57]\tvalid_0's ndcg@1: 0.8105\tvalid_0's ndcg@2: 0.873419\tvalid_0's ndcg@3: 0.899607\tvalid_0's ndcg@4: 0.911515\tvalid_0's ndcg@5: 0.914861\n",
      "[58]\tvalid_0's ndcg@1: 0.810525\tvalid_0's ndcg@2: 0.873539\tvalid_0's ndcg@3: 0.899689\tvalid_0's ndcg@4: 0.911522\tvalid_0's ndcg@5: 0.914888\n",
      "[59]\tvalid_0's ndcg@1: 0.811425\tvalid_0's ndcg@2: 0.874991\tvalid_0's ndcg@3: 0.900841\tvalid_0's ndcg@4: 0.912362\tvalid_0's ndcg@5: 0.915563\n",
      "[60]\tvalid_0's ndcg@1: 0.811675\tvalid_0's ndcg@2: 0.87502\tvalid_0's ndcg@3: 0.900958\tvalid_0's ndcg@4: 0.912446\tvalid_0's ndcg@5: 0.915647\n",
      "[61]\tvalid_0's ndcg@1: 0.811325\tvalid_0's ndcg@2: 0.874844\tvalid_0's ndcg@3: 0.900694\tvalid_0's ndcg@4: 0.912247\tvalid_0's ndcg@5: 0.915496\n",
      "[62]\tvalid_0's ndcg@1: 0.8112\tvalid_0's ndcg@2: 0.87475\tvalid_0's ndcg@3: 0.900575\tvalid_0's ndcg@4: 0.912107\tvalid_0's ndcg@5: 0.915424\n",
      "[63]\tvalid_0's ndcg@1: 0.811775\tvalid_0's ndcg@2: 0.875199\tvalid_0's ndcg@3: 0.901037\tvalid_0's ndcg@4: 0.912525\tvalid_0's ndcg@5: 0.915717\n",
      "[64]\tvalid_0's ndcg@1: 0.81195\tvalid_0's ndcg@2: 0.875453\tvalid_0's ndcg@3: 0.901078\tvalid_0's ndcg@4: 0.912588\tvalid_0's ndcg@5: 0.915828\n",
      "[65]\tvalid_0's ndcg@1: 0.811925\tvalid_0's ndcg@2: 0.875397\tvalid_0's ndcg@3: 0.901034\tvalid_0's ndcg@4: 0.912587\tvalid_0's ndcg@5: 0.915807\n",
      "[66]\tvalid_0's ndcg@1: 0.812275\tvalid_0's ndcg@2: 0.875888\tvalid_0's ndcg@3: 0.901713\tvalid_0's ndcg@4: 0.912976\tvalid_0's ndcg@5: 0.916071\n",
      "[67]\tvalid_0's ndcg@1: 0.812375\tvalid_0's ndcg@2: 0.875736\tvalid_0's ndcg@3: 0.901711\tvalid_0's ndcg@4: 0.912941\tvalid_0's ndcg@5: 0.916075\n",
      "[68]\tvalid_0's ndcg@1: 0.81255\tvalid_0's ndcg@2: 0.876085\tvalid_0's ndcg@3: 0.90186\tvalid_0's ndcg@4: 0.91309\tvalid_0's ndcg@5: 0.916194\n",
      "[69]\tvalid_0's ndcg@1: 0.812825\tvalid_0's ndcg@2: 0.876107\tvalid_0's ndcg@3: 0.902082\tvalid_0's ndcg@4: 0.913226\tvalid_0's ndcg@5: 0.916301\n",
      "[70]\tvalid_0's ndcg@1: 0.812675\tvalid_0's ndcg@2: 0.876178\tvalid_0's ndcg@3: 0.901928\tvalid_0's ndcg@4: 0.913244\tvalid_0's ndcg@5: 0.916262\n",
      "[71]\tvalid_0's ndcg@1: 0.812825\tvalid_0's ndcg@2: 0.876218\tvalid_0's ndcg@3: 0.902055\tvalid_0's ndcg@4: 0.913296\tvalid_0's ndcg@5: 0.916323\n",
      "[72]\tvalid_0's ndcg@1: 0.81355\tvalid_0's ndcg@2: 0.877227\tvalid_0's ndcg@3: 0.902927\tvalid_0's ndcg@4: 0.913898\tvalid_0's ndcg@5: 0.916819\n",
      "[73]\tvalid_0's ndcg@1: 0.814075\tvalid_0's ndcg@2: 0.877815\tvalid_0's ndcg@3: 0.903377\tvalid_0's ndcg@4: 0.91423\tvalid_0's ndcg@5: 0.917132\n",
      "[74]\tvalid_0's ndcg@1: 0.81425\tvalid_0's ndcg@2: 0.877942\tvalid_0's ndcg@3: 0.903492\tvalid_0's ndcg@4: 0.91427\tvalid_0's ndcg@5: 0.91721\n",
      "[75]\tvalid_0's ndcg@1: 0.8153\tvalid_0's ndcg@2: 0.878425\tvalid_0's ndcg@3: 0.903887\tvalid_0's ndcg@4: 0.914665\tvalid_0's ndcg@5: 0.917624\n",
      "[76]\tvalid_0's ndcg@1: 0.81485\tvalid_0's ndcg@2: 0.878211\tvalid_0's ndcg@3: 0.903749\tvalid_0's ndcg@4: 0.914505\tvalid_0's ndcg@5: 0.917464\n",
      "[77]\tvalid_0's ndcg@1: 0.815425\tvalid_0's ndcg@2: 0.878881\tvalid_0's ndcg@3: 0.904106\tvalid_0's ndcg@4: 0.91484\tvalid_0's ndcg@5: 0.91778\n",
      "[78]\tvalid_0's ndcg@1: 0.815875\tvalid_0's ndcg@2: 0.879173\tvalid_0's ndcg@3: 0.904261\tvalid_0's ndcg@4: 0.915038\tvalid_0's ndcg@5: 0.917969\n",
      "[79]\tvalid_0's ndcg@1: 0.8161\tvalid_0's ndcg@2: 0.879225\tvalid_0's ndcg@3: 0.904387\tvalid_0's ndcg@4: 0.915089\tvalid_0's ndcg@5: 0.918049\n",
      "[80]\tvalid_0's ndcg@1: 0.816975\tvalid_0's ndcg@2: 0.880383\tvalid_0's ndcg@3: 0.905346\tvalid_0's ndcg@4: 0.915747\tvalid_0's ndcg@5: 0.918648\n",
      "[81]\tvalid_0's ndcg@1: 0.8174\tvalid_0's ndcg@2: 0.880525\tvalid_0's ndcg@3: 0.905512\tvalid_0's ndcg@4: 0.915913\tvalid_0's ndcg@5: 0.918805\n",
      "[82]\tvalid_0's ndcg@1: 0.81975\tvalid_0's ndcg@2: 0.883505\tvalid_0's ndcg@3: 0.907655\tvalid_0's ndcg@4: 0.917453\tvalid_0's ndcg@5: 0.920248\n",
      "[83]\tvalid_0's ndcg@1: 0.81985\tvalid_0's ndcg@2: 0.883511\tvalid_0's ndcg@3: 0.907661\tvalid_0's ndcg@4: 0.917469\tvalid_0's ndcg@5: 0.920284\n",
      "[84]\tvalid_0's ndcg@1: 0.81955\tvalid_0's ndcg@2: 0.883163\tvalid_0's ndcg@3: 0.907488\tvalid_0's ndcg@4: 0.917276\tvalid_0's ndcg@5: 0.920119\n",
      "[85]\tvalid_0's ndcg@1: 0.81995\tvalid_0's ndcg@2: 0.883469\tvalid_0's ndcg@3: 0.907669\tvalid_0's ndcg@4: 0.917467\tvalid_0's ndcg@5: 0.920291\n",
      "[86]\tvalid_0's ndcg@1: 0.82015\tvalid_0's ndcg@2: 0.884016\tvalid_0's ndcg@3: 0.907916\tvalid_0's ndcg@4: 0.917703\tvalid_0's ndcg@5: 0.920479\n",
      "[87]\tvalid_0's ndcg@1: 0.820275\tvalid_0's ndcg@2: 0.884188\tvalid_0's ndcg@3: 0.908138\tvalid_0's ndcg@4: 0.917861\tvalid_0's ndcg@5: 0.920578\n",
      "[88]\tvalid_0's ndcg@1: 0.820425\tvalid_0's ndcg@2: 0.884464\tvalid_0's ndcg@3: 0.908277\tvalid_0's ndcg@4: 0.917989\tvalid_0's ndcg@5: 0.920697\n",
      "[89]\tvalid_0's ndcg@1: 0.82115\tvalid_0's ndcg@2: 0.885189\tvalid_0's ndcg@3: 0.908702\tvalid_0's ndcg@4: 0.918381\tvalid_0's ndcg@5: 0.92106\n",
      "[90]\tvalid_0's ndcg@1: 0.820825\tvalid_0's ndcg@2: 0.885133\tvalid_0's ndcg@3: 0.908595\tvalid_0's ndcg@4: 0.918242\tvalid_0's ndcg@5: 0.92096\n",
      "[91]\tvalid_0's ndcg@1: 0.82075\tvalid_0's ndcg@2: 0.885105\tvalid_0's ndcg@3: 0.908555\tvalid_0's ndcg@4: 0.918256\tvalid_0's ndcg@5: 0.920935\n",
      "[92]\tvalid_0's ndcg@1: 0.820925\tvalid_0's ndcg@2: 0.885154\tvalid_0's ndcg@3: 0.908666\tvalid_0's ndcg@4: 0.918378\tvalid_0's ndcg@5: 0.920999\n",
      "[93]\tvalid_0's ndcg@1: 0.8208\tvalid_0's ndcg@2: 0.885044\tvalid_0's ndcg@3: 0.908557\tvalid_0's ndcg@4: 0.918258\tvalid_0's ndcg@5: 0.920927\n",
      "[94]\tvalid_0's ndcg@1: 0.820625\tvalid_0's ndcg@2: 0.88498\tvalid_0's ndcg@3: 0.908492\tvalid_0's ndcg@4: 0.918172\tvalid_0's ndcg@5: 0.92087\n",
      "[95]\tvalid_0's ndcg@1: 0.82065\tvalid_0's ndcg@2: 0.884926\tvalid_0's ndcg@3: 0.908501\tvalid_0's ndcg@4: 0.918202\tvalid_0's ndcg@5: 0.920871\n",
      "[96]\tvalid_0's ndcg@1: 0.820875\tvalid_0's ndcg@2: 0.884993\tvalid_0's ndcg@3: 0.908568\tvalid_0's ndcg@4: 0.918258\tvalid_0's ndcg@5: 0.920947\n",
      "[97]\tvalid_0's ndcg@1: 0.8214\tvalid_0's ndcg@2: 0.885392\tvalid_0's ndcg@3: 0.908967\tvalid_0's ndcg@4: 0.91855\tvalid_0's ndcg@5: 0.921219\n",
      "[98]\tvalid_0's ndcg@1: 0.823025\tvalid_0's ndcg@2: 0.88667\tvalid_0's ndcg@3: 0.909845\tvalid_0's ndcg@4: 0.919298\tvalid_0's ndcg@5: 0.921997\n",
      "[99]\tvalid_0's ndcg@1: 0.8231\tvalid_0's ndcg@2: 0.886871\tvalid_0's ndcg@3: 0.909959\tvalid_0's ndcg@4: 0.919347\tvalid_0's ndcg@5: 0.922065\n",
      "[100]\tvalid_0's ndcg@1: 0.82335\tvalid_0's ndcg@2: 0.886869\tvalid_0's ndcg@3: 0.910056\tvalid_0's ndcg@4: 0.91937\tvalid_0's ndcg@5: 0.922126\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's ndcg@1: 0.82335\tvalid_0's ndcg@2: 0.886869\tvalid_0's ndcg@3: 0.910056\tvalid_0's ndcg@4: 0.91937\tvalid_0's ndcg@5: 0.922126\n",
      "[1]\tvalid_0's ndcg@1: 0.7672\tvalid_0's ndcg@2: 0.836366\tvalid_0's ndcg@3: 0.868353\tvalid_0's ndcg@4: 0.885602\tvalid_0's ndcg@5: 0.891995\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.774975\tvalid_0's ndcg@2: 0.844456\tvalid_0's ndcg@3: 0.874981\tvalid_0's ndcg@4: 0.890927\tvalid_0's ndcg@5: 0.896614\n",
      "[3]\tvalid_0's ndcg@1: 0.7808\tvalid_0's ndcg@2: 0.85025\tvalid_0's ndcg@3: 0.880137\tvalid_0's ndcg@4: 0.895178\tvalid_0's ndcg@5: 0.900062\n",
      "[4]\tvalid_0's ndcg@1: 0.7833\tvalid_0's ndcg@2: 0.851709\tvalid_0's ndcg@3: 0.881996\tvalid_0's ndcg@4: 0.896628\tvalid_0's ndcg@5: 0.901396\n",
      "[5]\tvalid_0's ndcg@1: 0.785625\tvalid_0's ndcg@2: 0.853623\tvalid_0's ndcg@3: 0.883173\tvalid_0's ndcg@4: 0.897773\tvalid_0's ndcg@5: 0.902532\n",
      "[6]\tvalid_0's ndcg@1: 0.785575\tvalid_0's ndcg@2: 0.85351\tvalid_0's ndcg@3: 0.883323\tvalid_0's ndcg@4: 0.897944\tvalid_0's ndcg@5: 0.902538\n",
      "[7]\tvalid_0's ndcg@1: 0.78675\tvalid_0's ndcg@2: 0.85355\tvalid_0's ndcg@3: 0.883637\tvalid_0's ndcg@4: 0.898312\tvalid_0's ndcg@5: 0.902819\n",
      "[8]\tvalid_0's ndcg@1: 0.7879\tvalid_0's ndcg@2: 0.854148\tvalid_0's ndcg@3: 0.884185\tvalid_0's ndcg@4: 0.898893\tvalid_0's ndcg@5: 0.903342\n",
      "[9]\tvalid_0's ndcg@1: 0.7881\tvalid_0's ndcg@2: 0.854411\tvalid_0's ndcg@3: 0.884423\tvalid_0's ndcg@4: 0.899099\tvalid_0's ndcg@5: 0.903518\n",
      "[10]\tvalid_0's ndcg@1: 0.788325\tvalid_0's ndcg@2: 0.854699\tvalid_0's ndcg@3: 0.884561\tvalid_0's ndcg@4: 0.89928\tvalid_0's ndcg@5: 0.903641\n",
      "[11]\tvalid_0's ndcg@1: 0.789575\tvalid_0's ndcg@2: 0.856185\tvalid_0's ndcg@3: 0.885598\tvalid_0's ndcg@4: 0.900198\tvalid_0's ndcg@5: 0.904395\n",
      "[12]\tvalid_0's ndcg@1: 0.788625\tvalid_0's ndcg@2: 0.855772\tvalid_0's ndcg@3: 0.885484\tvalid_0's ndcg@4: 0.899804\tvalid_0's ndcg@5: 0.904098\n",
      "[13]\tvalid_0's ndcg@1: 0.78915\tvalid_0's ndcg@2: 0.856265\tvalid_0's ndcg@3: 0.885803\tvalid_0's ndcg@4: 0.900155\tvalid_0's ndcg@5: 0.904391\n",
      "[14]\tvalid_0's ndcg@1: 0.7887\tvalid_0's ndcg@2: 0.855847\tvalid_0's ndcg@3: 0.885472\tvalid_0's ndcg@4: 0.899889\tvalid_0's ndcg@5: 0.904183\n",
      "[15]\tvalid_0's ndcg@1: 0.78855\tvalid_0's ndcg@2: 0.855618\tvalid_0's ndcg@3: 0.885305\tvalid_0's ndcg@4: 0.899744\tvalid_0's ndcg@5: 0.904057\n",
      "[16]\tvalid_0's ndcg@1: 0.789175\tvalid_0's ndcg@2: 0.856211\tvalid_0's ndcg@3: 0.885849\tvalid_0's ndcg@4: 0.900115\tvalid_0's ndcg@5: 0.904361\n",
      "[17]\tvalid_0's ndcg@1: 0.79195\tvalid_0's ndcg@2: 0.857614\tvalid_0's ndcg@3: 0.887077\tvalid_0's ndcg@4: 0.90131\tvalid_0's ndcg@5: 0.905498\n",
      "[18]\tvalid_0's ndcg@1: 0.791575\tvalid_0's ndcg@2: 0.857633\tvalid_0's ndcg@3: 0.886908\tvalid_0's ndcg@4: 0.901164\tvalid_0's ndcg@5: 0.90538\n",
      "[19]\tvalid_0's ndcg@1: 0.79255\tvalid_0's ndcg@2: 0.858198\tvalid_0's ndcg@3: 0.887323\tvalid_0's ndcg@4: 0.901632\tvalid_0's ndcg@5: 0.905781\n",
      "[20]\tvalid_0's ndcg@1: 0.792425\tvalid_0's ndcg@2: 0.858199\tvalid_0's ndcg@3: 0.887362\tvalid_0's ndcg@4: 0.901574\tvalid_0's ndcg@5: 0.905772\n",
      "[21]\tvalid_0's ndcg@1: 0.7947\tvalid_0's ndcg@2: 0.859702\tvalid_0's ndcg@3: 0.889027\tvalid_0's ndcg@4: 0.902507\tvalid_0's ndcg@5: 0.90681\n",
      "[22]\tvalid_0's ndcg@1: 0.7954\tvalid_0's ndcg@2: 0.860496\tvalid_0's ndcg@3: 0.889734\tvalid_0's ndcg@4: 0.903009\tvalid_0's ndcg@5: 0.907236\n",
      "[23]\tvalid_0's ndcg@1: 0.7952\tvalid_0's ndcg@2: 0.860422\tvalid_0's ndcg@3: 0.889597\tvalid_0's ndcg@4: 0.902895\tvalid_0's ndcg@5: 0.90716\n",
      "[24]\tvalid_0's ndcg@1: 0.79495\tvalid_0's ndcg@2: 0.86022\tvalid_0's ndcg@3: 0.889495\tvalid_0's ndcg@4: 0.90277\tvalid_0's ndcg@5: 0.907035\n",
      "[25]\tvalid_0's ndcg@1: 0.795025\tvalid_0's ndcg@2: 0.860247\tvalid_0's ndcg@3: 0.889622\tvalid_0's ndcg@4: 0.902801\tvalid_0's ndcg@5: 0.907066\n",
      "[26]\tvalid_0's ndcg@1: 0.79535\tvalid_0's ndcg@2: 0.86062\tvalid_0's ndcg@3: 0.889895\tvalid_0's ndcg@4: 0.903052\tvalid_0's ndcg@5: 0.90723\n",
      "[27]\tvalid_0's ndcg@1: 0.7961\tvalid_0's ndcg@2: 0.861275\tvalid_0's ndcg@3: 0.890313\tvalid_0's ndcg@4: 0.903416\tvalid_0's ndcg@5: 0.907584\n",
      "[28]\tvalid_0's ndcg@1: 0.796775\tvalid_0's ndcg@2: 0.862029\tvalid_0's ndcg@3: 0.890879\tvalid_0's ndcg@4: 0.90395\tvalid_0's ndcg@5: 0.908002\n",
      "[29]\tvalid_0's ndcg@1: 0.796875\tvalid_0's ndcg@2: 0.862003\tvalid_0's ndcg@3: 0.890778\tvalid_0's ndcg@4: 0.90386\tvalid_0's ndcg@5: 0.908009\n",
      "[30]\tvalid_0's ndcg@1: 0.796725\tvalid_0's ndcg@2: 0.861868\tvalid_0's ndcg@3: 0.890856\tvalid_0's ndcg@4: 0.903852\tvalid_0's ndcg@5: 0.907962\n",
      "[31]\tvalid_0's ndcg@1: 0.796525\tvalid_0's ndcg@2: 0.861747\tvalid_0's ndcg@3: 0.890672\tvalid_0's ndcg@4: 0.903765\tvalid_0's ndcg@5: 0.907875\n",
      "[32]\tvalid_0's ndcg@1: 0.800625\tvalid_0's ndcg@2: 0.865942\tvalid_0's ndcg@3: 0.89383\tvalid_0's ndcg@4: 0.906556\tvalid_0's ndcg@5: 0.910163\n",
      "[33]\tvalid_0's ndcg@1: 0.8006\tvalid_0's ndcg@2: 0.866027\tvalid_0's ndcg@3: 0.89394\tvalid_0's ndcg@4: 0.90657\tvalid_0's ndcg@5: 0.910187\n",
      "[34]\tvalid_0's ndcg@1: 0.80055\tvalid_0's ndcg@2: 0.866025\tvalid_0's ndcg@3: 0.89385\tvalid_0's ndcg@4: 0.906619\tvalid_0's ndcg@5: 0.910169\n",
      "[35]\tvalid_0's ndcg@1: 0.800225\tvalid_0's ndcg@2: 0.865905\tvalid_0's ndcg@3: 0.89373\tvalid_0's ndcg@4: 0.906564\tvalid_0's ndcg@5: 0.910065\n",
      "[36]\tvalid_0's ndcg@1: 0.79975\tvalid_0's ndcg@2: 0.865588\tvalid_0's ndcg@3: 0.893413\tvalid_0's ndcg@4: 0.906376\tvalid_0's ndcg@5: 0.909838\n",
      "[37]\tvalid_0's ndcg@1: 0.799875\tvalid_0's ndcg@2: 0.865981\tvalid_0's ndcg@3: 0.893718\tvalid_0's ndcg@4: 0.906477\tvalid_0's ndcg@5: 0.909968\n",
      "[38]\tvalid_0's ndcg@1: 0.8001\tvalid_0's ndcg@2: 0.865922\tvalid_0's ndcg@3: 0.893809\tvalid_0's ndcg@4: 0.906579\tvalid_0's ndcg@5: 0.910031\n",
      "[39]\tvalid_0's ndcg@1: 0.8002\tvalid_0's ndcg@2: 0.866116\tvalid_0's ndcg@3: 0.893916\tvalid_0's ndcg@4: 0.9066\tvalid_0's ndcg@5: 0.910091\n",
      "[40]\tvalid_0's ndcg@1: 0.8008\tvalid_0's ndcg@2: 0.866843\tvalid_0's ndcg@3: 0.89448\tvalid_0's ndcg@4: 0.907034\tvalid_0's ndcg@5: 0.910468\n",
      "[41]\tvalid_0's ndcg@1: 0.801975\tvalid_0's ndcg@2: 0.86786\tvalid_0's ndcg@3: 0.895422\tvalid_0's ndcg@4: 0.90775\tvalid_0's ndcg@5: 0.911087\n",
      "[42]\tvalid_0's ndcg@1: 0.8019\tvalid_0's ndcg@2: 0.867958\tvalid_0's ndcg@3: 0.895421\tvalid_0's ndcg@4: 0.907738\tvalid_0's ndcg@5: 0.911065\n",
      "[43]\tvalid_0's ndcg@1: 0.802625\tvalid_0's ndcg@2: 0.869015\tvalid_0's ndcg@3: 0.896077\tvalid_0's ndcg@4: 0.908308\tvalid_0's ndcg@5: 0.911577\n",
      "[44]\tvalid_0's ndcg@1: 0.802475\tvalid_0's ndcg@2: 0.868754\tvalid_0's ndcg@3: 0.895879\tvalid_0's ndcg@4: 0.908175\tvalid_0's ndcg@5: 0.911492\n",
      "[45]\tvalid_0's ndcg@1: 0.80265\tvalid_0's ndcg@2: 0.869134\tvalid_0's ndcg@3: 0.896184\tvalid_0's ndcg@4: 0.908383\tvalid_0's ndcg@5: 0.911633\n",
      "[46]\tvalid_0's ndcg@1: 0.802625\tvalid_0's ndcg@2: 0.869141\tvalid_0's ndcg@3: 0.896128\tvalid_0's ndcg@4: 0.90837\tvalid_0's ndcg@5: 0.911629\n",
      "[47]\tvalid_0's ndcg@1: 0.80225\tvalid_0's ndcg@2: 0.868782\tvalid_0's ndcg@3: 0.895832\tvalid_0's ndcg@4: 0.90817\tvalid_0's ndcg@5: 0.91143\n",
      "[48]\tvalid_0's ndcg@1: 0.803\tvalid_0's ndcg@2: 0.869421\tvalid_0's ndcg@3: 0.896584\tvalid_0's ndcg@4: 0.9086\tvalid_0's ndcg@5: 0.911839\n",
      "[49]\tvalid_0's ndcg@1: 0.80365\tvalid_0's ndcg@2: 0.870024\tvalid_0's ndcg@3: 0.897111\tvalid_0's ndcg@4: 0.909009\tvalid_0's ndcg@5: 0.91221\n",
      "[50]\tvalid_0's ndcg@1: 0.80455\tvalid_0's ndcg@2: 0.870766\tvalid_0's ndcg@3: 0.897641\tvalid_0's ndcg@4: 0.909291\tvalid_0's ndcg@5: 0.912618\n",
      "[51]\tvalid_0's ndcg@1: 0.80415\tvalid_0's ndcg@2: 0.870571\tvalid_0's ndcg@3: 0.897384\tvalid_0's ndcg@4: 0.909281\tvalid_0's ndcg@5: 0.912444\n",
      "[52]\tvalid_0's ndcg@1: 0.8046\tvalid_0's ndcg@2: 0.87099\tvalid_0's ndcg@3: 0.897765\tvalid_0's ndcg@4: 0.909522\tvalid_0's ndcg@5: 0.912685\n",
      "[53]\tvalid_0's ndcg@1: 0.80495\tvalid_0's ndcg@2: 0.871198\tvalid_0's ndcg@3: 0.898023\tvalid_0's ndcg@4: 0.909759\tvalid_0's ndcg@5: 0.912853\n",
      "[54]\tvalid_0's ndcg@1: 0.80435\tvalid_0's ndcg@2: 0.870866\tvalid_0's ndcg@3: 0.897778\tvalid_0's ndcg@4: 0.909428\tvalid_0's ndcg@5: 0.9126\n",
      "[55]\tvalid_0's ndcg@1: 0.804175\tvalid_0's ndcg@2: 0.870707\tvalid_0's ndcg@3: 0.897582\tvalid_0's ndcg@4: 0.909296\tvalid_0's ndcg@5: 0.912497\n",
      "[56]\tvalid_0's ndcg@1: 0.804475\tvalid_0's ndcg@2: 0.870801\tvalid_0's ndcg@3: 0.897826\tvalid_0's ndcg@4: 0.909369\tvalid_0's ndcg@5: 0.912618\n",
      "[57]\tvalid_0's ndcg@1: 0.8064\tvalid_0's ndcg@2: 0.871796\tvalid_0's ndcg@3: 0.898496\tvalid_0's ndcg@4: 0.910156\tvalid_0's ndcg@5: 0.913377\n",
      "[58]\tvalid_0's ndcg@1: 0.805925\tvalid_0's ndcg@2: 0.871621\tvalid_0's ndcg@3: 0.898271\tvalid_0's ndcg@4: 0.909888\tvalid_0's ndcg@5: 0.913196\n",
      "[59]\tvalid_0's ndcg@1: 0.80675\tvalid_0's ndcg@2: 0.87254\tvalid_0's ndcg@3: 0.898978\tvalid_0's ndcg@4: 0.910455\tvalid_0's ndcg@5: 0.913676\n",
      "[60]\tvalid_0's ndcg@1: 0.80675\tvalid_0's ndcg@2: 0.872572\tvalid_0's ndcg@3: 0.899134\tvalid_0's ndcg@4: 0.910483\tvalid_0's ndcg@5: 0.913703\n",
      "[61]\tvalid_0's ndcg@1: 0.8067\tvalid_0's ndcg@2: 0.872727\tvalid_0's ndcg@3: 0.899164\tvalid_0's ndcg@4: 0.910523\tvalid_0's ndcg@5: 0.913725\n",
      "[62]\tvalid_0's ndcg@1: 0.806375\tvalid_0's ndcg@2: 0.872591\tvalid_0's ndcg@3: 0.899041\tvalid_0's ndcg@4: 0.910411\tvalid_0's ndcg@5: 0.913602\n",
      "[63]\tvalid_0's ndcg@1: 0.8077\tvalid_0's ndcg@2: 0.8739\tvalid_0's ndcg@3: 0.900063\tvalid_0's ndcg@4: 0.911207\tvalid_0's ndcg@5: 0.914321\n",
      "[64]\tvalid_0's ndcg@1: 0.808125\tvalid_0's ndcg@2: 0.874325\tvalid_0's ndcg@3: 0.9003\tvalid_0's ndcg@4: 0.911498\tvalid_0's ndcg@5: 0.914544\n",
      "[65]\tvalid_0's ndcg@1: 0.808275\tvalid_0's ndcg@2: 0.874538\tvalid_0's ndcg@3: 0.900363\tvalid_0's ndcg@4: 0.91155\tvalid_0's ndcg@5: 0.914626\n",
      "[66]\tvalid_0's ndcg@1: 0.808375\tvalid_0's ndcg@2: 0.874449\tvalid_0's ndcg@3: 0.900349\tvalid_0's ndcg@4: 0.911514\tvalid_0's ndcg@5: 0.914619\n",
      "[67]\tvalid_0's ndcg@1: 0.808125\tvalid_0's ndcg@2: 0.87431\tvalid_0's ndcg@3: 0.90026\tvalid_0's ndcg@4: 0.911457\tvalid_0's ndcg@5: 0.914523\n",
      "[68]\tvalid_0's ndcg@1: 0.80805\tvalid_0's ndcg@2: 0.874298\tvalid_0's ndcg@3: 0.900173\tvalid_0's ndcg@4: 0.911413\tvalid_0's ndcg@5: 0.914489\n",
      "[69]\tvalid_0's ndcg@1: 0.808275\tvalid_0's ndcg@2: 0.87446\tvalid_0's ndcg@3: 0.900322\tvalid_0's ndcg@4: 0.911455\tvalid_0's ndcg@5: 0.914589\n",
      "[70]\tvalid_0's ndcg@1: 0.808775\tvalid_0's ndcg@2: 0.874691\tvalid_0's ndcg@3: 0.900479\tvalid_0's ndcg@4: 0.911644\tvalid_0's ndcg@5: 0.914768\n",
      "[71]\tvalid_0's ndcg@1: 0.808775\tvalid_0's ndcg@2: 0.874849\tvalid_0's ndcg@3: 0.900487\tvalid_0's ndcg@4: 0.91163\tvalid_0's ndcg@5: 0.914803\n",
      "[72]\tvalid_0's ndcg@1: 0.8087\tvalid_0's ndcg@2: 0.874806\tvalid_0's ndcg@3: 0.900431\tvalid_0's ndcg@4: 0.911617\tvalid_0's ndcg@5: 0.91478\n",
      "[73]\tvalid_0's ndcg@1: 0.8109\tvalid_0's ndcg@2: 0.876753\tvalid_0's ndcg@3: 0.901928\tvalid_0's ndcg@4: 0.913007\tvalid_0's ndcg@5: 0.915919\n",
      "[74]\tvalid_0's ndcg@1: 0.810725\tvalid_0's ndcg@2: 0.876515\tvalid_0's ndcg@3: 0.901653\tvalid_0's ndcg@4: 0.91285\tvalid_0's ndcg@5: 0.91579\n",
      "[75]\tvalid_0's ndcg@1: 0.811075\tvalid_0's ndcg@2: 0.876802\tvalid_0's ndcg@3: 0.90189\tvalid_0's ndcg@4: 0.913055\tvalid_0's ndcg@5: 0.915966\n",
      "[76]\tvalid_0's ndcg@1: 0.81125\tvalid_0's ndcg@2: 0.87693\tvalid_0's ndcg@3: 0.901917\tvalid_0's ndcg@4: 0.913093\tvalid_0's ndcg@5: 0.916043\n",
      "[77]\tvalid_0's ndcg@1: 0.811575\tvalid_0's ndcg@2: 0.877144\tvalid_0's ndcg@3: 0.902107\tvalid_0's ndcg@4: 0.913251\tvalid_0's ndcg@5: 0.916181\n",
      "[78]\tvalid_0's ndcg@1: 0.811975\tvalid_0's ndcg@2: 0.877623\tvalid_0's ndcg@3: 0.902548\tvalid_0's ndcg@4: 0.913552\tvalid_0's ndcg@5: 0.916444\n",
      "[79]\tvalid_0's ndcg@1: 0.81255\tvalid_0's ndcg@2: 0.878198\tvalid_0's ndcg@3: 0.902923\tvalid_0's ndcg@4: 0.913884\tvalid_0's ndcg@5: 0.916747\n",
      "[80]\tvalid_0's ndcg@1: 0.814475\tvalid_0's ndcg@2: 0.879918\tvalid_0's ndcg@3: 0.904518\tvalid_0's ndcg@4: 0.915027\tvalid_0's ndcg@5: 0.917773\n",
      "[81]\tvalid_0's ndcg@1: 0.814375\tvalid_0's ndcg@2: 0.880071\tvalid_0's ndcg@3: 0.904696\tvalid_0's ndcg@4: 0.915064\tvalid_0's ndcg@5: 0.917801\n",
      "[82]\tvalid_0's ndcg@1: 0.816425\tvalid_0's ndcg@2: 0.8816\tvalid_0's ndcg@3: 0.906088\tvalid_0's ndcg@4: 0.916122\tvalid_0's ndcg@5: 0.918811\n",
      "[83]\tvalid_0's ndcg@1: 0.817025\tvalid_0's ndcg@2: 0.881758\tvalid_0's ndcg@3: 0.906346\tvalid_0's ndcg@4: 0.916402\tvalid_0's ndcg@5: 0.919023\n",
      "[84]\tvalid_0's ndcg@1: 0.8169\tvalid_0's ndcg@2: 0.881681\tvalid_0's ndcg@3: 0.906318\tvalid_0's ndcg@4: 0.916342\tvalid_0's ndcg@5: 0.918982\n",
      "[85]\tvalid_0's ndcg@1: 0.8173\tvalid_0's ndcg@2: 0.881876\tvalid_0's ndcg@3: 0.906551\tvalid_0's ndcg@4: 0.916521\tvalid_0's ndcg@5: 0.919161\n",
      "[86]\tvalid_0's ndcg@1: 0.817275\tvalid_0's ndcg@2: 0.881835\tvalid_0's ndcg@3: 0.90646\tvalid_0's ndcg@4: 0.916527\tvalid_0's ndcg@5: 0.919138\n",
      "[87]\tvalid_0's ndcg@1: 0.817525\tvalid_0's ndcg@2: 0.882148\tvalid_0's ndcg@3: 0.90691\tvalid_0's ndcg@4: 0.916698\tvalid_0's ndcg@5: 0.919309\n",
      "[88]\tvalid_0's ndcg@1: 0.81775\tvalid_0's ndcg@2: 0.88231\tvalid_0's ndcg@3: 0.907135\tvalid_0's ndcg@4: 0.916847\tvalid_0's ndcg@5: 0.919429\n",
      "[89]\tvalid_0's ndcg@1: 0.8183\tvalid_0's ndcg@2: 0.882544\tvalid_0's ndcg@3: 0.907407\tvalid_0's ndcg@4: 0.917065\tvalid_0's ndcg@5: 0.919647\n",
      "[90]\tvalid_0's ndcg@1: 0.81865\tvalid_0's ndcg@2: 0.882689\tvalid_0's ndcg@3: 0.907514\tvalid_0's ndcg@4: 0.917172\tvalid_0's ndcg@5: 0.919784\n",
      "[91]\tvalid_0's ndcg@1: 0.81865\tvalid_0's ndcg@2: 0.882579\tvalid_0's ndcg@3: 0.907391\tvalid_0's ndcg@4: 0.917125\tvalid_0's ndcg@5: 0.919746\n",
      "[92]\tvalid_0's ndcg@1: 0.8189\tvalid_0's ndcg@2: 0.882719\tvalid_0's ndcg@3: 0.907494\tvalid_0's ndcg@4: 0.917205\tvalid_0's ndcg@5: 0.919846\n",
      "[93]\tvalid_0's ndcg@1: 0.819075\tvalid_0's ndcg@2: 0.882752\tvalid_0's ndcg@3: 0.907627\tvalid_0's ndcg@4: 0.917252\tvalid_0's ndcg@5: 0.919902\n",
      "[94]\tvalid_0's ndcg@1: 0.8188\tvalid_0's ndcg@2: 0.882745\tvalid_0's ndcg@3: 0.90757\tvalid_0's ndcg@4: 0.917163\tvalid_0's ndcg@5: 0.919832\n",
      "[95]\tvalid_0's ndcg@1: 0.8189\tvalid_0's ndcg@2: 0.882813\tvalid_0's ndcg@3: 0.907526\tvalid_0's ndcg@4: 0.917205\tvalid_0's ndcg@5: 0.919874\n",
      "[96]\tvalid_0's ndcg@1: 0.81915\tvalid_0's ndcg@2: 0.883016\tvalid_0's ndcg@3: 0.907628\tvalid_0's ndcg@4: 0.917319\tvalid_0's ndcg@5: 0.919988\n",
      "[97]\tvalid_0's ndcg@1: 0.820025\tvalid_0's ndcg@2: 0.88367\tvalid_0's ndcg@3: 0.908208\tvalid_0's ndcg@4: 0.917812\tvalid_0's ndcg@5: 0.920413\n",
      "[98]\tvalid_0's ndcg@1: 0.82025\tvalid_0's ndcg@2: 0.883895\tvalid_0's ndcg@3: 0.908445\tvalid_0's ndcg@4: 0.917931\tvalid_0's ndcg@5: 0.920542\n",
      "[99]\tvalid_0's ndcg@1: 0.8199\tvalid_0's ndcg@2: 0.883687\tvalid_0's ndcg@3: 0.908274\tvalid_0's ndcg@4: 0.917782\tvalid_0's ndcg@5: 0.920393\n",
      "[100]\tvalid_0's ndcg@1: 0.820175\tvalid_0's ndcg@2: 0.883962\tvalid_0's ndcg@3: 0.908462\tvalid_0's ndcg@4: 0.917915\tvalid_0's ndcg@5: 0.920536\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tvalid_0's ndcg@1: 0.82025\tvalid_0's ndcg@2: 0.883895\tvalid_0's ndcg@3: 0.908445\tvalid_0's ndcg@4: 0.917931\tvalid_0's ndcg@5: 0.920542\n",
      "[1]\tvalid_0's ndcg@1: 0.763975\tvalid_0's ndcg@2: 0.83292\tvalid_0's ndcg@3: 0.866082\tvalid_0's ndcg@4: 0.883482\tvalid_0's ndcg@5: 0.890484\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.77\tvalid_0's ndcg@2: 0.839434\tvalid_0's ndcg@3: 0.871746\tvalid_0's ndcg@4: 0.887671\tvalid_0's ndcg@5: 0.894228\n",
      "[3]\tvalid_0's ndcg@1: 0.776575\tvalid_0's ndcg@2: 0.845804\tvalid_0's ndcg@3: 0.876804\tvalid_0's ndcg@4: 0.89206\tvalid_0's ndcg@5: 0.897931\n",
      "[4]\tvalid_0's ndcg@1: 0.7785\tvalid_0's ndcg@2: 0.847051\tvalid_0's ndcg@3: 0.878463\tvalid_0's ndcg@4: 0.893031\tvalid_0's ndcg@5: 0.898882\n",
      "[5]\tvalid_0's ndcg@1: 0.782325\tvalid_0's ndcg@2: 0.849661\tvalid_0's ndcg@3: 0.880648\tvalid_0's ndcg@4: 0.89499\tvalid_0's ndcg@5: 0.900599\n",
      "[6]\tvalid_0's ndcg@1: 0.784\tvalid_0's ndcg@2: 0.851289\tvalid_0's ndcg@3: 0.881839\tvalid_0's ndcg@4: 0.89604\tvalid_0's ndcg@5: 0.901505\n",
      "[7]\tvalid_0's ndcg@1: 0.7868\tvalid_0's ndcg@2: 0.852291\tvalid_0's ndcg@3: 0.882516\tvalid_0's ndcg@4: 0.896857\tvalid_0's ndcg@5: 0.902447\n",
      "[8]\tvalid_0's ndcg@1: 0.786575\tvalid_0's ndcg@2: 0.852207\tvalid_0's ndcg@3: 0.88242\tvalid_0's ndcg@4: 0.896934\tvalid_0's ndcg@5: 0.90235\n",
      "[9]\tvalid_0's ndcg@1: 0.787375\tvalid_0's ndcg@2: 0.853449\tvalid_0's ndcg@3: 0.883587\tvalid_0's ndcg@4: 0.897756\tvalid_0's ndcg@5: 0.902959\n",
      "[10]\tvalid_0's ndcg@1: 0.7892\tvalid_0's ndcg@2: 0.854028\tvalid_0's ndcg@3: 0.884391\tvalid_0's ndcg@4: 0.898441\tvalid_0's ndcg@5: 0.903616\n",
      "[11]\tvalid_0's ndcg@1: 0.790575\tvalid_0's ndcg@2: 0.855703\tvalid_0's ndcg@3: 0.88564\tvalid_0's ndcg@4: 0.899508\tvalid_0's ndcg@5: 0.904508\n",
      "[12]\tvalid_0's ndcg@1: 0.7906\tvalid_0's ndcg@2: 0.85557\tvalid_0's ndcg@3: 0.885457\tvalid_0's ndcg@4: 0.899498\tvalid_0's ndcg@5: 0.904478\n",
      "[13]\tvalid_0's ndcg@1: 0.7897\tvalid_0's ndcg@2: 0.855175\tvalid_0's ndcg@3: 0.88505\tvalid_0's ndcg@4: 0.899154\tvalid_0's ndcg@5: 0.904164\n",
      "[14]\tvalid_0's ndcg@1: 0.790075\tvalid_0's ndcg@2: 0.855329\tvalid_0's ndcg@3: 0.885429\tvalid_0's ndcg@4: 0.899404\tvalid_0's ndcg@5: 0.904327\n",
      "[15]\tvalid_0's ndcg@1: 0.790275\tvalid_0's ndcg@2: 0.855734\tvalid_0's ndcg@3: 0.885759\tvalid_0's ndcg@4: 0.899702\tvalid_0's ndcg@5: 0.904509\n",
      "[16]\tvalid_0's ndcg@1: 0.7921\tvalid_0's ndcg@2: 0.857543\tvalid_0's ndcg@3: 0.887406\tvalid_0's ndcg@4: 0.901058\tvalid_0's ndcg@5: 0.905555\n",
      "[17]\tvalid_0's ndcg@1: 0.791825\tvalid_0's ndcg@2: 0.857379\tvalid_0's ndcg@3: 0.887479\tvalid_0's ndcg@4: 0.900959\tvalid_0's ndcg@5: 0.905466\n",
      "[18]\tvalid_0's ndcg@1: 0.791675\tvalid_0's ndcg@2: 0.857418\tvalid_0's ndcg@3: 0.887318\tvalid_0's ndcg@4: 0.900863\tvalid_0's ndcg@5: 0.905389\n",
      "[19]\tvalid_0's ndcg@1: 0.792025\tvalid_0's ndcg@2: 0.857547\tvalid_0's ndcg@3: 0.887572\tvalid_0's ndcg@4: 0.901106\tvalid_0's ndcg@5: 0.905555\n",
      "[20]\tvalid_0's ndcg@1: 0.792325\tvalid_0's ndcg@2: 0.857674\tvalid_0's ndcg@3: 0.887699\tvalid_0's ndcg@4: 0.901276\tvalid_0's ndcg@5: 0.905676\n",
      "[21]\tvalid_0's ndcg@1: 0.7935\tvalid_0's ndcg@2: 0.859211\tvalid_0's ndcg@3: 0.888799\tvalid_0's ndcg@4: 0.902214\tvalid_0's ndcg@5: 0.906412\n",
      "[22]\tvalid_0's ndcg@1: 0.794325\tvalid_0's ndcg@2: 0.859973\tvalid_0's ndcg@3: 0.889486\tvalid_0's ndcg@4: 0.902697\tvalid_0's ndcg@5: 0.906846\n",
      "[23]\tvalid_0's ndcg@1: 0.7942\tvalid_0's ndcg@2: 0.860132\tvalid_0's ndcg@3: 0.88972\tvalid_0's ndcg@4: 0.902812\tvalid_0's ndcg@5: 0.906923\n",
      "[24]\tvalid_0's ndcg@1: 0.794125\tvalid_0's ndcg@2: 0.859915\tvalid_0's ndcg@3: 0.88944\tvalid_0's ndcg@4: 0.902684\tvalid_0's ndcg@5: 0.906803\n",
      "[25]\tvalid_0's ndcg@1: 0.79375\tvalid_0's ndcg@2: 0.859635\tvalid_0's ndcg@3: 0.889185\tvalid_0's ndcg@4: 0.902493\tvalid_0's ndcg@5: 0.906593\n",
      "[26]\tvalid_0's ndcg@1: 0.794825\tvalid_0's ndcg@2: 0.860379\tvalid_0's ndcg@3: 0.889879\tvalid_0's ndcg@4: 0.902993\tvalid_0's ndcg@5: 0.907113\n",
      "[27]\tvalid_0's ndcg@1: 0.795125\tvalid_0's ndcg@2: 0.860474\tvalid_0's ndcg@3: 0.889874\tvalid_0's ndcg@4: 0.90302\tvalid_0's ndcg@5: 0.907188\n",
      "[28]\tvalid_0's ndcg@1: 0.795925\tvalid_0's ndcg@2: 0.861258\tvalid_0's ndcg@3: 0.890583\tvalid_0's ndcg@4: 0.903535\tvalid_0's ndcg@5: 0.907646\n",
      "[29]\tvalid_0's ndcg@1: 0.797425\tvalid_0's ndcg@2: 0.862237\tvalid_0's ndcg@3: 0.8913\tvalid_0's ndcg@4: 0.904188\tvalid_0's ndcg@5: 0.908288\n",
      "[30]\tvalid_0's ndcg@1: 0.798475\tvalid_0's ndcg@2: 0.864218\tvalid_0's ndcg@3: 0.893205\tvalid_0's ndcg@4: 0.905577\tvalid_0's ndcg@5: 0.909232\n",
      "[31]\tvalid_0's ndcg@1: 0.797675\tvalid_0's ndcg@2: 0.863686\tvalid_0's ndcg@3: 0.892799\tvalid_0's ndcg@4: 0.905224\tvalid_0's ndcg@5: 0.908879\n",
      "[32]\tvalid_0's ndcg@1: 0.802475\tvalid_0's ndcg@2: 0.868139\tvalid_0's ndcg@3: 0.896277\tvalid_0's ndcg@4: 0.908023\tvalid_0's ndcg@5: 0.911418\n",
      "[33]\tvalid_0's ndcg@1: 0.801825\tvalid_0's ndcg@2: 0.867599\tvalid_0's ndcg@3: 0.895862\tvalid_0's ndcg@4: 0.907684\tvalid_0's ndcg@5: 0.911098\n",
      "[34]\tvalid_0's ndcg@1: 0.8015\tvalid_0's ndcg@2: 0.867369\tvalid_0's ndcg@3: 0.895719\tvalid_0's ndcg@4: 0.90753\tvalid_0's ndcg@5: 0.910964\n",
      "[35]\tvalid_0's ndcg@1: 0.8014\tvalid_0's ndcg@2: 0.867395\tvalid_0's ndcg@3: 0.895708\tvalid_0's ndcg@4: 0.907627\tvalid_0's ndcg@5: 0.910954\n",
      "[36]\tvalid_0's ndcg@1: 0.800825\tvalid_0's ndcg@2: 0.866994\tvalid_0's ndcg@3: 0.895406\tvalid_0's ndcg@4: 0.907293\tvalid_0's ndcg@5: 0.910688\n",
      "[37]\tvalid_0's ndcg@1: 0.801375\tvalid_0's ndcg@2: 0.867496\tvalid_0's ndcg@3: 0.895896\tvalid_0's ndcg@4: 0.907686\tvalid_0's ndcg@5: 0.911003\n",
      "[38]\tvalid_0's ndcg@1: 0.801575\tvalid_0's ndcg@2: 0.867901\tvalid_0's ndcg@3: 0.896051\tvalid_0's ndcg@4: 0.907874\tvalid_0's ndcg@5: 0.911162\n",
      "[39]\tvalid_0's ndcg@1: 0.801475\tvalid_0's ndcg@2: 0.867754\tvalid_0's ndcg@3: 0.895992\tvalid_0's ndcg@4: 0.907814\tvalid_0's ndcg@5: 0.911102\n",
      "[40]\tvalid_0's ndcg@1: 0.802125\tvalid_0's ndcg@2: 0.868262\tvalid_0's ndcg@3: 0.8967\tvalid_0's ndcg@4: 0.908199\tvalid_0's ndcg@5: 0.911458\n",
      "[41]\tvalid_0's ndcg@1: 0.8035\tvalid_0's ndcg@2: 0.869054\tvalid_0's ndcg@3: 0.897316\tvalid_0's ndcg@4: 0.908815\tvalid_0's ndcg@5: 0.912045\n",
      "[42]\tvalid_0's ndcg@1: 0.803075\tvalid_0's ndcg@2: 0.868739\tvalid_0's ndcg@3: 0.897064\tvalid_0's ndcg@4: 0.908574\tvalid_0's ndcg@5: 0.911843\n",
      "[43]\tvalid_0's ndcg@1: 0.803175\tvalid_0's ndcg@2: 0.868492\tvalid_0's ndcg@3: 0.89693\tvalid_0's ndcg@4: 0.908515\tvalid_0's ndcg@5: 0.911813\n",
      "[44]\tvalid_0's ndcg@1: 0.80305\tvalid_0's ndcg@2: 0.868335\tvalid_0's ndcg@3: 0.89676\tvalid_0's ndcg@4: 0.908346\tvalid_0's ndcg@5: 0.911711\n",
      "[45]\tvalid_0's ndcg@1: 0.803525\tvalid_0's ndcg@2: 0.869047\tvalid_0's ndcg@3: 0.89726\tvalid_0's ndcg@4: 0.908705\tvalid_0's ndcg@5: 0.912061\n",
      "[46]\tvalid_0's ndcg@1: 0.80355\tvalid_0's ndcg@2: 0.868867\tvalid_0's ndcg@3: 0.89718\tvalid_0's ndcg@4: 0.908689\tvalid_0's ndcg@5: 0.912016\n",
      "[47]\tvalid_0's ndcg@1: 0.8032\tvalid_0's ndcg@2: 0.868691\tvalid_0's ndcg@3: 0.897028\tvalid_0's ndcg@4: 0.908559\tvalid_0's ndcg@5: 0.911877\n",
      "[48]\tvalid_0's ndcg@1: 0.8038\tvalid_0's ndcg@2: 0.869164\tvalid_0's ndcg@3: 0.897502\tvalid_0's ndcg@4: 0.908969\tvalid_0's ndcg@5: 0.912208\n",
      "[49]\tvalid_0's ndcg@1: 0.804375\tvalid_0's ndcg@2: 0.869534\tvalid_0's ndcg@3: 0.897884\tvalid_0's ndcg@4: 0.909211\tvalid_0's ndcg@5: 0.912461\n",
      "[50]\tvalid_0's ndcg@1: 0.804575\tvalid_0's ndcg@2: 0.87005\tvalid_0's ndcg@3: 0.8981\tvalid_0's ndcg@4: 0.909383\tvalid_0's ndcg@5: 0.912623\n",
      "[51]\tvalid_0's ndcg@1: 0.8046\tvalid_0's ndcg@2: 0.87039\tvalid_0's ndcg@3: 0.897953\tvalid_0's ndcg@4: 0.909366\tvalid_0's ndcg@5: 0.912664\n",
      "[52]\tvalid_0's ndcg@1: 0.8048\tvalid_0's ndcg@2: 0.870732\tvalid_0's ndcg@3: 0.898257\tvalid_0's ndcg@4: 0.90953\tvalid_0's ndcg@5: 0.912818\n",
      "[53]\tvalid_0's ndcg@1: 0.805475\tvalid_0's ndcg@2: 0.871218\tvalid_0's ndcg@3: 0.898705\tvalid_0's ndcg@4: 0.909849\tvalid_0's ndcg@5: 0.913157\n",
      "[54]\tvalid_0's ndcg@1: 0.8053\tvalid_0's ndcg@2: 0.871043\tvalid_0's ndcg@3: 0.898555\tvalid_0's ndcg@4: 0.909699\tvalid_0's ndcg@5: 0.913045\n",
      "[55]\tvalid_0's ndcg@1: 0.8054\tvalid_0's ndcg@2: 0.871174\tvalid_0's ndcg@3: 0.898574\tvalid_0's ndcg@4: 0.909707\tvalid_0's ndcg@5: 0.913102\n",
      "[56]\tvalid_0's ndcg@1: 0.80595\tvalid_0's ndcg@2: 0.871314\tvalid_0's ndcg@3: 0.898789\tvalid_0's ndcg@4: 0.909933\tvalid_0's ndcg@5: 0.913308\n",
      "[57]\tvalid_0's ndcg@1: 0.806425\tvalid_0's ndcg@2: 0.871789\tvalid_0's ndcg@3: 0.899089\tvalid_0's ndcg@4: 0.910147\tvalid_0's ndcg@5: 0.913571\n",
      "[58]\tvalid_0's ndcg@1: 0.8067\tvalid_0's ndcg@2: 0.871954\tvalid_0's ndcg@3: 0.899141\tvalid_0's ndcg@4: 0.910307\tvalid_0's ndcg@5: 0.913682\n",
      "[59]\tvalid_0's ndcg@1: 0.807575\tvalid_0's ndcg@2: 0.872655\tvalid_0's ndcg@3: 0.899905\tvalid_0's ndcg@4: 0.910952\tvalid_0's ndcg@5: 0.914144\n",
      "[60]\tvalid_0's ndcg@1: 0.807725\tvalid_0's ndcg@2: 0.872679\tvalid_0's ndcg@3: 0.899917\tvalid_0's ndcg@4: 0.910985\tvalid_0's ndcg@5: 0.914196\n",
      "[61]\tvalid_0's ndcg@1: 0.807825\tvalid_0's ndcg@2: 0.872685\tvalid_0's ndcg@3: 0.899897\tvalid_0's ndcg@4: 0.911062\tvalid_0's ndcg@5: 0.914215\n",
      "[62]\tvalid_0's ndcg@1: 0.8077\tvalid_0's ndcg@2: 0.872528\tvalid_0's ndcg@3: 0.899853\tvalid_0's ndcg@4: 0.910997\tvalid_0's ndcg@5: 0.91415\n",
      "[63]\tvalid_0's ndcg@1: 0.80845\tvalid_0's ndcg@2: 0.873183\tvalid_0's ndcg@3: 0.900596\tvalid_0's ndcg@4: 0.911514\tvalid_0's ndcg@5: 0.914579\n",
      "[64]\tvalid_0's ndcg@1: 0.8085\tvalid_0's ndcg@2: 0.87317\tvalid_0's ndcg@3: 0.900558\tvalid_0's ndcg@4: 0.911508\tvalid_0's ndcg@5: 0.914583\n",
      "[65]\tvalid_0's ndcg@1: 0.808625\tvalid_0's ndcg@2: 0.873705\tvalid_0's ndcg@3: 0.900705\tvalid_0's ndcg@4: 0.911666\tvalid_0's ndcg@5: 0.914732\n",
      "[66]\tvalid_0's ndcg@1: 0.8087\tvalid_0's ndcg@2: 0.873875\tvalid_0's ndcg@3: 0.900713\tvalid_0's ndcg@4: 0.911662\tvalid_0's ndcg@5: 0.914777\n",
      "[67]\tvalid_0's ndcg@1: 0.8088\tvalid_0's ndcg@2: 0.874007\tvalid_0's ndcg@3: 0.900819\tvalid_0's ndcg@4: 0.911737\tvalid_0's ndcg@5: 0.914841\n",
      "[68]\tvalid_0's ndcg@1: 0.8087\tvalid_0's ndcg@2: 0.874001\tvalid_0's ndcg@3: 0.900776\tvalid_0's ndcg@4: 0.911683\tvalid_0's ndcg@5: 0.914807\n",
      "[69]\tvalid_0's ndcg@1: 0.8094\tvalid_0's ndcg@2: 0.874291\tvalid_0's ndcg@3: 0.901266\tvalid_0's ndcg@4: 0.912044\tvalid_0's ndcg@5: 0.91511\n",
      "[70]\tvalid_0's ndcg@1: 0.81\tvalid_0's ndcg@2: 0.874513\tvalid_0's ndcg@3: 0.901475\tvalid_0's ndcg@4: 0.912253\tvalid_0's ndcg@5: 0.915328\n",
      "[71]\tvalid_0's ndcg@1: 0.809775\tvalid_0's ndcg@2: 0.87443\tvalid_0's ndcg@3: 0.90148\tvalid_0's ndcg@4: 0.912171\tvalid_0's ndcg@5: 0.915256\n",
      "[72]\tvalid_0's ndcg@1: 0.809725\tvalid_0's ndcg@2: 0.874427\tvalid_0's ndcg@3: 0.901577\tvalid_0's ndcg@4: 0.912193\tvalid_0's ndcg@5: 0.915259\n",
      "[73]\tvalid_0's ndcg@1: 0.8102\tvalid_0's ndcg@2: 0.87487\tvalid_0's ndcg@3: 0.90182\tvalid_0's ndcg@4: 0.912393\tvalid_0's ndcg@5: 0.915488\n",
      "[74]\tvalid_0's ndcg@1: 0.8103\tvalid_0's ndcg@2: 0.874986\tvalid_0's ndcg@3: 0.901799\tvalid_0's ndcg@4: 0.912458\tvalid_0's ndcg@5: 0.915533\n",
      "[75]\tvalid_0's ndcg@1: 0.81045\tvalid_0's ndcg@2: 0.875105\tvalid_0's ndcg@3: 0.901742\tvalid_0's ndcg@4: 0.912552\tvalid_0's ndcg@5: 0.915589\n",
      "[76]\tvalid_0's ndcg@1: 0.810925\tvalid_0's ndcg@2: 0.875343\tvalid_0's ndcg@3: 0.901943\tvalid_0's ndcg@4: 0.912721\tvalid_0's ndcg@5: 0.915777\n",
      "[77]\tvalid_0's ndcg@1: 0.81055\tvalid_0's ndcg@2: 0.875094\tvalid_0's ndcg@3: 0.901769\tvalid_0's ndcg@4: 0.912568\tvalid_0's ndcg@5: 0.915615\n",
      "[78]\tvalid_0's ndcg@1: 0.81095\tvalid_0's ndcg@2: 0.875179\tvalid_0's ndcg@3: 0.902016\tvalid_0's ndcg@4: 0.91274\tvalid_0's ndcg@5: 0.915757\n",
      "[79]\tvalid_0's ndcg@1: 0.81145\tvalid_0's ndcg@2: 0.8756\tvalid_0's ndcg@3: 0.902375\tvalid_0's ndcg@4: 0.912926\tvalid_0's ndcg@5: 0.916002\n",
      "[80]\tvalid_0's ndcg@1: 0.811775\tvalid_0's ndcg@2: 0.876193\tvalid_0's ndcg@3: 0.902718\tvalid_0's ndcg@4: 0.913162\tvalid_0's ndcg@5: 0.916247\n",
      "[81]\tvalid_0's ndcg@1: 0.811475\tvalid_0's ndcg@2: 0.875877\tvalid_0's ndcg@3: 0.902552\tvalid_0's ndcg@4: 0.912996\tvalid_0's ndcg@5: 0.916091\n",
      "[82]\tvalid_0's ndcg@1: 0.81265\tvalid_0's ndcg@2: 0.876831\tvalid_0's ndcg@3: 0.903281\tvalid_0's ndcg@4: 0.913693\tvalid_0's ndcg@5: 0.916672\n",
      "[83]\tvalid_0's ndcg@1: 0.812825\tvalid_0's ndcg@2: 0.877054\tvalid_0's ndcg@3: 0.903316\tvalid_0's ndcg@4: 0.913782\tvalid_0's ndcg@5: 0.91676\n",
      "[84]\tvalid_0's ndcg@1: 0.812525\tvalid_0's ndcg@2: 0.876974\tvalid_0's ndcg@3: 0.903199\tvalid_0's ndcg@4: 0.913611\tvalid_0's ndcg@5: 0.916638\n",
      "[85]\tvalid_0's ndcg@1: 0.812625\tvalid_0's ndcg@2: 0.877311\tvalid_0's ndcg@3: 0.903499\tvalid_0's ndcg@4: 0.913824\tvalid_0's ndcg@5: 0.916774\n",
      "[86]\tvalid_0's ndcg@1: 0.812875\tvalid_0's ndcg@2: 0.877498\tvalid_0's ndcg@3: 0.903573\tvalid_0's ndcg@4: 0.913909\tvalid_0's ndcg@5: 0.916878\n",
      "[87]\tvalid_0's ndcg@1: 0.812675\tvalid_0's ndcg@2: 0.877282\tvalid_0's ndcg@3: 0.90342\tvalid_0's ndcg@4: 0.91381\tvalid_0's ndcg@5: 0.916779\n",
      "[88]\tvalid_0's ndcg@1: 0.8133\tvalid_0's ndcg@2: 0.877671\tvalid_0's ndcg@3: 0.903671\tvalid_0's ndcg@4: 0.914018\tvalid_0's ndcg@5: 0.917025\n",
      "[89]\tvalid_0's ndcg@1: 0.81315\tvalid_0's ndcg@2: 0.877868\tvalid_0's ndcg@3: 0.90373\tvalid_0's ndcg@4: 0.914034\tvalid_0's ndcg@5: 0.917032\n",
      "[90]\tvalid_0's ndcg@1: 0.813075\tvalid_0's ndcg@2: 0.877666\tvalid_0's ndcg@3: 0.903616\tvalid_0's ndcg@4: 0.913974\tvalid_0's ndcg@5: 0.916972\n",
      "[91]\tvalid_0's ndcg@1: 0.813\tvalid_0's ndcg@2: 0.877812\tvalid_0's ndcg@3: 0.903512\tvalid_0's ndcg@4: 0.913978\tvalid_0's ndcg@5: 0.916966\n",
      "[92]\tvalid_0's ndcg@1: 0.8133\tvalid_0's ndcg@2: 0.877923\tvalid_0's ndcg@3: 0.903585\tvalid_0's ndcg@4: 0.914083\tvalid_0's ndcg@5: 0.917072\n",
      "[93]\tvalid_0's ndcg@1: 0.81315\tvalid_0's ndcg@2: 0.87771\tvalid_0's ndcg@3: 0.903447\tvalid_0's ndcg@4: 0.913988\tvalid_0's ndcg@5: 0.916977\n",
      "[94]\tvalid_0's ndcg@1: 0.8131\tvalid_0's ndcg@2: 0.877707\tvalid_0's ndcg@3: 0.90347\tvalid_0's ndcg@4: 0.913967\tvalid_0's ndcg@5: 0.916966\n",
      "[95]\tvalid_0's ndcg@1: 0.81295\tvalid_0's ndcg@2: 0.877762\tvalid_0's ndcg@3: 0.903412\tvalid_0's ndcg@4: 0.913932\tvalid_0's ndcg@5: 0.91693\n",
      "[96]\tvalid_0's ndcg@1: 0.813875\tvalid_0's ndcg@2: 0.878687\tvalid_0's ndcg@3: 0.904175\tvalid_0's ndcg@4: 0.914565\tvalid_0's ndcg@5: 0.917447\n",
      "[97]\tvalid_0's ndcg@1: 0.8144\tvalid_0's ndcg@2: 0.87937\tvalid_0's ndcg@3: 0.904645\tvalid_0's ndcg@4: 0.914981\tvalid_0's ndcg@5: 0.917776\n",
      "[98]\tvalid_0's ndcg@1: 0.8154\tvalid_0's ndcg@2: 0.880007\tvalid_0's ndcg@3: 0.905257\tvalid_0's ndcg@4: 0.915507\tvalid_0's ndcg@5: 0.918254\n",
      "[99]\tvalid_0's ndcg@1: 0.815175\tvalid_0's ndcg@2: 0.879893\tvalid_0's ndcg@3: 0.905118\tvalid_0's ndcg@4: 0.915368\tvalid_0's ndcg@5: 0.918143\n",
      "[100]\tvalid_0's ndcg@1: 0.815425\tvalid_0's ndcg@2: 0.880032\tvalid_0's ndcg@3: 0.905282\tvalid_0's ndcg@4: 0.915446\tvalid_0's ndcg@5: 0.918241\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's ndcg@1: 0.815425\tvalid_0's ndcg@2: 0.880032\tvalid_0's ndcg@3: 0.905282\tvalid_0's ndcg@4: 0.915446\tvalid_0's ndcg@5: 0.918241\n",
      "[1]\tvalid_0's ndcg@1: 0.760825\tvalid_0's ndcg@2: 0.830906\tvalid_0's ndcg@3: 0.864906\tvalid_0's ndcg@4: 0.88266\tvalid_0's ndcg@5: 0.889314\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.77425\tvalid_0's ndcg@2: 0.843905\tvalid_0's ndcg@3: 0.874767\tvalid_0's ndcg@4: 0.890541\tvalid_0's ndcg@5: 0.896518\n",
      "[3]\tvalid_0's ndcg@1: 0.7799\tvalid_0's ndcg@2: 0.849917\tvalid_0's ndcg@3: 0.879755\tvalid_0's ndcg@4: 0.894495\tvalid_0's ndcg@5: 0.899891\n",
      "[4]\tvalid_0's ndcg@1: 0.7836\tvalid_0's ndcg@2: 0.853255\tvalid_0's ndcg@3: 0.882842\tvalid_0's ndcg@4: 0.896796\tvalid_0's ndcg@5: 0.901912\n",
      "[5]\tvalid_0's ndcg@1: 0.787225\tvalid_0's ndcg@2: 0.855523\tvalid_0's ndcg@3: 0.884561\tvalid_0's ndcg@4: 0.898482\tvalid_0's ndcg@5: 0.903492\n",
      "[6]\tvalid_0's ndcg@1: 0.788125\tvalid_0's ndcg@2: 0.856139\tvalid_0's ndcg@3: 0.885102\tvalid_0's ndcg@4: 0.898894\tvalid_0's ndcg@5: 0.903904\n",
      "[7]\tvalid_0's ndcg@1: 0.789225\tvalid_0's ndcg@2: 0.856529\tvalid_0's ndcg@3: 0.885804\tvalid_0's ndcg@4: 0.899586\tvalid_0's ndcg@5: 0.904373\n",
      "[8]\tvalid_0's ndcg@1: 0.791625\tvalid_0's ndcg@2: 0.857778\tvalid_0's ndcg@3: 0.88679\tvalid_0's ndcg@4: 0.900518\tvalid_0's ndcg@5: 0.905306\n",
      "[9]\tvalid_0's ndcg@1: 0.791825\tvalid_0's ndcg@2: 0.85782\tvalid_0's ndcg@3: 0.886745\tvalid_0's ndcg@4: 0.900473\tvalid_0's ndcg@5: 0.905357\n",
      "[10]\tvalid_0's ndcg@1: 0.792425\tvalid_0's ndcg@2: 0.858263\tvalid_0's ndcg@3: 0.886938\tvalid_0's ndcg@4: 0.900719\tvalid_0's ndcg@5: 0.905613\n",
      "[11]\tvalid_0's ndcg@1: 0.793575\tvalid_0's ndcg@2: 0.859428\tvalid_0's ndcg@3: 0.887853\tvalid_0's ndcg@4: 0.901441\tvalid_0's ndcg@5: 0.906209\n",
      "[12]\tvalid_0's ndcg@1: 0.792925\tvalid_0's ndcg@2: 0.859062\tvalid_0's ndcg@3: 0.887575\tvalid_0's ndcg@4: 0.901195\tvalid_0's ndcg@5: 0.905963\n",
      "[13]\tvalid_0's ndcg@1: 0.79285\tvalid_0's ndcg@2: 0.859208\tvalid_0's ndcg@3: 0.887771\tvalid_0's ndcg@4: 0.901326\tvalid_0's ndcg@5: 0.905997\n",
      "[14]\tvalid_0's ndcg@1: 0.792525\tvalid_0's ndcg@2: 0.859388\tvalid_0's ndcg@3: 0.887988\tvalid_0's ndcg@4: 0.90136\tvalid_0's ndcg@5: 0.90607\n",
      "[15]\tvalid_0's ndcg@1: 0.7929\tvalid_0's ndcg@2: 0.859715\tvalid_0's ndcg@3: 0.888103\tvalid_0's ndcg@4: 0.901529\tvalid_0's ndcg@5: 0.90622\n",
      "[16]\tvalid_0's ndcg@1: 0.793475\tvalid_0's ndcg@2: 0.86029\tvalid_0's ndcg@3: 0.888628\tvalid_0's ndcg@4: 0.901968\tvalid_0's ndcg@5: 0.906504\n",
      "[17]\tvalid_0's ndcg@1: 0.793175\tvalid_0's ndcg@2: 0.859912\tvalid_0's ndcg@3: 0.888212\tvalid_0's ndcg@4: 0.901767\tvalid_0's ndcg@5: 0.906303\n",
      "[18]\tvalid_0's ndcg@1: 0.793275\tvalid_0's ndcg@2: 0.859617\tvalid_0's ndcg@3: 0.88828\tvalid_0's ndcg@4: 0.901663\tvalid_0's ndcg@5: 0.906286\n",
      "[19]\tvalid_0's ndcg@1: 0.7944\tvalid_0's ndcg@2: 0.860585\tvalid_0's ndcg@3: 0.889272\tvalid_0's ndcg@4: 0.902386\tvalid_0's ndcg@5: 0.906903\n",
      "[20]\tvalid_0's ndcg@1: 0.7948\tvalid_0's ndcg@2: 0.860748\tvalid_0's ndcg@3: 0.889435\tvalid_0's ndcg@4: 0.902539\tvalid_0's ndcg@5: 0.907065\n",
      "[21]\tvalid_0's ndcg@1: 0.796075\tvalid_0's ndcg@2: 0.86226\tvalid_0's ndcg@3: 0.890585\tvalid_0's ndcg@4: 0.903365\tvalid_0's ndcg@5: 0.907833\n",
      "[22]\tvalid_0's ndcg@1: 0.796425\tvalid_0's ndcg@2: 0.862925\tvalid_0's ndcg@3: 0.890912\tvalid_0's ndcg@4: 0.90379\tvalid_0's ndcg@5: 0.908084\n",
      "[23]\tvalid_0's ndcg@1: 0.796875\tvalid_0's ndcg@2: 0.862933\tvalid_0's ndcg@3: 0.891196\tvalid_0's ndcg@4: 0.903869\tvalid_0's ndcg@5: 0.90823\n",
      "[24]\tvalid_0's ndcg@1: 0.797375\tvalid_0's ndcg@2: 0.863244\tvalid_0's ndcg@3: 0.891382\tvalid_0's ndcg@4: 0.904011\tvalid_0's ndcg@5: 0.908441\n",
      "[25]\tvalid_0's ndcg@1: 0.79665\tvalid_0's ndcg@2: 0.863245\tvalid_0's ndcg@3: 0.891045\tvalid_0's ndcg@4: 0.903814\tvalid_0's ndcg@5: 0.908253\n",
      "[26]\tvalid_0's ndcg@1: 0.797475\tvalid_0's ndcg@2: 0.863928\tvalid_0's ndcg@3: 0.89149\tvalid_0's ndcg@4: 0.904141\tvalid_0's ndcg@5: 0.908609\n",
      "[27]\tvalid_0's ndcg@1: 0.797675\tvalid_0's ndcg@2: 0.863954\tvalid_0's ndcg@3: 0.891679\tvalid_0's ndcg@4: 0.90419\tvalid_0's ndcg@5: 0.908687\n",
      "[28]\tvalid_0's ndcg@1: 0.799\tvalid_0's ndcg@2: 0.865185\tvalid_0's ndcg@3: 0.89276\tvalid_0's ndcg@4: 0.905088\tvalid_0's ndcg@5: 0.909411\n",
      "[29]\tvalid_0's ndcg@1: 0.7986\tvalid_0's ndcg@2: 0.86499\tvalid_0's ndcg@3: 0.892565\tvalid_0's ndcg@4: 0.904947\tvalid_0's ndcg@5: 0.90926\n",
      "[30]\tvalid_0's ndcg@1: 0.79925\tvalid_0's ndcg@2: 0.865214\tvalid_0's ndcg@3: 0.892726\tvalid_0's ndcg@4: 0.905162\tvalid_0's ndcg@5: 0.909485\n",
      "[31]\tvalid_0's ndcg@1: 0.79935\tvalid_0's ndcg@2: 0.865156\tvalid_0's ndcg@3: 0.892881\tvalid_0's ndcg@4: 0.905306\tvalid_0's ndcg@5: 0.909523\n",
      "[32]\tvalid_0's ndcg@1: 0.802875\tvalid_0's ndcg@2: 0.868965\tvalid_0's ndcg@3: 0.896077\tvalid_0's ndcg@4: 0.907953\tvalid_0's ndcg@5: 0.911638\n",
      "[33]\tvalid_0's ndcg@1: 0.8026\tvalid_0's ndcg@2: 0.868753\tvalid_0's ndcg@3: 0.89589\tvalid_0's ndcg@4: 0.907874\tvalid_0's ndcg@5: 0.91151\n",
      "[34]\tvalid_0's ndcg@1: 0.802125\tvalid_0's ndcg@2: 0.868325\tvalid_0's ndcg@3: 0.89565\tvalid_0's ndcg@4: 0.907612\tvalid_0's ndcg@5: 0.911278\n",
      "[35]\tvalid_0's ndcg@1: 0.8019\tvalid_0's ndcg@2: 0.868053\tvalid_0's ndcg@3: 0.89549\tvalid_0's ndcg@4: 0.907474\tvalid_0's ndcg@5: 0.911149\n",
      "[36]\tvalid_0's ndcg@1: 0.8017\tvalid_0's ndcg@2: 0.867727\tvalid_0's ndcg@3: 0.895227\tvalid_0's ndcg@4: 0.907307\tvalid_0's ndcg@5: 0.911002\n",
      "[37]\tvalid_0's ndcg@1: 0.8014\tvalid_0's ndcg@2: 0.867932\tvalid_0's ndcg@3: 0.895369\tvalid_0's ndcg@4: 0.907288\tvalid_0's ndcg@5: 0.910963\n",
      "[38]\tvalid_0's ndcg@1: 0.801525\tvalid_0's ndcg@2: 0.868072\tvalid_0's ndcg@3: 0.895535\tvalid_0's ndcg@4: 0.907475\tvalid_0's ndcg@5: 0.911073\n",
      "[39]\tvalid_0's ndcg@1: 0.802125\tvalid_0's ndcg@2: 0.86842\tvalid_0's ndcg@3: 0.895732\tvalid_0's ndcg@4: 0.907619\tvalid_0's ndcg@5: 0.911285\n",
      "[40]\tvalid_0's ndcg@1: 0.803225\tvalid_0's ndcg@2: 0.869189\tvalid_0's ndcg@3: 0.896514\tvalid_0's ndcg@4: 0.908207\tvalid_0's ndcg@5: 0.911824\n",
      "[41]\tvalid_0's ndcg@1: 0.803525\tvalid_0's ndcg@2: 0.869457\tvalid_0's ndcg@3: 0.896682\tvalid_0's ndcg@4: 0.908353\tvalid_0's ndcg@5: 0.911971\n",
      "[42]\tvalid_0's ndcg@1: 0.804375\tvalid_0's ndcg@2: 0.869881\tvalid_0's ndcg@3: 0.897006\tvalid_0's ndcg@4: 0.908678\tvalid_0's ndcg@5: 0.912314\n",
      "[43]\tvalid_0's ndcg@1: 0.804525\tvalid_0's ndcg@2: 0.870047\tvalid_0's ndcg@3: 0.897147\tvalid_0's ndcg@4: 0.90884\tvalid_0's ndcg@5: 0.912409\n",
      "[44]\tvalid_0's ndcg@1: 0.80445\tvalid_0's ndcg@2: 0.870161\tvalid_0's ndcg@3: 0.897024\tvalid_0's ndcg@4: 0.908792\tvalid_0's ndcg@5: 0.91239\n",
      "[45]\tvalid_0's ndcg@1: 0.805125\tvalid_0's ndcg@2: 0.8706\tvalid_0's ndcg@3: 0.8974\tvalid_0's ndcg@4: 0.909179\tvalid_0's ndcg@5: 0.912689\n",
      "[46]\tvalid_0's ndcg@1: 0.805325\tvalid_0's ndcg@2: 0.870784\tvalid_0's ndcg@3: 0.897546\tvalid_0's ndcg@4: 0.90925\tvalid_0's ndcg@5: 0.912809\n",
      "[47]\tvalid_0's ndcg@1: 0.804875\tvalid_0's ndcg@2: 0.870507\tvalid_0's ndcg@3: 0.897145\tvalid_0's ndcg@4: 0.90901\tvalid_0's ndcg@5: 0.912579\n",
      "[48]\tvalid_0's ndcg@1: 0.80545\tvalid_0's ndcg@2: 0.871272\tvalid_0's ndcg@3: 0.898047\tvalid_0's ndcg@4: 0.909557\tvalid_0's ndcg@5: 0.913009\n",
      "[49]\tvalid_0's ndcg@1: 0.80615\tvalid_0's ndcg@2: 0.871735\tvalid_0's ndcg@3: 0.898423\tvalid_0's ndcg@4: 0.909879\tvalid_0's ndcg@5: 0.913331\n",
      "[50]\tvalid_0's ndcg@1: 0.80655\tvalid_0's ndcg@2: 0.872214\tvalid_0's ndcg@3: 0.898614\tvalid_0's ndcg@4: 0.910232\tvalid_0's ndcg@5: 0.913558\n",
      "[51]\tvalid_0's ndcg@1: 0.80785\tvalid_0's ndcg@2: 0.872978\tvalid_0's ndcg@3: 0.899265\tvalid_0's ndcg@4: 0.910807\tvalid_0's ndcg@5: 0.914105\n",
      "[52]\tvalid_0's ndcg@1: 0.809125\tvalid_0's ndcg@2: 0.874032\tvalid_0's ndcg@3: 0.900244\tvalid_0's ndcg@4: 0.911603\tvalid_0's ndcg@5: 0.914766\n",
      "[53]\tvalid_0's ndcg@1: 0.809075\tvalid_0's ndcg@2: 0.874218\tvalid_0's ndcg@3: 0.900281\tvalid_0's ndcg@4: 0.911629\tvalid_0's ndcg@5: 0.914802\n",
      "[54]\tvalid_0's ndcg@1: 0.809075\tvalid_0's ndcg@2: 0.874045\tvalid_0's ndcg@3: 0.900145\tvalid_0's ndcg@4: 0.911569\tvalid_0's ndcg@5: 0.914751\n",
      "[55]\tvalid_0's ndcg@1: 0.8088\tvalid_0's ndcg@2: 0.873896\tvalid_0's ndcg@3: 0.899959\tvalid_0's ndcg@4: 0.911469\tvalid_0's ndcg@5: 0.914621\n",
      "[56]\tvalid_0's ndcg@1: 0.80955\tvalid_0's ndcg@2: 0.874662\tvalid_0's ndcg@3: 0.900624\tvalid_0's ndcg@4: 0.911876\tvalid_0's ndcg@5: 0.915048\n",
      "[57]\tvalid_0's ndcg@1: 0.809125\tvalid_0's ndcg@2: 0.87441\tvalid_0's ndcg@3: 0.90036\tvalid_0's ndcg@4: 0.911633\tvalid_0's ndcg@5: 0.914854\n",
      "[58]\tvalid_0's ndcg@1: 0.80945\tvalid_0's ndcg@2: 0.874688\tvalid_0's ndcg@3: 0.900576\tvalid_0's ndcg@4: 0.911719\tvalid_0's ndcg@5: 0.915008\n",
      "[59]\tvalid_0's ndcg@1: 0.80965\tvalid_0's ndcg@2: 0.874746\tvalid_0's ndcg@3: 0.900659\tvalid_0's ndcg@4: 0.911802\tvalid_0's ndcg@5: 0.915091\n",
      "[60]\tvalid_0's ndcg@1: 0.8097\tvalid_0's ndcg@2: 0.874638\tvalid_0's ndcg@3: 0.900613\tvalid_0's ndcg@4: 0.911714\tvalid_0's ndcg@5: 0.91506\n",
      "[61]\tvalid_0's ndcg@1: 0.809725\tvalid_0's ndcg@2: 0.874506\tvalid_0's ndcg@3: 0.900506\tvalid_0's ndcg@4: 0.911617\tvalid_0's ndcg@5: 0.915021\n",
      "[62]\tvalid_0's ndcg@1: 0.809575\tvalid_0's ndcg@2: 0.874261\tvalid_0's ndcg@3: 0.900324\tvalid_0's ndcg@4: 0.911489\tvalid_0's ndcg@5: 0.914913\n",
      "[63]\tvalid_0's ndcg@1: 0.81175\tvalid_0's ndcg@2: 0.876373\tvalid_0's ndcg@3: 0.90231\tvalid_0's ndcg@4: 0.913077\tvalid_0's ndcg@5: 0.916163\n",
      "[64]\tvalid_0's ndcg@1: 0.811925\tvalid_0's ndcg@2: 0.876721\tvalid_0's ndcg@3: 0.902509\tvalid_0's ndcg@4: 0.913211\tvalid_0's ndcg@5: 0.916296\n",
      "[65]\tvalid_0's ndcg@1: 0.811975\tvalid_0's ndcg@2: 0.876503\tvalid_0's ndcg@3: 0.902341\tvalid_0's ndcg@4: 0.913183\tvalid_0's ndcg@5: 0.916249\n",
      "[66]\tvalid_0's ndcg@1: 0.811325\tvalid_0's ndcg@2: 0.876263\tvalid_0's ndcg@3: 0.902176\tvalid_0's ndcg@4: 0.913051\tvalid_0's ndcg@5: 0.916039\n",
      "[67]\tvalid_0's ndcg@1: 0.811425\tvalid_0's ndcg@2: 0.876411\tvalid_0's ndcg@3: 0.902148\tvalid_0's ndcg@4: 0.913077\tvalid_0's ndcg@5: 0.916075\n",
      "[68]\tvalid_0's ndcg@1: 0.811475\tvalid_0's ndcg@2: 0.876319\tvalid_0's ndcg@3: 0.902156\tvalid_0's ndcg@4: 0.913052\tvalid_0's ndcg@5: 0.91607\n",
      "[69]\tvalid_0's ndcg@1: 0.812025\tvalid_0's ndcg@2: 0.876632\tvalid_0's ndcg@3: 0.902432\tvalid_0's ndcg@4: 0.913242\tvalid_0's ndcg@5: 0.916298\n",
      "[70]\tvalid_0's ndcg@1: 0.81225\tvalid_0's ndcg@2: 0.876778\tvalid_0's ndcg@3: 0.902528\tvalid_0's ndcg@4: 0.913414\tvalid_0's ndcg@5: 0.916412\n",
      "[71]\tvalid_0's ndcg@1: 0.811925\tvalid_0's ndcg@2: 0.876548\tvalid_0's ndcg@3: 0.90241\tvalid_0's ndcg@4: 0.913242\tvalid_0's ndcg@5: 0.916269\n",
      "[72]\tvalid_0's ndcg@1: 0.812225\tvalid_0's ndcg@2: 0.876832\tvalid_0's ndcg@3: 0.902582\tvalid_0's ndcg@4: 0.913371\tvalid_0's ndcg@5: 0.916407\n",
      "[73]\tvalid_0's ndcg@1: 0.813025\tvalid_0's ndcg@2: 0.877711\tvalid_0's ndcg@3: 0.903286\tvalid_0's ndcg@4: 0.913859\tvalid_0's ndcg@5: 0.916877\n",
      "[74]\tvalid_0's ndcg@1: 0.8131\tvalid_0's ndcg@2: 0.877786\tvalid_0's ndcg@3: 0.903274\tvalid_0's ndcg@4: 0.913868\tvalid_0's ndcg@5: 0.916905\n",
      "[75]\tvalid_0's ndcg@1: 0.81405\tvalid_0's ndcg@2: 0.878326\tvalid_0's ndcg@3: 0.903688\tvalid_0's ndcg@4: 0.914229\tvalid_0's ndcg@5: 0.917285\n",
      "[76]\tvalid_0's ndcg@1: 0.813775\tvalid_0's ndcg@2: 0.878114\tvalid_0's ndcg@3: 0.903577\tvalid_0's ndcg@4: 0.914107\tvalid_0's ndcg@5: 0.917172\n",
      "[77]\tvalid_0's ndcg@1: 0.8134\tvalid_0's ndcg@2: 0.877834\tvalid_0's ndcg@3: 0.903334\tvalid_0's ndcg@4: 0.913918\tvalid_0's ndcg@5: 0.916974\n",
      "[78]\tvalid_0's ndcg@1: 0.814025\tvalid_0's ndcg@2: 0.878238\tvalid_0's ndcg@3: 0.903713\tvalid_0's ndcg@4: 0.914211\tvalid_0's ndcg@5: 0.917267\n",
      "[79]\tvalid_0's ndcg@1: 0.81415\tvalid_0's ndcg@2: 0.878599\tvalid_0's ndcg@3: 0.903774\tvalid_0's ndcg@4: 0.914348\tvalid_0's ndcg@5: 0.917355\n",
      "[80]\tvalid_0's ndcg@1: 0.81455\tvalid_0's ndcg@2: 0.878984\tvalid_0's ndcg@3: 0.904021\tvalid_0's ndcg@4: 0.914551\tvalid_0's ndcg@5: 0.917569\n",
      "[81]\tvalid_0's ndcg@1: 0.81485\tvalid_0's ndcg@2: 0.879142\tvalid_0's ndcg@3: 0.904192\tvalid_0's ndcg@4: 0.914689\tvalid_0's ndcg@5: 0.917697\n",
      "[82]\tvalid_0's ndcg@1: 0.8174\tvalid_0's ndcg@2: 0.881313\tvalid_0's ndcg@3: 0.905976\tvalid_0's ndcg@4: 0.916204\tvalid_0's ndcg@5: 0.919028\n",
      "[83]\tvalid_0's ndcg@1: 0.817475\tvalid_0's ndcg@2: 0.881278\tvalid_0's ndcg@3: 0.905953\tvalid_0's ndcg@4: 0.916214\tvalid_0's ndcg@5: 0.919018\n",
      "[84]\tvalid_0's ndcg@1: 0.81745\tvalid_0's ndcg@2: 0.881174\tvalid_0's ndcg@3: 0.905886\tvalid_0's ndcg@4: 0.916137\tvalid_0's ndcg@5: 0.91898\n",
      "[85]\tvalid_0's ndcg@1: 0.8173\tvalid_0's ndcg@2: 0.880961\tvalid_0's ndcg@3: 0.905711\tvalid_0's ndcg@4: 0.916058\tvalid_0's ndcg@5: 0.918882\n",
      "[86]\tvalid_0's ndcg@1: 0.8173\tvalid_0's ndcg@2: 0.88104\tvalid_0's ndcg@3: 0.905827\tvalid_0's ndcg@4: 0.916099\tvalid_0's ndcg@5: 0.918923\n",
      "[87]\tvalid_0's ndcg@1: 0.8173\tvalid_0's ndcg@2: 0.880977\tvalid_0's ndcg@3: 0.905839\tvalid_0's ndcg@4: 0.916089\tvalid_0's ndcg@5: 0.918904\n",
      "[88]\tvalid_0's ndcg@1: 0.81775\tvalid_0's ndcg@2: 0.881348\tvalid_0's ndcg@3: 0.905998\tvalid_0's ndcg@4: 0.916323\tvalid_0's ndcg@5: 0.919109\n",
      "[89]\tvalid_0's ndcg@1: 0.8178\tvalid_0's ndcg@2: 0.881524\tvalid_0's ndcg@3: 0.906074\tvalid_0's ndcg@4: 0.916367\tvalid_0's ndcg@5: 0.919172\n",
      "[90]\tvalid_0's ndcg@1: 0.81795\tvalid_0's ndcg@2: 0.881579\tvalid_0's ndcg@3: 0.906104\tvalid_0's ndcg@4: 0.916419\tvalid_0's ndcg@5: 0.919233\n",
      "[91]\tvalid_0's ndcg@1: 0.817825\tvalid_0's ndcg@2: 0.881517\tvalid_0's ndcg@3: 0.905942\tvalid_0's ndcg@4: 0.916311\tvalid_0's ndcg@5: 0.919164\n",
      "[92]\tvalid_0's ndcg@1: 0.817675\tvalid_0's ndcg@2: 0.881304\tvalid_0's ndcg@3: 0.905842\tvalid_0's ndcg@4: 0.916221\tvalid_0's ndcg@5: 0.919074\n",
      "[93]\tvalid_0's ndcg@1: 0.817425\tvalid_0's ndcg@2: 0.881212\tvalid_0's ndcg@3: 0.905762\tvalid_0's ndcg@4: 0.916098\tvalid_0's ndcg@5: 0.91898\n",
      "[94]\tvalid_0's ndcg@1: 0.81765\tvalid_0's ndcg@2: 0.881295\tvalid_0's ndcg@3: 0.905808\tvalid_0's ndcg@4: 0.916176\tvalid_0's ndcg@5: 0.919068\n",
      "[95]\tvalid_0's ndcg@1: 0.817675\tvalid_0's ndcg@2: 0.881304\tvalid_0's ndcg@3: 0.905817\tvalid_0's ndcg@4: 0.916185\tvalid_0's ndcg@5: 0.919077\n",
      "[96]\tvalid_0's ndcg@1: 0.817925\tvalid_0's ndcg@2: 0.881412\tvalid_0's ndcg@3: 0.905937\tvalid_0's ndcg@4: 0.916317\tvalid_0's ndcg@5: 0.919179\n",
      "[97]\tvalid_0's ndcg@1: 0.818825\tvalid_0's ndcg@2: 0.882202\tvalid_0's ndcg@3: 0.906639\tvalid_0's ndcg@4: 0.916868\tvalid_0's ndcg@5: 0.919653\n",
      "[98]\tvalid_0's ndcg@1: 0.81915\tvalid_0's ndcg@2: 0.882606\tvalid_0's ndcg@3: 0.906956\tvalid_0's ndcg@4: 0.917141\tvalid_0's ndcg@5: 0.919859\n",
      "[99]\tvalid_0's ndcg@1: 0.819425\tvalid_0's ndcg@2: 0.88266\tvalid_0's ndcg@3: 0.90706\tvalid_0's ndcg@4: 0.917213\tvalid_0's ndcg@5: 0.91996\n",
      "[100]\tvalid_0's ndcg@1: 0.8195\tvalid_0's ndcg@2: 0.88264\tvalid_0's ndcg@3: 0.90714\tvalid_0's ndcg@4: 0.917229\tvalid_0's ndcg@5: 0.919985\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's ndcg@1: 0.8195\tvalid_0's ndcg@2: 0.88264\tvalid_0's ndcg@3: 0.90714\tvalid_0's ndcg@4: 0.917229\tvalid_0's ndcg@5: 0.919985\n",
      "[1]\tvalid_0's ndcg@1: 0.759875\tvalid_0's ndcg@2: 0.829656\tvalid_0's ndcg@3: 0.863906\tvalid_0's ndcg@4: 0.882177\tvalid_0's ndcg@5: 0.888686\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.77305\tvalid_0's ndcg@2: 0.842894\tvalid_0's ndcg@3: 0.873594\tvalid_0's ndcg@4: 0.889712\tvalid_0's ndcg@5: 0.895863\n",
      "[3]\tvalid_0's ndcg@1: 0.77795\tvalid_0's ndcg@2: 0.848583\tvalid_0's ndcg@3: 0.87812\tvalid_0's ndcg@4: 0.893937\tvalid_0's ndcg@5: 0.898975\n",
      "[4]\tvalid_0's ndcg@1: 0.783775\tvalid_0's ndcg@2: 0.854171\tvalid_0's ndcg@3: 0.883233\tvalid_0's ndcg@4: 0.897747\tvalid_0's ndcg@5: 0.902264\n",
      "[5]\tvalid_0's ndcg@1: 0.78885\tvalid_0's ndcg@2: 0.856801\tvalid_0's ndcg@3: 0.885351\tvalid_0's ndcg@4: 0.899682\tvalid_0's ndcg@5: 0.904314\n",
      "[6]\tvalid_0's ndcg@1: 0.7888\tvalid_0's ndcg@2: 0.856704\tvalid_0's ndcg@3: 0.884791\tvalid_0's ndcg@4: 0.899413\tvalid_0's ndcg@5: 0.904229\n",
      "[7]\tvalid_0's ndcg@1: 0.790125\tvalid_0's ndcg@2: 0.857287\tvalid_0's ndcg@3: 0.885637\tvalid_0's ndcg@4: 0.900119\tvalid_0's ndcg@5: 0.90479\n",
      "[8]\tvalid_0's ndcg@1: 0.790375\tvalid_0's ndcg@2: 0.857948\tvalid_0's ndcg@3: 0.885973\tvalid_0's ndcg@4: 0.900368\tvalid_0's ndcg@5: 0.90502\n",
      "[9]\tvalid_0's ndcg@1: 0.791575\tvalid_0's ndcg@2: 0.858785\tvalid_0's ndcg@3: 0.886535\tvalid_0's ndcg@4: 0.900909\tvalid_0's ndcg@5: 0.905532\n",
      "[10]\tvalid_0's ndcg@1: 0.79155\tvalid_0's ndcg@2: 0.858507\tvalid_0's ndcg@3: 0.886245\tvalid_0's ndcg@4: 0.900726\tvalid_0's ndcg@5: 0.905475\n",
      "[11]\tvalid_0's ndcg@1: 0.792725\tvalid_0's ndcg@2: 0.859746\tvalid_0's ndcg@3: 0.887646\tvalid_0's ndcg@4: 0.901589\tvalid_0's ndcg@5: 0.906173\n",
      "[12]\tvalid_0's ndcg@1: 0.79195\tvalid_0's ndcg@2: 0.85916\tvalid_0's ndcg@3: 0.887297\tvalid_0's ndcg@4: 0.901208\tvalid_0's ndcg@5: 0.905841\n",
      "[13]\tvalid_0's ndcg@1: 0.791825\tvalid_0's ndcg@2: 0.859445\tvalid_0's ndcg@3: 0.887582\tvalid_0's ndcg@4: 0.901418\tvalid_0's ndcg@5: 0.905905\n",
      "[14]\tvalid_0's ndcg@1: 0.791975\tvalid_0's ndcg@2: 0.859011\tvalid_0's ndcg@3: 0.887374\tvalid_0's ndcg@4: 0.901285\tvalid_0's ndcg@5: 0.90583\n",
      "[15]\tvalid_0's ndcg@1: 0.793575\tvalid_0's ndcg@2: 0.859823\tvalid_0's ndcg@3: 0.88791\tvalid_0's ndcg@4: 0.901886\tvalid_0's ndcg@5: 0.90645\n",
      "[16]\tvalid_0's ndcg@1: 0.79445\tvalid_0's ndcg@2: 0.860635\tvalid_0's ndcg@3: 0.88861\tvalid_0's ndcg@4: 0.902327\tvalid_0's ndcg@5: 0.906843\n",
      "[17]\tvalid_0's ndcg@1: 0.794225\tvalid_0's ndcg@2: 0.86063\tvalid_0's ndcg@3: 0.888555\tvalid_0's ndcg@4: 0.902197\tvalid_0's ndcg@5: 0.906791\n",
      "[18]\tvalid_0's ndcg@1: 0.794575\tvalid_0's ndcg@2: 0.861012\tvalid_0's ndcg@3: 0.888787\tvalid_0's ndcg@4: 0.902429\tvalid_0's ndcg@5: 0.906984\n",
      "[19]\tvalid_0's ndcg@1: 0.7949\tvalid_0's ndcg@2: 0.861226\tvalid_0's ndcg@3: 0.889151\tvalid_0's ndcg@4: 0.902675\tvalid_0's ndcg@5: 0.907172\n",
      "[20]\tvalid_0's ndcg@1: 0.7955\tvalid_0's ndcg@2: 0.861574\tvalid_0's ndcg@3: 0.889337\tvalid_0's ndcg@4: 0.902828\tvalid_0's ndcg@5: 0.907421\n",
      "[21]\tvalid_0's ndcg@1: 0.796575\tvalid_0's ndcg@2: 0.862618\tvalid_0's ndcg@3: 0.89028\tvalid_0's ndcg@4: 0.903588\tvalid_0's ndcg@5: 0.908017\n",
      "[22]\tvalid_0's ndcg@1: 0.7978\tvalid_0's ndcg@2: 0.863811\tvalid_0's ndcg@3: 0.891124\tvalid_0's ndcg@4: 0.904399\tvalid_0's ndcg@5: 0.908684\n",
      "[23]\tvalid_0's ndcg@1: 0.79765\tvalid_0's ndcg@2: 0.863787\tvalid_0's ndcg@3: 0.891037\tvalid_0's ndcg@4: 0.904184\tvalid_0's ndcg@5: 0.908574\n",
      "[24]\tvalid_0's ndcg@1: 0.797675\tvalid_0's ndcg@2: 0.863497\tvalid_0's ndcg@3: 0.891047\tvalid_0's ndcg@4: 0.904129\tvalid_0's ndcg@5: 0.908539\n",
      "[25]\tvalid_0's ndcg@1: 0.797775\tvalid_0's ndcg@2: 0.863549\tvalid_0's ndcg@3: 0.891087\tvalid_0's ndcg@4: 0.904212\tvalid_0's ndcg@5: 0.908593\n",
      "[26]\tvalid_0's ndcg@1: 0.798575\tvalid_0's ndcg@2: 0.864334\tvalid_0's ndcg@3: 0.891746\tvalid_0's ndcg@4: 0.904688\tvalid_0's ndcg@5: 0.909011\n",
      "[27]\tvalid_0's ndcg@1: 0.79925\tvalid_0's ndcg@2: 0.864567\tvalid_0's ndcg@3: 0.891942\tvalid_0's ndcg@4: 0.904852\tvalid_0's ndcg@5: 0.909252\n",
      "[28]\tvalid_0's ndcg@1: 0.799675\tvalid_0's ndcg@2: 0.865166\tvalid_0's ndcg@3: 0.892291\tvalid_0's ndcg@4: 0.905114\tvalid_0's ndcg@5: 0.909524\n",
      "[29]\tvalid_0's ndcg@1: 0.7997\tvalid_0's ndcg@2: 0.865632\tvalid_0's ndcg@3: 0.892407\tvalid_0's ndcg@4: 0.905317\tvalid_0's ndcg@5: 0.90964\n",
      "[30]\tvalid_0's ndcg@1: 0.7999\tvalid_0's ndcg@2: 0.86569\tvalid_0's ndcg@3: 0.89249\tvalid_0's ndcg@4: 0.905357\tvalid_0's ndcg@5: 0.909728\n",
      "[31]\tvalid_0's ndcg@1: 0.79955\tvalid_0's ndcg@2: 0.865451\tvalid_0's ndcg@3: 0.892388\tvalid_0's ndcg@4: 0.905222\tvalid_0's ndcg@5: 0.909574\n",
      "[32]\tvalid_0's ndcg@1: 0.80505\tvalid_0's ndcg@2: 0.870761\tvalid_0's ndcg@3: 0.896974\tvalid_0's ndcg@4: 0.908914\tvalid_0's ndcg@5: 0.912657\n",
      "[33]\tvalid_0's ndcg@1: 0.804525\tvalid_0's ndcg@2: 0.870426\tvalid_0's ndcg@3: 0.896726\tvalid_0's ndcg@4: 0.90872\tvalid_0's ndcg@5: 0.912443\n",
      "[34]\tvalid_0's ndcg@1: 0.80385\tvalid_0's ndcg@2: 0.869861\tvalid_0's ndcg@3: 0.896361\tvalid_0's ndcg@4: 0.908355\tvalid_0's ndcg@5: 0.912127\n",
      "[35]\tvalid_0's ndcg@1: 0.803725\tvalid_0's ndcg@2: 0.869657\tvalid_0's ndcg@3: 0.896257\tvalid_0's ndcg@4: 0.908208\tvalid_0's ndcg@5: 0.912058\n",
      "[36]\tvalid_0's ndcg@1: 0.8037\tvalid_0's ndcg@2: 0.869679\tvalid_0's ndcg@3: 0.896254\tvalid_0's ndcg@4: 0.908195\tvalid_0's ndcg@5: 0.912054\n",
      "[37]\tvalid_0's ndcg@1: 0.804125\tvalid_0's ndcg@2: 0.870136\tvalid_0's ndcg@3: 0.896486\tvalid_0's ndcg@4: 0.908383\tvalid_0's ndcg@5: 0.912242\n",
      "[38]\tvalid_0's ndcg@1: 0.8044\tvalid_0's ndcg@2: 0.870379\tvalid_0's ndcg@3: 0.896604\tvalid_0's ndcg@4: 0.908545\tvalid_0's ndcg@5: 0.912404\n",
      "[39]\tvalid_0's ndcg@1: 0.803775\tvalid_0's ndcg@2: 0.869991\tvalid_0's ndcg@3: 0.896229\tvalid_0's ndcg@4: 0.908244\tvalid_0's ndcg@5: 0.912123\n",
      "[40]\tvalid_0's ndcg@1: 0.804475\tvalid_0's ndcg@2: 0.87036\tvalid_0's ndcg@3: 0.896935\tvalid_0's ndcg@4: 0.908638\tvalid_0's ndcg@5: 0.912449\n",
      "[41]\tvalid_0's ndcg@1: 0.805225\tvalid_0's ndcg@2: 0.871141\tvalid_0's ndcg@3: 0.897504\tvalid_0's ndcg@4: 0.909111\tvalid_0's ndcg@5: 0.912873\n",
      "[42]\tvalid_0's ndcg@1: 0.80535\tvalid_0's ndcg@2: 0.871251\tvalid_0's ndcg@3: 0.897701\tvalid_0's ndcg@4: 0.909318\tvalid_0's ndcg@5: 0.912974\n",
      "[43]\tvalid_0's ndcg@1: 0.805675\tvalid_0's ndcg@2: 0.871371\tvalid_0's ndcg@3: 0.897596\tvalid_0's ndcg@4: 0.909375\tvalid_0's ndcg@5: 0.913069\n",
      "[44]\tvalid_0's ndcg@1: 0.805725\tvalid_0's ndcg@2: 0.8712\tvalid_0's ndcg@3: 0.897575\tvalid_0's ndcg@4: 0.909365\tvalid_0's ndcg@5: 0.913059\n",
      "[45]\tvalid_0's ndcg@1: 0.807275\tvalid_0's ndcg@2: 0.872907\tvalid_0's ndcg@3: 0.89907\tvalid_0's ndcg@4: 0.91044\tvalid_0's ndcg@5: 0.913951\n",
      "[46]\tvalid_0's ndcg@1: 0.8073\tvalid_0's ndcg@2: 0.872885\tvalid_0's ndcg@3: 0.899023\tvalid_0's ndcg@4: 0.910479\tvalid_0's ndcg@5: 0.91396\n",
      "[47]\tvalid_0's ndcg@1: 0.806425\tvalid_0's ndcg@2: 0.872389\tvalid_0's ndcg@3: 0.898451\tvalid_0's ndcg@4: 0.909993\tvalid_0's ndcg@5: 0.913581\n",
      "[48]\tvalid_0's ndcg@1: 0.806575\tvalid_0's ndcg@2: 0.872413\tvalid_0's ndcg@3: 0.89845\tvalid_0's ndcg@4: 0.910078\tvalid_0's ndcg@5: 0.913628\n",
      "[49]\tvalid_0's ndcg@1: 0.807425\tvalid_0's ndcg@2: 0.872963\tvalid_0's ndcg@3: 0.899138\tvalid_0's ndcg@4: 0.910594\tvalid_0's ndcg@5: 0.914056\n",
      "[50]\tvalid_0's ndcg@1: 0.808275\tvalid_0's ndcg@2: 0.873608\tvalid_0's ndcg@3: 0.89952\tvalid_0's ndcg@4: 0.911084\tvalid_0's ndcg@5: 0.91445\n",
      "[51]\tvalid_0's ndcg@1: 0.808675\tvalid_0's ndcg@2: 0.873724\tvalid_0's ndcg@3: 0.899736\tvalid_0's ndcg@4: 0.911246\tvalid_0's ndcg@5: 0.914612\n",
      "[52]\tvalid_0's ndcg@1: 0.809025\tvalid_0's ndcg@2: 0.874011\tvalid_0's ndcg@3: 0.900061\tvalid_0's ndcg@4: 0.911431\tvalid_0's ndcg@5: 0.914777\n",
      "[53]\tvalid_0's ndcg@1: 0.8091\tvalid_0's ndcg@2: 0.874433\tvalid_0's ndcg@3: 0.900008\tvalid_0's ndcg@4: 0.91155\tvalid_0's ndcg@5: 0.914838\n",
      "[54]\tvalid_0's ndcg@1: 0.808325\tvalid_0's ndcg@2: 0.874084\tvalid_0's ndcg@3: 0.899759\tvalid_0's ndcg@4: 0.911301\tvalid_0's ndcg@5: 0.91455\n",
      "[55]\tvalid_0's ndcg@1: 0.80815\tvalid_0's ndcg@2: 0.873719\tvalid_0's ndcg@3: 0.899644\tvalid_0's ndcg@4: 0.911187\tvalid_0's ndcg@5: 0.914446\n",
      "[56]\tvalid_0's ndcg@1: 0.809075\tvalid_0's ndcg@2: 0.874392\tvalid_0's ndcg@3: 0.900167\tvalid_0's ndcg@4: 0.911623\tvalid_0's ndcg@5: 0.914873\n",
      "[57]\tvalid_0's ndcg@1: 0.8088\tvalid_0's ndcg@2: 0.874464\tvalid_0's ndcg@3: 0.900089\tvalid_0's ndcg@4: 0.91161\tvalid_0's ndcg@5: 0.91482\n",
      "[58]\tvalid_0's ndcg@1: 0.80955\tvalid_0's ndcg@2: 0.875088\tvalid_0's ndcg@3: 0.900388\tvalid_0's ndcg@4: 0.911941\tvalid_0's ndcg@5: 0.915161\n",
      "[59]\tvalid_0's ndcg@1: 0.809625\tvalid_0's ndcg@2: 0.874895\tvalid_0's ndcg@3: 0.90047\tvalid_0's ndcg@4: 0.911969\tvalid_0's ndcg@5: 0.91516\n",
      "[60]\tvalid_0's ndcg@1: 0.809975\tvalid_0's ndcg@2: 0.874992\tvalid_0's ndcg@3: 0.900542\tvalid_0's ndcg@4: 0.912095\tvalid_0's ndcg@5: 0.915287\n",
      "[61]\tvalid_0's ndcg@1: 0.809575\tvalid_0's ndcg@2: 0.87475\tvalid_0's ndcg@3: 0.900425\tvalid_0's ndcg@4: 0.911838\tvalid_0's ndcg@5: 0.915117\n",
      "[62]\tvalid_0's ndcg@1: 0.8097\tvalid_0's ndcg@2: 0.87456\tvalid_0's ndcg@3: 0.90026\tvalid_0's ndcg@4: 0.911737\tvalid_0's ndcg@5: 0.915074\n",
      "[63]\tvalid_0's ndcg@1: 0.810325\tvalid_0's ndcg@2: 0.875579\tvalid_0's ndcg@3: 0.901229\tvalid_0's ndcg@4: 0.912373\tvalid_0's ndcg@5: 0.915555\n",
      "[64]\tvalid_0's ndcg@1: 0.810375\tvalid_0's ndcg@2: 0.875582\tvalid_0's ndcg@3: 0.901132\tvalid_0's ndcg@4: 0.912361\tvalid_0's ndcg@5: 0.915553\n",
      "[65]\tvalid_0's ndcg@1: 0.8103\tvalid_0's ndcg@2: 0.875601\tvalid_0's ndcg@3: 0.901226\tvalid_0's ndcg@4: 0.91237\tvalid_0's ndcg@5: 0.915552\n",
      "[66]\tvalid_0's ndcg@1: 0.81065\tvalid_0's ndcg@2: 0.875935\tvalid_0's ndcg@3: 0.901535\tvalid_0's ndcg@4: 0.912647\tvalid_0's ndcg@5: 0.915751\n",
      "[67]\tvalid_0's ndcg@1: 0.81095\tvalid_0's ndcg@2: 0.876172\tvalid_0's ndcg@3: 0.901547\tvalid_0's ndcg@4: 0.912788\tvalid_0's ndcg@5: 0.915883\n",
      "[68]\tvalid_0's ndcg@1: 0.8109\tvalid_0's ndcg@2: 0.876138\tvalid_0's ndcg@3: 0.901501\tvalid_0's ndcg@4: 0.91272\tvalid_0's ndcg@5: 0.915853\n",
      "[69]\tvalid_0's ndcg@1: 0.81075\tvalid_0's ndcg@2: 0.875893\tvalid_0's ndcg@3: 0.901518\tvalid_0's ndcg@4: 0.912587\tvalid_0's ndcg@5: 0.915769\n",
      "[70]\tvalid_0's ndcg@1: 0.81095\tvalid_0's ndcg@2: 0.875983\tvalid_0's ndcg@3: 0.901671\tvalid_0's ndcg@4: 0.912739\tvalid_0's ndcg@5: 0.915843\n",
      "[71]\tvalid_0's ndcg@1: 0.810725\tvalid_0's ndcg@2: 0.8759\tvalid_0's ndcg@3: 0.901525\tvalid_0's ndcg@4: 0.912712\tvalid_0's ndcg@5: 0.915768\n",
      "[72]\tvalid_0's ndcg@1: 0.8108\tvalid_0's ndcg@2: 0.87618\tvalid_0's ndcg@3: 0.90173\tvalid_0's ndcg@4: 0.912863\tvalid_0's ndcg@5: 0.915871\n",
      "[73]\tvalid_0's ndcg@1: 0.81185\tvalid_0's ndcg@2: 0.87712\tvalid_0's ndcg@3: 0.902282\tvalid_0's ndcg@4: 0.913415\tvalid_0's ndcg@5: 0.916384\n",
      "[74]\tvalid_0's ndcg@1: 0.8117\tvalid_0's ndcg@2: 0.876985\tvalid_0's ndcg@3: 0.902223\tvalid_0's ndcg@4: 0.913313\tvalid_0's ndcg@5: 0.916311\n",
      "[75]\tvalid_0's ndcg@1: 0.8118\tvalid_0's ndcg@2: 0.877291\tvalid_0's ndcg@3: 0.902328\tvalid_0's ndcg@4: 0.913439\tvalid_0's ndcg@5: 0.916399\n",
      "[76]\tvalid_0's ndcg@1: 0.812075\tvalid_0's ndcg@2: 0.877755\tvalid_0's ndcg@3: 0.902642\tvalid_0's ndcg@4: 0.913721\tvalid_0's ndcg@5: 0.916623\n",
      "[77]\tvalid_0's ndcg@1: 0.812575\tvalid_0's ndcg@2: 0.877655\tvalid_0's ndcg@3: 0.90278\tvalid_0's ndcg@4: 0.913827\tvalid_0's ndcg@5: 0.916748\n",
      "[78]\tvalid_0's ndcg@1: 0.813275\tvalid_0's ndcg@2: 0.878466\tvalid_0's ndcg@3: 0.903428\tvalid_0's ndcg@4: 0.914303\tvalid_0's ndcg@5: 0.917166\n",
      "[79]\tvalid_0's ndcg@1: 0.8136\tvalid_0's ndcg@2: 0.878649\tvalid_0's ndcg@3: 0.903536\tvalid_0's ndcg@4: 0.914432\tvalid_0's ndcg@5: 0.917286\n",
      "[80]\tvalid_0's ndcg@1: 0.81455\tvalid_0's ndcg@2: 0.87941\tvalid_0's ndcg@3: 0.904147\tvalid_0's ndcg@4: 0.91486\tvalid_0's ndcg@5: 0.917723\n",
      "[81]\tvalid_0's ndcg@1: 0.814725\tvalid_0's ndcg@2: 0.879395\tvalid_0's ndcg@3: 0.904208\tvalid_0's ndcg@4: 0.91491\tvalid_0's ndcg@5: 0.917773\n",
      "[82]\tvalid_0's ndcg@1: 0.816425\tvalid_0's ndcg@2: 0.880843\tvalid_0's ndcg@3: 0.90518\tvalid_0's ndcg@4: 0.915721\tvalid_0's ndcg@5: 0.918603\n",
      "[83]\tvalid_0's ndcg@1: 0.8165\tvalid_0's ndcg@2: 0.881013\tvalid_0's ndcg@3: 0.905188\tvalid_0's ndcg@4: 0.915804\tvalid_0's ndcg@5: 0.918647\n",
      "[84]\tvalid_0's ndcg@1: 0.8165\tvalid_0's ndcg@2: 0.880918\tvalid_0's ndcg@3: 0.90518\tvalid_0's ndcg@4: 0.915786\tvalid_0's ndcg@5: 0.918629\n",
      "[85]\tvalid_0's ndcg@1: 0.8162\tvalid_0's ndcg@2: 0.880555\tvalid_0's ndcg@3: 0.904955\tvalid_0's ndcg@4: 0.915571\tvalid_0's ndcg@5: 0.918453\n",
      "[86]\tvalid_0's ndcg@1: 0.81645\tvalid_0's ndcg@2: 0.880694\tvalid_0's ndcg@3: 0.905244\tvalid_0's ndcg@4: 0.915721\tvalid_0's ndcg@5: 0.918583\n",
      "[87]\tvalid_0's ndcg@1: 0.816625\tvalid_0's ndcg@2: 0.880822\tvalid_0's ndcg@3: 0.90541\tvalid_0's ndcg@4: 0.915767\tvalid_0's ndcg@5: 0.918669\n",
      "[88]\tvalid_0's ndcg@1: 0.816875\tvalid_0's ndcg@2: 0.881167\tvalid_0's ndcg@3: 0.905554\tvalid_0's ndcg@4: 0.91588\tvalid_0's ndcg@5: 0.9188\n",
      "[89]\tvalid_0's ndcg@1: 0.817375\tvalid_0's ndcg@2: 0.881667\tvalid_0's ndcg@3: 0.905929\tvalid_0's ndcg@4: 0.916158\tvalid_0's ndcg@5: 0.919079\n",
      "[90]\tvalid_0's ndcg@1: 0.81735\tvalid_0's ndcg@2: 0.881642\tvalid_0's ndcg@3: 0.905842\tvalid_0's ndcg@4: 0.916135\tvalid_0's ndcg@5: 0.919056\n",
      "[91]\tvalid_0's ndcg@1: 0.8172\tvalid_0's ndcg@2: 0.881397\tvalid_0's ndcg@3: 0.905747\tvalid_0's ndcg@4: 0.916073\tvalid_0's ndcg@5: 0.918974\n",
      "[92]\tvalid_0's ndcg@1: 0.817425\tvalid_0's ndcg@2: 0.881669\tvalid_0's ndcg@3: 0.905982\tvalid_0's ndcg@4: 0.916243\tvalid_0's ndcg@5: 0.919106\n",
      "[93]\tvalid_0's ndcg@1: 0.8175\tvalid_0's ndcg@2: 0.881618\tvalid_0's ndcg@3: 0.905931\tvalid_0's ndcg@4: 0.916213\tvalid_0's ndcg@5: 0.919105\n",
      "[94]\tvalid_0's ndcg@1: 0.8172\tvalid_0's ndcg@2: 0.881413\tvalid_0's ndcg@3: 0.905738\tvalid_0's ndcg@4: 0.916085\tvalid_0's ndcg@5: 0.918967\n",
      "[95]\tvalid_0's ndcg@1: 0.8173\tvalid_0's ndcg@2: 0.881466\tvalid_0's ndcg@3: 0.905866\tvalid_0's ndcg@4: 0.91618\tvalid_0's ndcg@5: 0.919024\n",
      "[96]\tvalid_0's ndcg@1: 0.81765\tvalid_0's ndcg@2: 0.881816\tvalid_0's ndcg@3: 0.906091\tvalid_0's ndcg@4: 0.916351\tvalid_0's ndcg@5: 0.919195\n",
      "[97]\tvalid_0's ndcg@1: 0.818825\tvalid_0's ndcg@2: 0.883054\tvalid_0's ndcg@3: 0.907154\tvalid_0's ndcg@4: 0.917081\tvalid_0's ndcg@5: 0.919866\n",
      "[98]\tvalid_0's ndcg@1: 0.820175\tvalid_0's ndcg@2: 0.884009\tvalid_0's ndcg@3: 0.907984\tvalid_0's ndcg@4: 0.917782\tvalid_0's ndcg@5: 0.920519\n",
      "[99]\tvalid_0's ndcg@1: 0.820325\tvalid_0's ndcg@2: 0.883875\tvalid_0's ndcg@3: 0.907925\tvalid_0's ndcg@4: 0.917799\tvalid_0's ndcg@5: 0.920536\n",
      "[100]\tvalid_0's ndcg@1: 0.820425\tvalid_0's ndcg@2: 0.883975\tvalid_0's ndcg@3: 0.9079\tvalid_0's ndcg@4: 0.917838\tvalid_0's ndcg@5: 0.920585\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's ndcg@1: 0.820425\tvalid_0's ndcg@2: 0.883975\tvalid_0's ndcg@3: 0.9079\tvalid_0's ndcg@4: 0.917838\tvalid_0's ndcg@5: 0.920585\n"
     ]
    }
   ],
   "source": [
    "# 五折交叉验证，这里的五折交叉是以用户为目标进行五折划分\n",
    "#  这一部分与前面的单独训练和验证是分开的\n",
    "def get_kfold_users(trn_df, n=5):\n",
    "    user_ids = trn_df['user_id'].unique()\n",
    "    user_set = [user_ids[i::n] for i in range(n)]\n",
    "    return user_set\n",
    "\n",
    "k_fold = 5\n",
    "trn_df = trn_user_item_feats_df_rank_model\n",
    "user_set = get_kfold_users(trn_df, n=k_fold)\n",
    "\n",
    "score_list = []\n",
    "score_df = trn_df[['user_id', 'click_article_id','label']]\n",
    "sub_preds = np.zeros(tst_user_item_feats_df_rank_model.shape[0])\n",
    "\n",
    "# 五折交叉验证，并将中间结果保存用于staking\n",
    "for n_fold, valid_user in enumerate(user_set):\n",
    "    train_idx = trn_df[~trn_df['user_id'].isin(valid_user)] # add slide user\n",
    "    valid_idx = trn_df[trn_df['user_id'].isin(valid_user)]\n",
    "    \n",
    "    # 训练集与验证集的用户分组\n",
    "    train_idx.sort_values(by=['user_id'], inplace=True)\n",
    "    g_train = train_idx.groupby(['user_id'], as_index=False).count()[\"label\"].values\n",
    "    \n",
    "    valid_idx.sort_values(by=['user_id'], inplace=True)\n",
    "    g_val = valid_idx.groupby(['user_id'], as_index=False).count()[\"label\"].values\n",
    "    \n",
    "    # 定义模型\n",
    "    lgb_ranker = lgb.LGBMRanker(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=100, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=50, random_state=2018, n_jobs= 16)  \n",
    "    # 训练模型\n",
    "    lgb_ranker.fit(train_idx[lgb_cols], train_idx['label'], group=g_train,\n",
    "                   eval_set=[(valid_idx[lgb_cols], valid_idx['label'])], eval_group= [g_val], \n",
    "                   eval_at=[1, 2, 3, 4, 5], eval_metric=['ndcg', ], early_stopping_rounds=50, )\n",
    "    \n",
    "    # 预测验证集结果\n",
    "    valid_idx['pred_score'] = lgb_ranker.predict(valid_idx[lgb_cols], num_iteration=lgb_ranker.best_iteration_)\n",
    "    \n",
    "    # 对输出结果进行归一化\n",
    "    valid_idx['pred_score'] = valid_idx[['pred_score']].transform(lambda x: norm_sim(x))\n",
    "    \n",
    "    valid_idx.sort_values(by=['user_id', 'pred_score'])\n",
    "    valid_idx['pred_rank'] = valid_idx.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    \n",
    "    # 将验证集的预测结果放到一个列表中，后面进行拼接\n",
    "    score_list.append(valid_idx[['user_id', 'click_article_id', 'pred_score', 'pred_rank']])\n",
    "    \n",
    "    # 如果是线上测试，需要计算每次交叉验证的结果相加，最后求平均\n",
    "    if not offline:\n",
    "        sub_preds += lgb_ranker.predict(tst_user_item_feats_df_rank_model[lgb_cols], lgb_ranker.best_iteration_)\n",
    "    \n",
    "score_df_ = pd.concat(score_list, axis=0)\n",
    "score_df = score_df.merge(score_df_, how='left', on=['user_id', 'click_article_id'])\n",
    "# 保存训练集交叉验证产生的新特征\n",
    "score_df[['user_id', 'click_article_id', 'pred_score', 'pred_rank', 'label']].to_csv(save_path + 'trn_lgb_ranker_feats.csv', index=False)\n",
    "    \n",
    "# 测试集的预测结果，多次交叉验证求平均,将预测的score和对应的rank特征保存，可以用于后面的staking，这里还可以构造其他更多的特征\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = sub_preds / k_fold\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = tst_user_item_feats_df_rank_model['pred_score'].transform(lambda x: norm_sim(x))\n",
    "tst_user_item_feats_df_rank_model.sort_values(by=['user_id', 'pred_score'])\n",
    "tst_user_item_feats_df_rank_model['pred_rank'] = tst_user_item_feats_df_rank_model.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "\n",
    "# 保存测试集交叉验证的新特征\n",
    "tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score', 'pred_rank']].to_csv(save_path + 'tst_lgb_ranker_feats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "# 单模型生成提交结果\n",
    "rank_results = tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results['click_article_id'] = rank_results['click_article_id'].astype(int)\n",
    "submit(rank_results, topk=5, model_name='lgb_ranker_cv5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之前只用itemcf召回结果提交线上为0.0780，这里用lgb提交线上为0.0919，还是有提升的，之后还是得从召回策略上入手，先提升召回的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.LGB分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型及参数的定义\n",
    "lgb_Classfication = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=500, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=50, random_state=2018, n_jobs= 16, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "if offline:\n",
    "    lgb_Classfication.fit(trn_user_item_feats_df_rank_model[lgb_cols], trn_user_item_feats_df_rank_model['label'],\n",
    "                    eval_set=[(val_user_item_feats_df_rank_model[lgb_cols], val_user_item_feats_df_rank_model['label'])], \n",
    "                    eval_metric=['auc', ],early_stopping_rounds=50, )\n",
    "else:\n",
    "    lgb_Classfication.fit(trn_user_item_feats_df_rank_model[lgb_cols], trn_user_item_feats_df_rank_model['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "tst_user_item_feats_df['pred_score'] = lgb_Classfication.predict_proba(tst_user_item_feats_df[lgb_cols])[:,1]\n",
    "\n",
    "# 将这里的排序结果保存一份，用户后面的模型融合\n",
    "tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']].to_csv(save_path + 'lgb_cls_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "rank_results = tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results['click_article_id'] = rank_results['click_article_id'].astype(int)\n",
    "submit(rank_results, topk=5, model_name='lgb_cls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.771702\tvalid_0's binary_logloss: 0.335874\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's auc: 0.77594\tvalid_0's binary_logloss: 0.334733\n",
      "[3]\tvalid_0's auc: 0.7839\tvalid_0's binary_logloss: 0.334269\n",
      "[4]\tvalid_0's auc: 0.785218\tvalid_0's binary_logloss: 0.333341\n",
      "[5]\tvalid_0's auc: 0.786996\tvalid_0's binary_logloss: 0.332269\n",
      "[6]\tvalid_0's auc: 0.787598\tvalid_0's binary_logloss: 0.331212\n",
      "[7]\tvalid_0's auc: 0.789114\tvalid_0's binary_logloss: 0.33065\n",
      "[8]\tvalid_0's auc: 0.789421\tvalid_0's binary_logloss: 0.329644\n",
      "[9]\tvalid_0's auc: 0.790224\tvalid_0's binary_logloss: 0.328985\n",
      "[10]\tvalid_0's auc: 0.790109\tvalid_0's binary_logloss: 0.328037\n",
      "[11]\tvalid_0's auc: 0.792497\tvalid_0's binary_logloss: 0.327393\n",
      "[12]\tvalid_0's auc: 0.792497\tvalid_0's binary_logloss: 0.326671\n",
      "[13]\tvalid_0's auc: 0.792446\tvalid_0's binary_logloss: 0.326087\n",
      "[14]\tvalid_0's auc: 0.792265\tvalid_0's binary_logloss: 0.325244\n",
      "[15]\tvalid_0's auc: 0.792401\tvalid_0's binary_logloss: 0.324347\n",
      "[16]\tvalid_0's auc: 0.793674\tvalid_0's binary_logloss: 0.323766\n",
      "[17]\tvalid_0's auc: 0.793731\tvalid_0's binary_logloss: 0.322912\n",
      "[18]\tvalid_0's auc: 0.793922\tvalid_0's binary_logloss: 0.322433\n",
      "[19]\tvalid_0's auc: 0.794122\tvalid_0's binary_logloss: 0.321789\n",
      "[20]\tvalid_0's auc: 0.793995\tvalid_0's binary_logloss: 0.320988\n",
      "[21]\tvalid_0's auc: 0.794485\tvalid_0's binary_logloss: 0.320788\n",
      "[22]\tvalid_0's auc: 0.795348\tvalid_0's binary_logloss: 0.320249\n",
      "[23]\tvalid_0's auc: 0.795369\tvalid_0's binary_logloss: 0.319795\n",
      "[24]\tvalid_0's auc: 0.795372\tvalid_0's binary_logloss: 0.319056\n",
      "[25]\tvalid_0's auc: 0.795436\tvalid_0's binary_logloss: 0.318321\n",
      "[26]\tvalid_0's auc: 0.796232\tvalid_0's binary_logloss: 0.317806\n",
      "[27]\tvalid_0's auc: 0.796105\tvalid_0's binary_logloss: 0.317111\n",
      "[28]\tvalid_0's auc: 0.796697\tvalid_0's binary_logloss: 0.316606\n",
      "[29]\tvalid_0's auc: 0.796651\tvalid_0's binary_logloss: 0.315921\n",
      "[30]\tvalid_0's auc: 0.796581\tvalid_0's binary_logloss: 0.315253\n",
      "[31]\tvalid_0's auc: 0.796493\tvalid_0's binary_logloss: 0.314618\n",
      "[32]\tvalid_0's auc: 0.797472\tvalid_0's binary_logloss: 0.31415\n",
      "[33]\tvalid_0's auc: 0.797499\tvalid_0's binary_logloss: 0.313502\n",
      "[34]\tvalid_0's auc: 0.797503\tvalid_0's binary_logloss: 0.312887\n",
      "[35]\tvalid_0's auc: 0.797645\tvalid_0's binary_logloss: 0.312395\n",
      "[36]\tvalid_0's auc: 0.797616\tvalid_0's binary_logloss: 0.311802\n",
      "[37]\tvalid_0's auc: 0.798327\tvalid_0's binary_logloss: 0.311495\n",
      "[38]\tvalid_0's auc: 0.798523\tvalid_0's binary_logloss: 0.311019\n",
      "[39]\tvalid_0's auc: 0.798442\tvalid_0's binary_logloss: 0.310449\n",
      "[40]\tvalid_0's auc: 0.799076\tvalid_0's binary_logloss: 0.309985\n",
      "[41]\tvalid_0's auc: 0.799209\tvalid_0's binary_logloss: 0.309595\n",
      "[42]\tvalid_0's auc: 0.799312\tvalid_0's binary_logloss: 0.309151\n",
      "[43]\tvalid_0's auc: 0.799212\tvalid_0's binary_logloss: 0.308608\n",
      "[44]\tvalid_0's auc: 0.799249\tvalid_0's binary_logloss: 0.308089\n",
      "[45]\tvalid_0's auc: 0.801458\tvalid_0's binary_logloss: 0.307541\n",
      "[46]\tvalid_0's auc: 0.801838\tvalid_0's binary_logloss: 0.307195\n",
      "[47]\tvalid_0's auc: 0.80174\tvalid_0's binary_logloss: 0.306694\n",
      "[48]\tvalid_0's auc: 0.801656\tvalid_0's binary_logloss: 0.3062\n",
      "[49]\tvalid_0's auc: 0.801939\tvalid_0's binary_logloss: 0.305837\n",
      "[50]\tvalid_0's auc: 0.802214\tvalid_0's binary_logloss: 0.305675\n",
      "[51]\tvalid_0's auc: 0.802383\tvalid_0's binary_logloss: 0.30553\n",
      "[52]\tvalid_0's auc: 0.804004\tvalid_0's binary_logloss: 0.305019\n",
      "[53]\tvalid_0's auc: 0.80435\tvalid_0's binary_logloss: 0.304621\n",
      "[54]\tvalid_0's auc: 0.804348\tvalid_0's binary_logloss: 0.304151\n",
      "[55]\tvalid_0's auc: 0.804445\tvalid_0's binary_logloss: 0.303684\n",
      "[56]\tvalid_0's auc: 0.804668\tvalid_0's binary_logloss: 0.303436\n",
      "[57]\tvalid_0's auc: 0.804871\tvalid_0's binary_logloss: 0.30297\n",
      "[58]\tvalid_0's auc: 0.805034\tvalid_0's binary_logloss: 0.30251\n",
      "[59]\tvalid_0's auc: 0.804996\tvalid_0's binary_logloss: 0.302181\n",
      "[60]\tvalid_0's auc: 0.804928\tvalid_0's binary_logloss: 0.301717\n",
      "[61]\tvalid_0's auc: 0.804817\tvalid_0's binary_logloss: 0.30131\n",
      "[62]\tvalid_0's auc: 0.804745\tvalid_0's binary_logloss: 0.300891\n",
      "[63]\tvalid_0's auc: 0.805147\tvalid_0's binary_logloss: 0.300549\n",
      "[64]\tvalid_0's auc: 0.805173\tvalid_0's binary_logloss: 0.300218\n",
      "[65]\tvalid_0's auc: 0.805221\tvalid_0's binary_logloss: 0.299797\n",
      "[66]\tvalid_0's auc: 0.805252\tvalid_0's binary_logloss: 0.299369\n",
      "[67]\tvalid_0's auc: 0.805654\tvalid_0's binary_logloss: 0.299016\n",
      "[68]\tvalid_0's auc: 0.805608\tvalid_0's binary_logloss: 0.298645\n",
      "[69]\tvalid_0's auc: 0.805745\tvalid_0's binary_logloss: 0.298454\n",
      "[70]\tvalid_0's auc: 0.805964\tvalid_0's binary_logloss: 0.298131\n",
      "[71]\tvalid_0's auc: 0.805933\tvalid_0's binary_logloss: 0.297841\n",
      "[72]\tvalid_0's auc: 0.806184\tvalid_0's binary_logloss: 0.297509\n",
      "[73]\tvalid_0's auc: 0.806542\tvalid_0's binary_logloss: 0.297225\n",
      "[74]\tvalid_0's auc: 0.8066\tvalid_0's binary_logloss: 0.296818\n",
      "[75]\tvalid_0's auc: 0.806796\tvalid_0's binary_logloss: 0.296511\n",
      "[76]\tvalid_0's auc: 0.806834\tvalid_0's binary_logloss: 0.296139\n",
      "[77]\tvalid_0's auc: 0.806827\tvalid_0's binary_logloss: 0.295761\n",
      "[78]\tvalid_0's auc: 0.807018\tvalid_0's binary_logloss: 0.295451\n",
      "[79]\tvalid_0's auc: 0.807175\tvalid_0's binary_logloss: 0.295172\n",
      "[80]\tvalid_0's auc: 0.807899\tvalid_0's binary_logloss: 0.294792\n",
      "[81]\tvalid_0's auc: 0.807931\tvalid_0's binary_logloss: 0.294572\n",
      "[82]\tvalid_0's auc: 0.808244\tvalid_0's binary_logloss: 0.294427\n",
      "[83]\tvalid_0's auc: 0.808387\tvalid_0's binary_logloss: 0.294153\n",
      "[84]\tvalid_0's auc: 0.80834\tvalid_0's binary_logloss: 0.293826\n",
      "[85]\tvalid_0's auc: 0.808387\tvalid_0's binary_logloss: 0.293485\n",
      "[86]\tvalid_0's auc: 0.808334\tvalid_0's binary_logloss: 0.293242\n",
      "[87]\tvalid_0's auc: 0.808261\tvalid_0's binary_logloss: 0.292929\n",
      "[88]\tvalid_0's auc: 0.80854\tvalid_0's binary_logloss: 0.292646\n",
      "[89]\tvalid_0's auc: 0.808565\tvalid_0's binary_logloss: 0.292384\n",
      "[90]\tvalid_0's auc: 0.808514\tvalid_0's binary_logloss: 0.292078\n",
      "[91]\tvalid_0's auc: 0.808484\tvalid_0's binary_logloss: 0.291781\n",
      "[92]\tvalid_0's auc: 0.808461\tvalid_0's binary_logloss: 0.291594\n",
      "[93]\tvalid_0's auc: 0.808402\tvalid_0's binary_logloss: 0.291304\n",
      "[94]\tvalid_0's auc: 0.808379\tvalid_0's binary_logloss: 0.29101\n",
      "[95]\tvalid_0's auc: 0.808406\tvalid_0's binary_logloss: 0.290708\n",
      "[96]\tvalid_0's auc: 0.808583\tvalid_0's binary_logloss: 0.290463\n",
      "[97]\tvalid_0's auc: 0.809094\tvalid_0's binary_logloss: 0.29026\n",
      "[98]\tvalid_0's auc: 0.809497\tvalid_0's binary_logloss: 0.290041\n",
      "[99]\tvalid_0's auc: 0.809457\tvalid_0's binary_logloss: 0.289779\n",
      "[100]\tvalid_0's auc: 0.809539\tvalid_0's binary_logloss: 0.289657\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.809539\tvalid_0's binary_logloss: 0.289657\n",
      "[1]\tvalid_0's auc: 0.777163\tvalid_0's binary_logloss: 0.33871\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's auc: 0.779483\tvalid_0's binary_logloss: 0.337532\n",
      "[3]\tvalid_0's auc: 0.786189\tvalid_0's binary_logloss: 0.337046\n",
      "[4]\tvalid_0's auc: 0.788506\tvalid_0's binary_logloss: 0.336083\n",
      "[5]\tvalid_0's auc: 0.791121\tvalid_0's binary_logloss: 0.334943\n",
      "[6]\tvalid_0's auc: 0.792288\tvalid_0's binary_logloss: 0.333838\n",
      "[7]\tvalid_0's auc: 0.792492\tvalid_0's binary_logloss: 0.33327\n",
      "[8]\tvalid_0's auc: 0.793377\tvalid_0's binary_logloss: 0.332161\n",
      "[9]\tvalid_0's auc: 0.794709\tvalid_0's binary_logloss: 0.33147\n",
      "[10]\tvalid_0's auc: 0.79482\tvalid_0's binary_logloss: 0.330478\n",
      "[11]\tvalid_0's auc: 0.796659\tvalid_0's binary_logloss: 0.329826\n",
      "[12]\tvalid_0's auc: 0.796992\tvalid_0's binary_logloss: 0.329065\n",
      "[13]\tvalid_0's auc: 0.797136\tvalid_0's binary_logloss: 0.328438\n",
      "[14]\tvalid_0's auc: 0.796839\tvalid_0's binary_logloss: 0.327554\n",
      "[15]\tvalid_0's auc: 0.796499\tvalid_0's binary_logloss: 0.326669\n",
      "[16]\tvalid_0's auc: 0.797844\tvalid_0's binary_logloss: 0.326087\n",
      "[17]\tvalid_0's auc: 0.797661\tvalid_0's binary_logloss: 0.325243\n",
      "[18]\tvalid_0's auc: 0.797864\tvalid_0's binary_logloss: 0.324749\n",
      "[19]\tvalid_0's auc: 0.79794\tvalid_0's binary_logloss: 0.324102\n",
      "[20]\tvalid_0's auc: 0.79781\tvalid_0's binary_logloss: 0.323298\n",
      "[21]\tvalid_0's auc: 0.799059\tvalid_0's binary_logloss: 0.32305\n",
      "[22]\tvalid_0's auc: 0.799683\tvalid_0's binary_logloss: 0.32251\n",
      "[23]\tvalid_0's auc: 0.799837\tvalid_0's binary_logloss: 0.322042\n",
      "[24]\tvalid_0's auc: 0.79972\tvalid_0's binary_logloss: 0.321278\n",
      "[25]\tvalid_0's auc: 0.799541\tvalid_0's binary_logloss: 0.32053\n",
      "[26]\tvalid_0's auc: 0.800082\tvalid_0's binary_logloss: 0.320019\n",
      "[27]\tvalid_0's auc: 0.80002\tvalid_0's binary_logloss: 0.319281\n",
      "[28]\tvalid_0's auc: 0.80032\tvalid_0's binary_logloss: 0.318773\n",
      "[29]\tvalid_0's auc: 0.800321\tvalid_0's binary_logloss: 0.318053\n",
      "[30]\tvalid_0's auc: 0.800426\tvalid_0's binary_logloss: 0.317304\n",
      "[31]\tvalid_0's auc: 0.800279\tvalid_0's binary_logloss: 0.316655\n",
      "[32]\tvalid_0's auc: 0.80083\tvalid_0's binary_logloss: 0.316216\n",
      "[33]\tvalid_0's auc: 0.800874\tvalid_0's binary_logloss: 0.31556\n",
      "[34]\tvalid_0's auc: 0.800836\tvalid_0's binary_logloss: 0.314915\n",
      "[35]\tvalid_0's auc: 0.801008\tvalid_0's binary_logloss: 0.314404\n",
      "[36]\tvalid_0's auc: 0.800973\tvalid_0's binary_logloss: 0.313786\n",
      "[37]\tvalid_0's auc: 0.801501\tvalid_0's binary_logloss: 0.313504\n",
      "[38]\tvalid_0's auc: 0.801805\tvalid_0's binary_logloss: 0.313006\n",
      "[39]\tvalid_0's auc: 0.80181\tvalid_0's binary_logloss: 0.312374\n",
      "[40]\tvalid_0's auc: 0.802317\tvalid_0's binary_logloss: 0.311895\n",
      "[41]\tvalid_0's auc: 0.802472\tvalid_0's binary_logloss: 0.311483\n",
      "[42]\tvalid_0's auc: 0.802567\tvalid_0's binary_logloss: 0.31103\n",
      "[43]\tvalid_0's auc: 0.802519\tvalid_0's binary_logloss: 0.310481\n",
      "[44]\tvalid_0's auc: 0.802527\tvalid_0's binary_logloss: 0.309944\n",
      "[45]\tvalid_0's auc: 0.804875\tvalid_0's binary_logloss: 0.309376\n",
      "[46]\tvalid_0's auc: 0.80523\tvalid_0's binary_logloss: 0.309022\n",
      "[47]\tvalid_0's auc: 0.805163\tvalid_0's binary_logloss: 0.308512\n",
      "[48]\tvalid_0's auc: 0.805546\tvalid_0's binary_logloss: 0.307989\n",
      "[49]\tvalid_0's auc: 0.805655\tvalid_0's binary_logloss: 0.307634\n",
      "[50]\tvalid_0's auc: 0.806006\tvalid_0's binary_logloss: 0.307458\n",
      "[51]\tvalid_0's auc: 0.806119\tvalid_0's binary_logloss: 0.307313\n",
      "[52]\tvalid_0's auc: 0.807627\tvalid_0's binary_logloss: 0.306792\n",
      "[53]\tvalid_0's auc: 0.807733\tvalid_0's binary_logloss: 0.306425\n",
      "[54]\tvalid_0's auc: 0.807672\tvalid_0's binary_logloss: 0.305947\n",
      "[55]\tvalid_0's auc: 0.807662\tvalid_0's binary_logloss: 0.305462\n",
      "[56]\tvalid_0's auc: 0.807884\tvalid_0's binary_logloss: 0.30522\n",
      "[57]\tvalid_0's auc: 0.808023\tvalid_0's binary_logloss: 0.30471\n",
      "[58]\tvalid_0's auc: 0.808055\tvalid_0's binary_logloss: 0.30422\n",
      "[59]\tvalid_0's auc: 0.80807\tvalid_0's binary_logloss: 0.303881\n",
      "[60]\tvalid_0's auc: 0.808095\tvalid_0's binary_logloss: 0.303433\n",
      "[61]\tvalid_0's auc: 0.808047\tvalid_0's binary_logloss: 0.303016\n",
      "[62]\tvalid_0's auc: 0.808023\tvalid_0's binary_logloss: 0.302587\n",
      "[63]\tvalid_0's auc: 0.808785\tvalid_0's binary_logloss: 0.302178\n",
      "[64]\tvalid_0's auc: 0.808773\tvalid_0's binary_logloss: 0.301839\n",
      "[65]\tvalid_0's auc: 0.809165\tvalid_0's binary_logloss: 0.301385\n",
      "[66]\tvalid_0's auc: 0.809178\tvalid_0's binary_logloss: 0.300937\n",
      "[67]\tvalid_0's auc: 0.809329\tvalid_0's binary_logloss: 0.30061\n",
      "[68]\tvalid_0's auc: 0.80933\tvalid_0's binary_logloss: 0.300203\n",
      "[69]\tvalid_0's auc: 0.809462\tvalid_0's binary_logloss: 0.300019\n",
      "[70]\tvalid_0's auc: 0.809593\tvalid_0's binary_logloss: 0.299713\n",
      "[71]\tvalid_0's auc: 0.80968\tvalid_0's binary_logloss: 0.299413\n",
      "[72]\tvalid_0's auc: 0.809678\tvalid_0's binary_logloss: 0.299128\n",
      "[73]\tvalid_0's auc: 0.810234\tvalid_0's binary_logloss: 0.298811\n",
      "[74]\tvalid_0's auc: 0.810269\tvalid_0's binary_logloss: 0.298426\n",
      "[75]\tvalid_0's auc: 0.810544\tvalid_0's binary_logloss: 0.298105\n",
      "[76]\tvalid_0's auc: 0.810564\tvalid_0's binary_logloss: 0.297728\n",
      "[77]\tvalid_0's auc: 0.810573\tvalid_0's binary_logloss: 0.297368\n",
      "[78]\tvalid_0's auc: 0.81057\tvalid_0's binary_logloss: 0.297076\n",
      "[79]\tvalid_0's auc: 0.810761\tvalid_0's binary_logloss: 0.296781\n",
      "[80]\tvalid_0's auc: 0.811414\tvalid_0's binary_logloss: 0.296398\n",
      "[81]\tvalid_0's auc: 0.811415\tvalid_0's binary_logloss: 0.296169\n",
      "[82]\tvalid_0's auc: 0.811977\tvalid_0's binary_logloss: 0.295972\n",
      "[83]\tvalid_0's auc: 0.81212\tvalid_0's binary_logloss: 0.295692\n",
      "[84]\tvalid_0's auc: 0.812124\tvalid_0's binary_logloss: 0.295353\n",
      "[85]\tvalid_0's auc: 0.812226\tvalid_0's binary_logloss: 0.295014\n",
      "[86]\tvalid_0's auc: 0.812315\tvalid_0's binary_logloss: 0.294746\n",
      "[87]\tvalid_0's auc: 0.812346\tvalid_0's binary_logloss: 0.294424\n",
      "[88]\tvalid_0's auc: 0.812418\tvalid_0's binary_logloss: 0.294159\n",
      "[89]\tvalid_0's auc: 0.812642\tvalid_0's binary_logloss: 0.293855\n",
      "[90]\tvalid_0's auc: 0.812608\tvalid_0's binary_logloss: 0.293544\n",
      "[91]\tvalid_0's auc: 0.812585\tvalid_0's binary_logloss: 0.293241\n",
      "[92]\tvalid_0's auc: 0.812658\tvalid_0's binary_logloss: 0.293039\n",
      "[93]\tvalid_0's auc: 0.812609\tvalid_0's binary_logloss: 0.292737\n",
      "[94]\tvalid_0's auc: 0.812645\tvalid_0's binary_logloss: 0.292433\n",
      "[95]\tvalid_0's auc: 0.81268\tvalid_0's binary_logloss: 0.29212\n",
      "[96]\tvalid_0's auc: 0.812926\tvalid_0's binary_logloss: 0.291872\n",
      "[97]\tvalid_0's auc: 0.813481\tvalid_0's binary_logloss: 0.291654\n",
      "[98]\tvalid_0's auc: 0.813869\tvalid_0's binary_logloss: 0.291434\n",
      "[99]\tvalid_0's auc: 0.813837\tvalid_0's binary_logloss: 0.291162\n",
      "[100]\tvalid_0's auc: 0.813921\tvalid_0's binary_logloss: 0.291045\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.813921\tvalid_0's binary_logloss: 0.291045\n",
      "[1]\tvalid_0's auc: 0.771492\tvalid_0's binary_logloss: 0.340108\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's auc: 0.773249\tvalid_0's binary_logloss: 0.33894\n",
      "[3]\tvalid_0's auc: 0.782016\tvalid_0's binary_logloss: 0.338472\n",
      "[4]\tvalid_0's auc: 0.784903\tvalid_0's binary_logloss: 0.33752\n",
      "[5]\tvalid_0's auc: 0.786777\tvalid_0's binary_logloss: 0.336417\n",
      "[6]\tvalid_0's auc: 0.787774\tvalid_0's binary_logloss: 0.335349\n",
      "[7]\tvalid_0's auc: 0.789144\tvalid_0's binary_logloss: 0.33479\n",
      "[8]\tvalid_0's auc: 0.789544\tvalid_0's binary_logloss: 0.333748\n",
      "[9]\tvalid_0's auc: 0.790708\tvalid_0's binary_logloss: 0.333069\n",
      "[10]\tvalid_0's auc: 0.790378\tvalid_0's binary_logloss: 0.332101\n",
      "[11]\tvalid_0's auc: 0.792798\tvalid_0's binary_logloss: 0.331438\n",
      "[12]\tvalid_0's auc: 0.793045\tvalid_0's binary_logloss: 0.330703\n",
      "[13]\tvalid_0's auc: 0.793012\tvalid_0's binary_logloss: 0.330094\n",
      "[14]\tvalid_0's auc: 0.792759\tvalid_0's binary_logloss: 0.329237\n",
      "[15]\tvalid_0's auc: 0.792702\tvalid_0's binary_logloss: 0.328353\n",
      "[16]\tvalid_0's auc: 0.794261\tvalid_0's binary_logloss: 0.327768\n",
      "[17]\tvalid_0's auc: 0.793954\tvalid_0's binary_logloss: 0.326947\n",
      "[18]\tvalid_0's auc: 0.794359\tvalid_0's binary_logloss: 0.326449\n",
      "[19]\tvalid_0's auc: 0.794528\tvalid_0's binary_logloss: 0.32579\n",
      "[20]\tvalid_0's auc: 0.794454\tvalid_0's binary_logloss: 0.324978\n",
      "[21]\tvalid_0's auc: 0.795511\tvalid_0's binary_logloss: 0.324752\n",
      "[22]\tvalid_0's auc: 0.796396\tvalid_0's binary_logloss: 0.324203\n",
      "[23]\tvalid_0's auc: 0.796585\tvalid_0's binary_logloss: 0.323737\n",
      "[24]\tvalid_0's auc: 0.796457\tvalid_0's binary_logloss: 0.32298\n",
      "[25]\tvalid_0's auc: 0.796276\tvalid_0's binary_logloss: 0.322242\n",
      "[26]\tvalid_0's auc: 0.796807\tvalid_0's binary_logloss: 0.321728\n",
      "[27]\tvalid_0's auc: 0.796747\tvalid_0's binary_logloss: 0.321016\n",
      "[28]\tvalid_0's auc: 0.797168\tvalid_0's binary_logloss: 0.320497\n",
      "[29]\tvalid_0's auc: 0.797153\tvalid_0's binary_logloss: 0.319813\n",
      "[30]\tvalid_0's auc: 0.797126\tvalid_0's binary_logloss: 0.319137\n",
      "[31]\tvalid_0's auc: 0.797061\tvalid_0's binary_logloss: 0.318482\n",
      "[32]\tvalid_0's auc: 0.8003\tvalid_0's binary_logloss: 0.317838\n",
      "[33]\tvalid_0's auc: 0.800203\tvalid_0's binary_logloss: 0.317195\n",
      "[34]\tvalid_0's auc: 0.800245\tvalid_0's binary_logloss: 0.316565\n",
      "[35]\tvalid_0's auc: 0.800379\tvalid_0's binary_logloss: 0.316069\n",
      "[36]\tvalid_0's auc: 0.800255\tvalid_0's binary_logloss: 0.315467\n",
      "[37]\tvalid_0's auc: 0.800897\tvalid_0's binary_logloss: 0.315168\n",
      "[38]\tvalid_0's auc: 0.801002\tvalid_0's binary_logloss: 0.314686\n",
      "[39]\tvalid_0's auc: 0.800991\tvalid_0's binary_logloss: 0.314098\n",
      "[40]\tvalid_0's auc: 0.801618\tvalid_0's binary_logloss: 0.313618\n",
      "[41]\tvalid_0's auc: 0.803135\tvalid_0's binary_logloss: 0.313196\n",
      "[42]\tvalid_0's auc: 0.803242\tvalid_0's binary_logloss: 0.312717\n",
      "[43]\tvalid_0's auc: 0.803218\tvalid_0's binary_logloss: 0.312169\n",
      "[44]\tvalid_0's auc: 0.803097\tvalid_0's binary_logloss: 0.311635\n",
      "[45]\tvalid_0's auc: 0.805224\tvalid_0's binary_logloss: 0.311053\n",
      "[46]\tvalid_0's auc: 0.805495\tvalid_0's binary_logloss: 0.310701\n",
      "[47]\tvalid_0's auc: 0.80536\tvalid_0's binary_logloss: 0.31019\n",
      "[48]\tvalid_0's auc: 0.805337\tvalid_0's binary_logloss: 0.309621\n",
      "[49]\tvalid_0's auc: 0.805613\tvalid_0's binary_logloss: 0.309251\n",
      "[50]\tvalid_0's auc: 0.805845\tvalid_0's binary_logloss: 0.309073\n",
      "[51]\tvalid_0's auc: 0.805887\tvalid_0's binary_logloss: 0.308929\n",
      "[52]\tvalid_0's auc: 0.807299\tvalid_0's binary_logloss: 0.308424\n",
      "[53]\tvalid_0's auc: 0.807517\tvalid_0's binary_logloss: 0.308042\n",
      "[54]\tvalid_0's auc: 0.807419\tvalid_0's binary_logloss: 0.307573\n",
      "[55]\tvalid_0's auc: 0.807389\tvalid_0's binary_logloss: 0.307098\n",
      "[56]\tvalid_0's auc: 0.807603\tvalid_0's binary_logloss: 0.306858\n",
      "[57]\tvalid_0's auc: 0.807425\tvalid_0's binary_logloss: 0.306406\n",
      "[58]\tvalid_0's auc: 0.807488\tvalid_0's binary_logloss: 0.305936\n",
      "[59]\tvalid_0's auc: 0.807502\tvalid_0's binary_logloss: 0.305583\n",
      "[60]\tvalid_0's auc: 0.807627\tvalid_0's binary_logloss: 0.30513\n",
      "[61]\tvalid_0's auc: 0.807524\tvalid_0's binary_logloss: 0.304719\n",
      "[62]\tvalid_0's auc: 0.807506\tvalid_0's binary_logloss: 0.304291\n",
      "[63]\tvalid_0's auc: 0.807945\tvalid_0's binary_logloss: 0.303915\n",
      "[64]\tvalid_0's auc: 0.807952\tvalid_0's binary_logloss: 0.303585\n",
      "[65]\tvalid_0's auc: 0.807993\tvalid_0's binary_logloss: 0.303168\n",
      "[66]\tvalid_0's auc: 0.808147\tvalid_0's binary_logloss: 0.302722\n",
      "[67]\tvalid_0's auc: 0.808356\tvalid_0's binary_logloss: 0.302384\n",
      "[68]\tvalid_0's auc: 0.808377\tvalid_0's binary_logloss: 0.302\n",
      "[69]\tvalid_0's auc: 0.80847\tvalid_0's binary_logloss: 0.301817\n",
      "[70]\tvalid_0's auc: 0.808628\tvalid_0's binary_logloss: 0.301501\n",
      "[71]\tvalid_0's auc: 0.808627\tvalid_0's binary_logloss: 0.301206\n",
      "[72]\tvalid_0's auc: 0.80863\tvalid_0's binary_logloss: 0.300922\n",
      "[73]\tvalid_0's auc: 0.80881\tvalid_0's binary_logloss: 0.300662\n",
      "[74]\tvalid_0's auc: 0.808835\tvalid_0's binary_logloss: 0.300289\n",
      "[75]\tvalid_0's auc: 0.809032\tvalid_0's binary_logloss: 0.299975\n",
      "[76]\tvalid_0's auc: 0.809072\tvalid_0's binary_logloss: 0.299614\n",
      "[77]\tvalid_0's auc: 0.809097\tvalid_0's binary_logloss: 0.299254\n",
      "[78]\tvalid_0's auc: 0.809056\tvalid_0's binary_logloss: 0.298974\n",
      "[79]\tvalid_0's auc: 0.809185\tvalid_0's binary_logloss: 0.298689\n",
      "[80]\tvalid_0's auc: 0.810202\tvalid_0's binary_logloss: 0.298264\n",
      "[81]\tvalid_0's auc: 0.810238\tvalid_0's binary_logloss: 0.298051\n",
      "[82]\tvalid_0's auc: 0.81064\tvalid_0's binary_logloss: 0.297868\n",
      "[83]\tvalid_0's auc: 0.810739\tvalid_0's binary_logloss: 0.297585\n",
      "[84]\tvalid_0's auc: 0.810662\tvalid_0's binary_logloss: 0.297259\n",
      "[85]\tvalid_0's auc: 0.810713\tvalid_0's binary_logloss: 0.296936\n",
      "[86]\tvalid_0's auc: 0.810723\tvalid_0's binary_logloss: 0.29666\n",
      "[87]\tvalid_0's auc: 0.810701\tvalid_0's binary_logloss: 0.296349\n",
      "[88]\tvalid_0's auc: 0.810853\tvalid_0's binary_logloss: 0.296067\n",
      "[89]\tvalid_0's auc: 0.810885\tvalid_0's binary_logloss: 0.295812\n",
      "[90]\tvalid_0's auc: 0.810852\tvalid_0's binary_logloss: 0.295505\n",
      "[91]\tvalid_0's auc: 0.810815\tvalid_0's binary_logloss: 0.295207\n",
      "[92]\tvalid_0's auc: 0.81082\tvalid_0's binary_logloss: 0.294998\n",
      "[93]\tvalid_0's auc: 0.810774\tvalid_0's binary_logloss: 0.294707\n",
      "[94]\tvalid_0's auc: 0.810725\tvalid_0's binary_logloss: 0.294411\n",
      "[95]\tvalid_0's auc: 0.810745\tvalid_0's binary_logloss: 0.294123\n",
      "[96]\tvalid_0's auc: 0.81093\tvalid_0's binary_logloss: 0.293873\n",
      "[97]\tvalid_0's auc: 0.811279\tvalid_0's binary_logloss: 0.293685\n",
      "[98]\tvalid_0's auc: 0.811676\tvalid_0's binary_logloss: 0.293476\n",
      "[99]\tvalid_0's auc: 0.811672\tvalid_0's binary_logloss: 0.293205\n",
      "[100]\tvalid_0's auc: 0.811756\tvalid_0's binary_logloss: 0.293085\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.811756\tvalid_0's binary_logloss: 0.293085\n",
      "[1]\tvalid_0's auc: 0.773483\tvalid_0's binary_logloss: 0.340285\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's auc: 0.776708\tvalid_0's binary_logloss: 0.339129\n",
      "[3]\tvalid_0's auc: 0.784747\tvalid_0's binary_logloss: 0.338633\n",
      "[4]\tvalid_0's auc: 0.787518\tvalid_0's binary_logloss: 0.337672\n",
      "[5]\tvalid_0's auc: 0.789251\tvalid_0's binary_logloss: 0.336576\n",
      "[6]\tvalid_0's auc: 0.790529\tvalid_0's binary_logloss: 0.335489\n",
      "[7]\tvalid_0's auc: 0.791355\tvalid_0's binary_logloss: 0.334927\n",
      "[8]\tvalid_0's auc: 0.791483\tvalid_0's binary_logloss: 0.333909\n",
      "[9]\tvalid_0's auc: 0.792214\tvalid_0's binary_logloss: 0.333238\n",
      "[10]\tvalid_0's auc: 0.79205\tvalid_0's binary_logloss: 0.332279\n",
      "[11]\tvalid_0's auc: 0.793953\tvalid_0's binary_logloss: 0.331635\n",
      "[12]\tvalid_0's auc: 0.794049\tvalid_0's binary_logloss: 0.330902\n",
      "[13]\tvalid_0's auc: 0.793781\tvalid_0's binary_logloss: 0.330312\n",
      "[14]\tvalid_0's auc: 0.793808\tvalid_0's binary_logloss: 0.32944\n",
      "[15]\tvalid_0's auc: 0.794062\tvalid_0's binary_logloss: 0.32852\n",
      "[16]\tvalid_0's auc: 0.795431\tvalid_0's binary_logloss: 0.327943\n",
      "[17]\tvalid_0's auc: 0.795202\tvalid_0's binary_logloss: 0.327105\n",
      "[18]\tvalid_0's auc: 0.795628\tvalid_0's binary_logloss: 0.326611\n",
      "[19]\tvalid_0's auc: 0.795632\tvalid_0's binary_logloss: 0.325969\n",
      "[20]\tvalid_0's auc: 0.795572\tvalid_0's binary_logloss: 0.32518\n",
      "[21]\tvalid_0's auc: 0.796417\tvalid_0's binary_logloss: 0.324958\n",
      "[22]\tvalid_0's auc: 0.797163\tvalid_0's binary_logloss: 0.324408\n",
      "[23]\tvalid_0's auc: 0.797243\tvalid_0's binary_logloss: 0.323946\n",
      "[24]\tvalid_0's auc: 0.79721\tvalid_0's binary_logloss: 0.323197\n",
      "[25]\tvalid_0's auc: 0.797173\tvalid_0's binary_logloss: 0.322453\n",
      "[26]\tvalid_0's auc: 0.797601\tvalid_0's binary_logloss: 0.321942\n",
      "[27]\tvalid_0's auc: 0.797452\tvalid_0's binary_logloss: 0.321233\n",
      "[28]\tvalid_0's auc: 0.79806\tvalid_0's binary_logloss: 0.320713\n",
      "[29]\tvalid_0's auc: 0.79809\tvalid_0's binary_logloss: 0.320023\n",
      "[30]\tvalid_0's auc: 0.798052\tvalid_0's binary_logloss: 0.319333\n",
      "[31]\tvalid_0's auc: 0.798087\tvalid_0's binary_logloss: 0.318685\n",
      "[32]\tvalid_0's auc: 0.799281\tvalid_0's binary_logloss: 0.318193\n",
      "[33]\tvalid_0's auc: 0.799328\tvalid_0's binary_logloss: 0.317543\n",
      "[34]\tvalid_0's auc: 0.799368\tvalid_0's binary_logloss: 0.316907\n",
      "[35]\tvalid_0's auc: 0.799579\tvalid_0's binary_logloss: 0.316398\n",
      "[36]\tvalid_0's auc: 0.799551\tvalid_0's binary_logloss: 0.315789\n",
      "[37]\tvalid_0's auc: 0.800264\tvalid_0's binary_logloss: 0.315483\n",
      "[38]\tvalid_0's auc: 0.800347\tvalid_0's binary_logloss: 0.315007\n",
      "[39]\tvalid_0's auc: 0.800339\tvalid_0's binary_logloss: 0.31442\n",
      "[40]\tvalid_0's auc: 0.800792\tvalid_0's binary_logloss: 0.313957\n",
      "[41]\tvalid_0's auc: 0.800851\tvalid_0's binary_logloss: 0.313583\n",
      "[42]\tvalid_0's auc: 0.801027\tvalid_0's binary_logloss: 0.313125\n",
      "[43]\tvalid_0's auc: 0.800957\tvalid_0's binary_logloss: 0.312588\n",
      "[44]\tvalid_0's auc: 0.800897\tvalid_0's binary_logloss: 0.312054\n",
      "[45]\tvalid_0's auc: 0.803194\tvalid_0's binary_logloss: 0.311483\n",
      "[46]\tvalid_0's auc: 0.803533\tvalid_0's binary_logloss: 0.311126\n",
      "[47]\tvalid_0's auc: 0.803491\tvalid_0's binary_logloss: 0.310619\n",
      "[48]\tvalid_0's auc: 0.803591\tvalid_0's binary_logloss: 0.310046\n",
      "[49]\tvalid_0's auc: 0.803951\tvalid_0's binary_logloss: 0.309677\n",
      "[50]\tvalid_0's auc: 0.804172\tvalid_0's binary_logloss: 0.309511\n",
      "[51]\tvalid_0's auc: 0.804295\tvalid_0's binary_logloss: 0.309362\n",
      "[52]\tvalid_0's auc: 0.805467\tvalid_0's binary_logloss: 0.308882\n",
      "[53]\tvalid_0's auc: 0.80569\tvalid_0's binary_logloss: 0.308506\n",
      "[54]\tvalid_0's auc: 0.805634\tvalid_0's binary_logloss: 0.308024\n",
      "[55]\tvalid_0's auc: 0.805583\tvalid_0's binary_logloss: 0.307553\n",
      "[56]\tvalid_0's auc: 0.8058\tvalid_0's binary_logloss: 0.307319\n",
      "[57]\tvalid_0's auc: 0.805751\tvalid_0's binary_logloss: 0.306819\n",
      "[58]\tvalid_0's auc: 0.806003\tvalid_0's binary_logloss: 0.306346\n",
      "[59]\tvalid_0's auc: 0.806269\tvalid_0's binary_logloss: 0.305977\n",
      "[60]\tvalid_0's auc: 0.806402\tvalid_0's binary_logloss: 0.30553\n",
      "[61]\tvalid_0's auc: 0.806241\tvalid_0's binary_logloss: 0.305107\n",
      "[62]\tvalid_0's auc: 0.806268\tvalid_0's binary_logloss: 0.304681\n",
      "[63]\tvalid_0's auc: 0.806564\tvalid_0's binary_logloss: 0.30434\n",
      "[64]\tvalid_0's auc: 0.806567\tvalid_0's binary_logloss: 0.304015\n",
      "[65]\tvalid_0's auc: 0.806711\tvalid_0's binary_logloss: 0.303593\n",
      "[66]\tvalid_0's auc: 0.806766\tvalid_0's binary_logloss: 0.303178\n",
      "[67]\tvalid_0's auc: 0.806899\tvalid_0's binary_logloss: 0.302849\n",
      "[68]\tvalid_0's auc: 0.806786\tvalid_0's binary_logloss: 0.302456\n",
      "[69]\tvalid_0's auc: 0.806905\tvalid_0's binary_logloss: 0.302271\n",
      "[70]\tvalid_0's auc: 0.807028\tvalid_0's binary_logloss: 0.301961\n",
      "[71]\tvalid_0's auc: 0.80702\tvalid_0's binary_logloss: 0.301665\n",
      "[72]\tvalid_0's auc: 0.807062\tvalid_0's binary_logloss: 0.301369\n",
      "[73]\tvalid_0's auc: 0.807205\tvalid_0's binary_logloss: 0.301111\n",
      "[74]\tvalid_0's auc: 0.807305\tvalid_0's binary_logloss: 0.300733\n",
      "[75]\tvalid_0's auc: 0.807562\tvalid_0's binary_logloss: 0.30041\n",
      "[76]\tvalid_0's auc: 0.80754\tvalid_0's binary_logloss: 0.300032\n",
      "[77]\tvalid_0's auc: 0.80757\tvalid_0's binary_logloss: 0.299633\n",
      "[78]\tvalid_0's auc: 0.807594\tvalid_0's binary_logloss: 0.299335\n",
      "[79]\tvalid_0's auc: 0.807761\tvalid_0's binary_logloss: 0.299055\n",
      "[80]\tvalid_0's auc: 0.808741\tvalid_0's binary_logloss: 0.298631\n",
      "[81]\tvalid_0's auc: 0.808746\tvalid_0's binary_logloss: 0.298406\n",
      "[82]\tvalid_0's auc: 0.809721\tvalid_0's binary_logloss: 0.298141\n",
      "[83]\tvalid_0's auc: 0.810017\tvalid_0's binary_logloss: 0.297834\n",
      "[84]\tvalid_0's auc: 0.810057\tvalid_0's binary_logloss: 0.297498\n",
      "[85]\tvalid_0's auc: 0.810114\tvalid_0's binary_logloss: 0.297156\n",
      "[86]\tvalid_0's auc: 0.810095\tvalid_0's binary_logloss: 0.296905\n",
      "[87]\tvalid_0's auc: 0.810151\tvalid_0's binary_logloss: 0.296588\n",
      "[88]\tvalid_0's auc: 0.810321\tvalid_0's binary_logloss: 0.296325\n",
      "[89]\tvalid_0's auc: 0.810278\tvalid_0's binary_logloss: 0.296087\n",
      "[90]\tvalid_0's auc: 0.810272\tvalid_0's binary_logloss: 0.295774\n",
      "[91]\tvalid_0's auc: 0.810257\tvalid_0's binary_logloss: 0.295471\n",
      "[92]\tvalid_0's auc: 0.810218\tvalid_0's binary_logloss: 0.295287\n",
      "[93]\tvalid_0's auc: 0.810188\tvalid_0's binary_logloss: 0.294983\n",
      "[94]\tvalid_0's auc: 0.810166\tvalid_0's binary_logloss: 0.294679\n",
      "[95]\tvalid_0's auc: 0.810178\tvalid_0's binary_logloss: 0.294369\n",
      "[96]\tvalid_0's auc: 0.810336\tvalid_0's binary_logloss: 0.294123\n",
      "[97]\tvalid_0's auc: 0.810636\tvalid_0's binary_logloss: 0.293953\n",
      "[98]\tvalid_0's auc: 0.810913\tvalid_0's binary_logloss: 0.293757\n",
      "[99]\tvalid_0's auc: 0.810902\tvalid_0's binary_logloss: 0.293488\n",
      "[100]\tvalid_0's auc: 0.811024\tvalid_0's binary_logloss: 0.29336\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.811024\tvalid_0's binary_logloss: 0.29336\n",
      "[1]\tvalid_0's auc: 0.774736\tvalid_0's binary_logloss: 0.341688\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's auc: 0.77764\tvalid_0's binary_logloss: 0.340512\n",
      "[3]\tvalid_0's auc: 0.783774\tvalid_0's binary_logloss: 0.340021\n",
      "[4]\tvalid_0's auc: 0.785332\tvalid_0's binary_logloss: 0.339053\n",
      "[5]\tvalid_0's auc: 0.787875\tvalid_0's binary_logloss: 0.337941\n",
      "[6]\tvalid_0's auc: 0.78853\tvalid_0's binary_logloss: 0.336855\n",
      "[7]\tvalid_0's auc: 0.789512\tvalid_0's binary_logloss: 0.336289\n",
      "[8]\tvalid_0's auc: 0.789809\tvalid_0's binary_logloss: 0.335256\n",
      "[9]\tvalid_0's auc: 0.790597\tvalid_0's binary_logloss: 0.33458\n",
      "[10]\tvalid_0's auc: 0.790713\tvalid_0's binary_logloss: 0.333603\n",
      "[11]\tvalid_0's auc: 0.792848\tvalid_0's binary_logloss: 0.332959\n",
      "[12]\tvalid_0's auc: 0.792846\tvalid_0's binary_logloss: 0.332218\n",
      "[13]\tvalid_0's auc: 0.793\tvalid_0's binary_logloss: 0.331606\n",
      "[14]\tvalid_0's auc: 0.792595\tvalid_0's binary_logloss: 0.330725\n",
      "[15]\tvalid_0's auc: 0.79246\tvalid_0's binary_logloss: 0.329846\n",
      "[16]\tvalid_0's auc: 0.793861\tvalid_0's binary_logloss: 0.329262\n",
      "[17]\tvalid_0's auc: 0.793517\tvalid_0's binary_logloss: 0.328424\n",
      "[18]\tvalid_0's auc: 0.79365\tvalid_0's binary_logloss: 0.327936\n",
      "[19]\tvalid_0's auc: 0.793655\tvalid_0's binary_logloss: 0.327297\n",
      "[20]\tvalid_0's auc: 0.793486\tvalid_0's binary_logloss: 0.326485\n",
      "[21]\tvalid_0's auc: 0.793964\tvalid_0's binary_logloss: 0.326289\n",
      "[22]\tvalid_0's auc: 0.794615\tvalid_0's binary_logloss: 0.325745\n",
      "[23]\tvalid_0's auc: 0.794709\tvalid_0's binary_logloss: 0.325287\n",
      "[24]\tvalid_0's auc: 0.794732\tvalid_0's binary_logloss: 0.324529\n",
      "[25]\tvalid_0's auc: 0.7946\tvalid_0's binary_logloss: 0.323777\n",
      "[26]\tvalid_0's auc: 0.795214\tvalid_0's binary_logloss: 0.323273\n",
      "[27]\tvalid_0's auc: 0.79503\tvalid_0's binary_logloss: 0.322567\n",
      "[28]\tvalid_0's auc: 0.795314\tvalid_0's binary_logloss: 0.322069\n",
      "[29]\tvalid_0's auc: 0.795145\tvalid_0's binary_logloss: 0.321385\n",
      "[30]\tvalid_0's auc: 0.795373\tvalid_0's binary_logloss: 0.320681\n",
      "[31]\tvalid_0's auc: 0.79519\tvalid_0's binary_logloss: 0.320039\n",
      "[32]\tvalid_0's auc: 0.797322\tvalid_0's binary_logloss: 0.319473\n",
      "[33]\tvalid_0's auc: 0.797324\tvalid_0's binary_logloss: 0.318829\n",
      "[34]\tvalid_0's auc: 0.797292\tvalid_0's binary_logloss: 0.318192\n",
      "[35]\tvalid_0's auc: 0.797469\tvalid_0's binary_logloss: 0.317685\n",
      "[36]\tvalid_0's auc: 0.79743\tvalid_0's binary_logloss: 0.317076\n",
      "[37]\tvalid_0's auc: 0.797808\tvalid_0's binary_logloss: 0.316796\n",
      "[38]\tvalid_0's auc: 0.797944\tvalid_0's binary_logloss: 0.316307\n",
      "[39]\tvalid_0's auc: 0.798006\tvalid_0's binary_logloss: 0.315681\n",
      "[40]\tvalid_0's auc: 0.798399\tvalid_0's binary_logloss: 0.315231\n",
      "[41]\tvalid_0's auc: 0.798643\tvalid_0's binary_logloss: 0.314821\n",
      "[42]\tvalid_0's auc: 0.798762\tvalid_0's binary_logloss: 0.314364\n",
      "[43]\tvalid_0's auc: 0.798696\tvalid_0's binary_logloss: 0.313808\n",
      "[44]\tvalid_0's auc: 0.798681\tvalid_0's binary_logloss: 0.313287\n",
      "[45]\tvalid_0's auc: 0.800611\tvalid_0's binary_logloss: 0.31274\n",
      "[46]\tvalid_0's auc: 0.801107\tvalid_0's binary_logloss: 0.312377\n",
      "[47]\tvalid_0's auc: 0.800963\tvalid_0's binary_logloss: 0.31187\n",
      "[48]\tvalid_0's auc: 0.80121\tvalid_0's binary_logloss: 0.31133\n",
      "[49]\tvalid_0's auc: 0.801538\tvalid_0's binary_logloss: 0.310962\n",
      "[50]\tvalid_0's auc: 0.801895\tvalid_0's binary_logloss: 0.310796\n",
      "[51]\tvalid_0's auc: 0.802007\tvalid_0's binary_logloss: 0.310653\n",
      "[52]\tvalid_0's auc: 0.8036\tvalid_0's binary_logloss: 0.310131\n",
      "[53]\tvalid_0's auc: 0.803746\tvalid_0's binary_logloss: 0.309761\n",
      "[54]\tvalid_0's auc: 0.803723\tvalid_0's binary_logloss: 0.30928\n",
      "[55]\tvalid_0's auc: 0.803706\tvalid_0's binary_logloss: 0.308803\n",
      "[56]\tvalid_0's auc: 0.804016\tvalid_0's binary_logloss: 0.308561\n",
      "[57]\tvalid_0's auc: 0.803896\tvalid_0's binary_logloss: 0.30811\n",
      "[58]\tvalid_0's auc: 0.803992\tvalid_0's binary_logloss: 0.307639\n",
      "[59]\tvalid_0's auc: 0.803969\tvalid_0's binary_logloss: 0.307304\n",
      "[60]\tvalid_0's auc: 0.804009\tvalid_0's binary_logloss: 0.306865\n",
      "[61]\tvalid_0's auc: 0.80393\tvalid_0's binary_logloss: 0.30645\n",
      "[62]\tvalid_0's auc: 0.803889\tvalid_0's binary_logloss: 0.306022\n",
      "[63]\tvalid_0's auc: 0.804022\tvalid_0's binary_logloss: 0.305702\n",
      "[64]\tvalid_0's auc: 0.804037\tvalid_0's binary_logloss: 0.305369\n",
      "[65]\tvalid_0's auc: 0.804043\tvalid_0's binary_logloss: 0.304961\n",
      "[66]\tvalid_0's auc: 0.804115\tvalid_0's binary_logloss: 0.304543\n",
      "[67]\tvalid_0's auc: 0.804286\tvalid_0's binary_logloss: 0.304224\n",
      "[68]\tvalid_0's auc: 0.804237\tvalid_0's binary_logloss: 0.303828\n",
      "[69]\tvalid_0's auc: 0.804417\tvalid_0's binary_logloss: 0.303641\n",
      "[70]\tvalid_0's auc: 0.804628\tvalid_0's binary_logloss: 0.303328\n",
      "[71]\tvalid_0's auc: 0.804614\tvalid_0's binary_logloss: 0.303036\n",
      "[72]\tvalid_0's auc: 0.804694\tvalid_0's binary_logloss: 0.302729\n",
      "[73]\tvalid_0's auc: 0.80488\tvalid_0's binary_logloss: 0.302476\n",
      "[74]\tvalid_0's auc: 0.804926\tvalid_0's binary_logloss: 0.302089\n",
      "[75]\tvalid_0's auc: 0.805156\tvalid_0's binary_logloss: 0.30178\n",
      "[76]\tvalid_0's auc: 0.805209\tvalid_0's binary_logloss: 0.301413\n",
      "[77]\tvalid_0's auc: 0.805305\tvalid_0's binary_logloss: 0.301049\n",
      "[78]\tvalid_0's auc: 0.805308\tvalid_0's binary_logloss: 0.30075\n",
      "[79]\tvalid_0's auc: 0.805391\tvalid_0's binary_logloss: 0.300482\n",
      "[80]\tvalid_0's auc: 0.806254\tvalid_0's binary_logloss: 0.30008\n",
      "[81]\tvalid_0's auc: 0.806261\tvalid_0's binary_logloss: 0.299846\n",
      "[82]\tvalid_0's auc: 0.807096\tvalid_0's binary_logloss: 0.299599\n",
      "[83]\tvalid_0's auc: 0.807187\tvalid_0's binary_logloss: 0.299324\n",
      "[84]\tvalid_0's auc: 0.807137\tvalid_0's binary_logloss: 0.298996\n",
      "[85]\tvalid_0's auc: 0.807142\tvalid_0's binary_logloss: 0.298663\n",
      "[86]\tvalid_0's auc: 0.807114\tvalid_0's binary_logloss: 0.298412\n",
      "[87]\tvalid_0's auc: 0.807173\tvalid_0's binary_logloss: 0.298084\n",
      "[88]\tvalid_0's auc: 0.807289\tvalid_0's binary_logloss: 0.297833\n",
      "[89]\tvalid_0's auc: 0.807384\tvalid_0's binary_logloss: 0.297554\n",
      "[90]\tvalid_0's auc: 0.807339\tvalid_0's binary_logloss: 0.297249\n",
      "[91]\tvalid_0's auc: 0.807304\tvalid_0's binary_logloss: 0.296951\n",
      "[92]\tvalid_0's auc: 0.807293\tvalid_0's binary_logloss: 0.296745\n",
      "[93]\tvalid_0's auc: 0.807239\tvalid_0's binary_logloss: 0.296451\n",
      "[94]\tvalid_0's auc: 0.807227\tvalid_0's binary_logloss: 0.296154\n",
      "[95]\tvalid_0's auc: 0.807316\tvalid_0's binary_logloss: 0.295841\n",
      "[96]\tvalid_0's auc: 0.807451\tvalid_0's binary_logloss: 0.295606\n",
      "[97]\tvalid_0's auc: 0.807872\tvalid_0's binary_logloss: 0.295419\n",
      "[98]\tvalid_0's auc: 0.80821\tvalid_0's binary_logloss: 0.295218\n",
      "[99]\tvalid_0's auc: 0.808186\tvalid_0's binary_logloss: 0.294954\n",
      "[100]\tvalid_0's auc: 0.808288\tvalid_0's binary_logloss: 0.294826\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.808288\tvalid_0's binary_logloss: 0.294826\n"
     ]
    }
   ],
   "source": [
    "# 五折交叉验证，这里的五折交叉是以用户为目标进行五折划分\n",
    "#  这一部分与前面的单独训练和验证是分开的\n",
    "def get_kfold_users(trn_df, n=5):\n",
    "    user_ids = trn_df['user_id'].unique()\n",
    "    user_set = [user_ids[i::n] for i in range(n)]\n",
    "    return user_set\n",
    "\n",
    "k_fold = 5\n",
    "trn_df = trn_user_item_feats_df_rank_model\n",
    "user_set = get_kfold_users(trn_df, n=k_fold)\n",
    "\n",
    "score_list = []\n",
    "score_df = trn_df[['user_id', 'click_article_id', 'label']]\n",
    "sub_preds = np.zeros(tst_user_item_feats_df_rank_model.shape[0])\n",
    "\n",
    "# 五折交叉验证，并将中间结果保存用于staking\n",
    "for n_fold, valid_user in enumerate(user_set):\n",
    "    train_idx = trn_df[~trn_df['user_id'].isin(valid_user)] # add slide user\n",
    "    valid_idx = trn_df[trn_df['user_id'].isin(valid_user)]\n",
    "    \n",
    "    # 模型及参数的定义\n",
    "    lgb_Classfication = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=100, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=50, random_state=2018, n_jobs= 16, verbose=10)  \n",
    "    # 训练模型\n",
    "    lgb_Classfication.fit(train_idx[lgb_cols], train_idx['label'],eval_set=[(valid_idx[lgb_cols], valid_idx['label'])], \n",
    "                          eval_metric=['auc', ],early_stopping_rounds=50, )\n",
    "    \n",
    "    # 预测验证集结果\n",
    "    valid_idx['pred_score'] = lgb_Classfication.predict_proba(valid_idx[lgb_cols], \n",
    "                                                              num_iteration=lgb_Classfication.best_iteration_)[:,1]\n",
    "    \n",
    "    # 对输出结果进行归一化 分类模型输出的值本身就是一个概率值不需要进行归一化\n",
    "    # valid_idx['pred_score'] = valid_idx[['pred_score']].transform(lambda x: norm_sim(x))\n",
    "    \n",
    "    valid_idx.sort_values(by=['user_id', 'pred_score'])\n",
    "    valid_idx['pred_rank'] = valid_idx.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    \n",
    "    # 将验证集的预测结果放到一个列表中，后面进行拼接\n",
    "    score_list.append(valid_idx[['user_id', 'click_article_id', 'pred_score', 'pred_rank']])\n",
    "    \n",
    "    # 如果是线上测试，需要计算每次交叉验证的结果相加，最后求平均\n",
    "    if not offline:\n",
    "        sub_preds += lgb_Classfication.predict_proba(tst_user_item_feats_df_rank_model[lgb_cols], \n",
    "                                                     num_iteration=lgb_Classfication.best_iteration_)[:,1]\n",
    "    \n",
    "score_df_ = pd.concat(score_list, axis=0)\n",
    "score_df = score_df.merge(score_df_, how='left', on=['user_id', 'click_article_id'])\n",
    "# 保存训练集交叉验证产生的新特征\n",
    "score_df[['user_id', 'click_article_id', 'pred_score', 'pred_rank', 'label']].to_csv(save_path + 'trn_lgb_cls_feats.csv', index=False)\n",
    "    \n",
    "# 测试集的预测结果，多次交叉验证求平均,将预测的score和对应的rank特征保存，可以用于后面的staking，这里还可以构造其他更多的特征\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = sub_preds / k_fold\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = tst_user_item_feats_df_rank_model['pred_score'].transform(lambda x: norm_sim(x))\n",
    "tst_user_item_feats_df_rank_model.sort_values(by=['user_id', 'pred_score'])\n",
    "tst_user_item_feats_df_rank_model['pred_rank'] = tst_user_item_feats_df_rank_model.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "\n",
    "# 保存测试集交叉验证的新特征\n",
    "tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score', 'pred_rank']].to_csv(save_path + 'tst_lgb_cls_feats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "rank_results = tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results['click_article_id'] = rank_results['click_article_id'].astype(int)\n",
    "submit(rank_results, topk=5, model_name='lgb_cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.DIN模型\n",
    "\n",
    "DIN的应用场景是阿里巴巴的电商广告推荐，在计算一个用户$u$是否点击一个广告$a$时，模型的输入特征分为两部分：用户$u$的特征组，候选广告$a$的特征组。用户和广告都含有两个非常重要的特征——商品id和商铺id。用户特征里的商品id是一个序列，代表用户曾经点击过的商铺集合，商铺id同理；而广告特征里的商品id和商铺id就是广告对应的商品id和商铺id。\n",
    "\n",
    "在原来的基础模型中，用户特征组中的商品序列和商铺序列经过简单的平均池化操作后就进入上层神经网络进行下一步训练，序列中的商铺既没有区分重要程度，也和广告特征中的商品id没有关系。而事实上，广告特征和用户特征的关联程度是非常强的。从模型的角度看，在建模过程中国投给不同特征的“注意力”理应有所不同，且注意力得分的计算理应与广告特征有关。\n",
    "\n",
    "将上述“注意力”的思想反映到模型中就是：利用候选商品和历史行为商品之间的相关性计算一个权重，这个权重就代表了“注意力”的强弱，注意力部分的形式化表达如下式：\n",
    "$$V_u=f(V_a)=\\sum\\limits_{i=1}^N w_iV_i=\\sum\\limits_{i=1}^N g(V_i, V_a)V_i$$\n",
    "\n",
    "其中，$V_u$是用户的Embedding向量，$V_a$是候选广告商品的Embedding向量，$V_i$是用户$u$的第$i$次行为的Embedding向量。这里用户的行为就是浏览商品或店铺，因此行为的Embedding向量就是那次浏览的商铺或者店铺的Embedding向量。\n",
    "\n",
    "加入了注意力机制后，$V_u$从过去$V_i$的加和变成了$V_i$的加权和，其权重$w_i$由$V_i$和$V_a$的关系决定，即上式中的$g(V_i,V_a)$，即注意力得分。$g(V_i,V_a)$的形式采用了注意力激活单元，其本质是个小的神经网络，其输入层是两个Embedding向量，经过元素减操作后，与原Embedding向量一同连接后形成全连接层的输入，最后通过单神经元输出层生成注意力得分。\n",
    "\n",
    "需要留意的是商铺id只跟历史行为中的商铺id序列发生作用，商品id只跟用户的商品id序列发生作用，因为注意力的轻重应该由同类信息的相关性决定。\n",
    "\n",
    "##### 1.4.1.用户的历史点击行为列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if offline:\n",
    "    all_data = pd.read_csv('./data_raw/train_click_log.csv')\n",
    "else:\n",
    "    trn_data = pd.read_csv('./data_raw/train_click_log.csv')\n",
    "    tst_data = pd.read_csv('./data_raw/testA_click_log.csv')\n",
    "    all_data = trn_data.append(tst_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_click =all_data[['user_id', 'click_article_id']].groupby('user_id').agg({list}).reset_index()\n",
    "his_behavior_df = pd.DataFrame()\n",
    "his_behavior_df['user_id'] = hist_click['user_id']\n",
    "his_behavior_df['hist_click_article_id'] = hist_click['click_article_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把之前构造的用户物品特征拷贝一份\n",
    "trn_user_item_feats_df_din_model = trn_user_item_feats_df.copy()\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df_din_model = val_user_item_feats_df.copy()\n",
    "else: \n",
    "    val_user_item_feats_df_din_model = None\n",
    "    \n",
    "tst_user_item_feats_df_din_model = tst_user_item_feats_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将用户的历史点击行为特征接上\n",
    "trn_user_item_feats_df_din_model = trn_user_item_feats_df_din_model.merge(his_behavior_df, on='user_id')\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df_din_model = val_user_item_feats_df_din_model.merge(his_behavior_df, on='user_id')\n",
    "else:\n",
    "    val_user_item_feats_df_din_model = None\n",
    "\n",
    "tst_user_item_feats_df_din_model = tst_user_item_feats_df_din_model.merge(his_behavior_df, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>sim0</th>\n",
       "      <th>time_diff0</th>\n",
       "      <th>word_diff0</th>\n",
       "      <th>sim_max</th>\n",
       "      <th>sim_min</th>\n",
       "      <th>sim_sum</th>\n",
       "      <th>sim_mean</th>\n",
       "      <th>score</th>\n",
       "      <th>...</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "      <th>user_time_hob1</th>\n",
       "      <th>user_time_hob2</th>\n",
       "      <th>words_hbo</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>words_count</th>\n",
       "      <th>is_cat_hob</th>\n",
       "      <th>hist_click_article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>324426</td>\n",
       "      <td>0.181872</td>\n",
       "      <td>17249000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.181872</td>\n",
       "      <td>0.181872</td>\n",
       "      <td>0.181872</td>\n",
       "      <td>0.181872</td>\n",
       "      <td>0.330990</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343715</td>\n",
       "      <td>0.992865</td>\n",
       "      <td>266.0</td>\n",
       "      <td>434</td>\n",
       "      <td>1508167842000</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>[30760, 157507]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>79851</td>\n",
       "      <td>0.180059</td>\n",
       "      <td>20303000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.180059</td>\n",
       "      <td>0.180059</td>\n",
       "      <td>0.180059</td>\n",
       "      <td>0.180059</td>\n",
       "      <td>0.360521</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343715</td>\n",
       "      <td>0.992865</td>\n",
       "      <td>266.0</td>\n",
       "      <td>173</td>\n",
       "      <td>1508164788000</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>[30760, 157507]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>161082</td>\n",
       "      <td>0.086313</td>\n",
       "      <td>18190916000</td>\n",
       "      <td>128</td>\n",
       "      <td>0.086313</td>\n",
       "      <td>0.086313</td>\n",
       "      <td>0.086313</td>\n",
       "      <td>0.086313</td>\n",
       "      <td>0.455943</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343715</td>\n",
       "      <td>0.992865</td>\n",
       "      <td>266.0</td>\n",
       "      <td>281</td>\n",
       "      <td>1489994175000</td>\n",
       "      <td>290</td>\n",
       "      <td>0</td>\n",
       "      <td>[30760, 157507]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>180441</td>\n",
       "      <td>0.256028</td>\n",
       "      <td>22730277000</td>\n",
       "      <td>36</td>\n",
       "      <td>0.256028</td>\n",
       "      <td>0.256028</td>\n",
       "      <td>0.256028</td>\n",
       "      <td>0.256028</td>\n",
       "      <td>0.492409</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343715</td>\n",
       "      <td>0.992865</td>\n",
       "      <td>266.0</td>\n",
       "      <td>301</td>\n",
       "      <td>1485454814000</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>[30760, 157507]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>50644</td>\n",
       "      <td>0.255950</td>\n",
       "      <td>2772000</td>\n",
       "      <td>26</td>\n",
       "      <td>0.255950</td>\n",
       "      <td>0.255950</td>\n",
       "      <td>0.255950</td>\n",
       "      <td>0.255950</td>\n",
       "      <td>0.577445</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343715</td>\n",
       "      <td>0.992865</td>\n",
       "      <td>266.0</td>\n",
       "      <td>99</td>\n",
       "      <td>1508182319000</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>[30760, 157507]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  click_article_id      sim0   time_diff0  word_diff0   sim_max  \\\n",
       "0        0            324426  0.181872     17249000          12  0.181872   \n",
       "1        0             79851  0.180059     20303000          21  0.180059   \n",
       "2        0            161082  0.086313  18190916000         128  0.086313   \n",
       "3        0            180441  0.256028  22730277000          36  0.256028   \n",
       "4        0             50644  0.255950      2772000          26  0.255950   \n",
       "\n",
       "    sim_min   sim_sum  sim_mean     score  ...  click_region  \\\n",
       "0  0.181872  0.181872  0.181872  0.330990  ...            25   \n",
       "1  0.180059  0.180059  0.180059  0.360521  ...            25   \n",
       "2  0.086313  0.086313  0.086313  0.455943  ...            25   \n",
       "3  0.256028  0.256028  0.256028  0.492409  ...            25   \n",
       "4  0.255950  0.255950  0.255950  0.577445  ...            25   \n",
       "\n",
       "   click_referrer_type  user_time_hob1  user_time_hob2  words_hbo  \\\n",
       "0                    2        0.343715        0.992865      266.0   \n",
       "1                    2        0.343715        0.992865      266.0   \n",
       "2                    2        0.343715        0.992865      266.0   \n",
       "3                    2        0.343715        0.992865      266.0   \n",
       "4                    2        0.343715        0.992865      266.0   \n",
       "\n",
       "   category_id  created_at_ts  words_count  is_cat_hob  hist_click_article_id  \n",
       "0          434  1508167842000          150           0        [30760, 157507]  \n",
       "1          173  1508164788000          183           0        [30760, 157507]  \n",
       "2          281  1489994175000          290           0        [30760, 157507]  \n",
       "3          301  1485454814000          198           0        [30760, 157507]  \n",
       "4           99  1508182319000          188           0        [30760, 157507]  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_user_item_feats_df_din_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.2.调用deepctr库中的DIN模型\n",
    "\n",
    "deepctr的函数原型如下：\n",
    "\n",
    "> def DIN(dnn_feature_columns, history_feature_list, dnn_use_bn=False,\n",
    ">     dnn_hidden_units=(200, 80), dnn_activation='relu', att_hidden_size=(80, 40), att_activation=\"dice\",\n",
    ">    att_weight_normalization=False, l2_reg_dnn=0, l2_reg_embedding=1e-6, dnn_dropout=0, seed=1024,\n",
    ">     task='binary'):\n",
    ">\n",
    "> * dnn_feature_columns: 特征列， 包含数据所有特征的列表\n",
    "> * history_feature_list: 用户历史行为列， 反应用户历史行为的特征的列表\n",
    "> * dnn_use_bn: 是否使用BatchNormalization\n",
    "> * dnn_hidden_units: 全连接层网络的层数和每一层神经元的个数， 一个列表或者元组\n",
    "> * dnn_activation_relu: 全连接网络的激活单元类型\n",
    "> * att_hidden_size: 注意力层的全连接网络的层数和每一层神经元的个数\n",
    "> * att_activation: 注意力层的激活单元类型\n",
    "> * att_weight_normalization: 是否归一化注意力得分\n",
    "> * l2_reg_dnn: 全连接网络的正则化系数\n",
    "> * l2_reg_embedding: embedding向量的正则化稀疏\n",
    "> * dnn_dropout: 全连接网络的神经元的失活概率\n",
    "> * task: 任务， 可以是分类， 也可是是回归\n",
    "\n",
    "在具体使用的时候， 我们必须要传入特征列和历史行为列， 但是再传入之前， 我们需要进行一下特征列的预处理。具体如下：\n",
    "\n",
    "* 首先处理数据集得到数据，由于我们是基于用户过去的行为去预测用户是否点击当前文章，所以我们需要把数据的特征列划分成数值型特征，离散型特征和历史行为特征列三部分，对于每一部分，DIN模型的处理会有不同：\n",
    "   1. 对于离散型特征， 在我们的数据集中就是那些类别型的特征， 比如`user_id`， 这种类别型特征首先要经过embedding处理得到每个特征的低维稠密型表示。既然要经过embedding， 那么就需要为每一列的类别特征的取值建立一个字典，并指明embedding维度， 所以在使用deepctr的DIN模型准备数据的时候， 我们需要通过`SparseFeat()`函数指明这些类别型特征, 这个函数的传入参数就是列名， 列的唯一取值(建立字典用)和embedding维度。\n",
    "   2. 对于用户历史行为特征列，比如文章id，文章的类别等这种，同样的需要先经过embedding处理，只不过和上面不一样的地方是，对于这种特征在得到每个特征的embedding表示之后，还**需要通过一个Attention_layer计算用户的历史行为和当前候选文章的相关性**以此得到当前用户的embedding向量，这个向量就可以**基于当前的候选文章与用户过去点击过得历史文章的相似性的程度来反应用户的兴趣**， 并且随着用户的不同的历史点击来变化，去动态的模拟用户兴趣的变化过程。\n",
    "      \n",
    "      这类特征对于每个用户都是一个历史行为序列，对于每个用户，历史行为序列长度会不一样，可能有的用户点击的历史文章多，有的点击的历史文章少，所以我们还需要把这个长度统一起来， 在为DIN模型准备数据的时候， 我们首先要通过`SparseFeat()`函数指明这些类别型特征， 然后还需要通过`VarLenSparseFeat()`函数再进行序列填充， 使得每个用户的历史序列一样长， 所以这个函数参数中会有个maxlen，来指明序列的最大长度是多少。\n",
    "   3. 对于连续型特征列， 我们只需要用`DenseFeat()`函数来指明列名和维度即可。\n",
    "   \n",
    "* 处理完特征列之后， 我们把相应的数据与列进行对应，就得到了最后的数据。\n",
    "\n",
    "下面的逻辑是这样：首先写一个数据准备函数得到数据和特征列， 然后就是建立DIN模型并训练， 最后基于模型进行测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入deepctr\n",
    "from deepctr.models import DIN\n",
    "from deepctr.feature_column import SparseFeat, VarLenSparseFeat, DenseFeat, get_feature_names\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import * \n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据准备函数\n",
    "def get_din_feats_columns(df, dense_fea, sparse_fea, behavior_fea, his_behavior_fea, emb_dim=32, max_len=100):\n",
    "    \"\"\"\n",
    "    数据准备函数:\n",
    "    df: 数据集\n",
    "    dense_fea: 数值型特征列\n",
    "    sparse_fea: 离散型特征列\n",
    "    behavior_fea: 用户的候选行为特征列\n",
    "    his_behavior_fea: 用户的历史行为特征列\n",
    "    embedding_dim: embedding的维度， 这里为了简单， 统一把离散型特征列采用一样的隐向量维度（若不一样后续需要sequence padding？）\n",
    "    max_len: 用户序列的最大长度\n",
    "    返回字典形式的数据x，特征列dnn_feature_columns\n",
    "    \"\"\"\n",
    "    \n",
    "    sparse_feature_columns = [SparseFeat(feat, vocabulary_size=df[feat].nunique() + 1, embedding_dim=emb_dim) for feat in sparse_fea]\n",
    "    \n",
    "    dense_feature_columns = [DenseFeat(feat, 1, ) for feat in dense_fea]\n",
    "    \n",
    "    var_feature_columns = [VarLenSparseFeat(SparseFeat(feat, vocabulary_size=df['click_article_id'].nunique() + 1,\n",
    "                                    embedding_dim=emb_dim, embedding_name='click_article_id'), maxlen=max_len) for feat in hist_behavior_fea]\n",
    "    \n",
    "    dnn_feature_columns = sparse_feature_columns + dense_feature_columns + var_feature_columns\n",
    "    \n",
    "    # 建立x, x是一个字典的形式，x是数据\n",
    "    x = {}\n",
    "    for name in get_feature_names(dnn_feature_columns):\n",
    "        if name in his_behavior_fea:\n",
    "            # 这是历史行为序列\n",
    "            his_list = [l for l in df[name]]\n",
    "            x[name] = pad_sequences(his_list, maxlen=max_len, padding='post')      # 二维数组\n",
    "        else:\n",
    "            x[name] = df[name].values\n",
    "    \n",
    "    return x, dnn_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把特征分开\n",
    "sparse_fea = ['user_id', 'click_article_id', 'category_id', 'click_environment', 'click_deviceGroup', \n",
    "              'click_os', 'click_country', 'click_region', 'click_referrer_type', 'is_cat_hob']\n",
    "\n",
    "behavior_fea = ['click_article_id']\n",
    "\n",
    "hist_behavior_fea = ['hist_click_article_id']\n",
    "\n",
    "dense_fea = ['sim0', 'time_diff0', 'word_diff0', 'sim_max', 'sim_min', 'sim_sum', 'sim_mean', 'score',\n",
    "             'rank','click_size','time_diff_mean','active_level','user_time_hob1','user_time_hob2',\n",
    "             'words_hbo','words_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense特征进行归一化, 神经网络训练都需要将数值进行归一化处理\n",
    "mm = MinMaxScaler()\n",
    "\n",
    "# 下面是做一些特殊处理，当在其他的地方出现无效值的时候，不处理无法进行归一化，刚开始可以先把他注释掉，在运行了下面的代码\n",
    "# 之后如果发现报错，应该先去想办法处理如何不出现inf之类的值\n",
    "# trn_user_item_feats_df_din_model.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "# tst_user_item_feats_df_din_model.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "for feat in dense_fea:\n",
    "    trn_user_item_feats_df_din_model[feat] = mm.fit_transform(trn_user_item_feats_df_din_model[[feat]])\n",
    "    \n",
    "    if val_user_item_feats_df_din_model is not None:\n",
    "        val_user_item_feats_df_din_model[feat] = mm.fit_transform(val_user_item_feats_df_din_model[[feat]])\n",
    "    \n",
    "    tst_user_item_feats_df_din_model[feat] = mm.fit_transform(tst_user_item_feats_df_din_model[[feat]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备训练数据\n",
    "x_trn, dnn_feature_columns = get_din_feats_columns(trn_user_item_feats_df_din_model, dense_fea, \n",
    "                                               sparse_fea, behavior_fea, hist_behavior_fea, max_len=50)\n",
    "y_trn = trn_user_item_feats_df_din_model['label'].values\n",
    "\n",
    "if offline:\n",
    "    # 准备验证数据\n",
    "    x_val, dnn_feature_columns = get_din_feats_columns(val_user_item_feats_df_din_model, dense_fea, \n",
    "                                                   sparse_fea, behavior_fea, hist_behavior_fea, max_len=50)\n",
    "    y_val = val_user_item_feats_df_din_model['label'].values\n",
    "    \n",
    "dense_fea = [x for x in dense_fea if x != 'label']\n",
    "x_tst, dnn_feature_columns = get_din_feats_columns(tst_user_item_feats_df_din_model, dense_fea, \n",
    "                                               sparse_fea, behavior_fea, hist_behavior_fea, max_len=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_id (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_article_id (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "category_id (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_environment (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_deviceGroup (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_os (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_country (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_region (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_referrer_type (InputLayer [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "is_cat_hob (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_user_id (Embedding)  (None, 1, 32)        1600032     user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sparse_seq_emb_hist_click_artic multiple             489920      click_article_id[0][0]           \n",
      "                                                                 hist_click_article_id[0][0]      \n",
      "                                                                 click_article_id[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_category_id (Embeddi (None, 1, 32)        7680        category_id[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_click_environment (E (None, 1, 32)        128         click_environment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_click_deviceGroup (E (None, 1, 32)        160         click_deviceGroup[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_click_os (Embedding) (None, 1, 32)        288         click_os[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_click_country (Embed (None, 1, 32)        384         click_country[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_click_region (Embedd (None, 1, 32)        928         click_region[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_click_referrer_type  (None, 1, 32)        256         click_referrer_type[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_is_cat_hob (Embeddin (None, 1, 32)        64          is_cat_hob[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "no_mask (NoMask)                (None, 1, 32)        0           sparse_emb_user_id[0][0]         \n",
      "                                                                 sparse_seq_emb_hist_click_article\n",
      "                                                                 sparse_emb_category_id[0][0]     \n",
      "                                                                 sparse_emb_click_environment[0][0\n",
      "                                                                 sparse_emb_click_deviceGroup[0][0\n",
      "                                                                 sparse_emb_click_os[0][0]        \n",
      "                                                                 sparse_emb_click_country[0][0]   \n",
      "                                                                 sparse_emb_click_region[0][0]    \n",
      "                                                                 sparse_emb_click_referrer_type[0]\n",
      "                                                                 sparse_emb_is_cat_hob[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "hist_click_article_id (InputLay [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1, 320)       0           no_mask[0][0]                    \n",
      "                                                                 no_mask[1][0]                    \n",
      "                                                                 no_mask[2][0]                    \n",
      "                                                                 no_mask[3][0]                    \n",
      "                                                                 no_mask[4][0]                    \n",
      "                                                                 no_mask[5][0]                    \n",
      "                                                                 no_mask[6][0]                    \n",
      "                                                                 no_mask[7][0]                    \n",
      "                                                                 no_mask[8][0]                    \n",
      "                                                                 no_mask[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "no_mask_1 (NoMask)              (None, 1, 320)       0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_sequence_pooling_laye (None, 1, 32)        13961       sparse_seq_emb_hist_click_article\n",
      "                                                                 sparse_seq_emb_hist_click_article\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 352)       0           no_mask_1[0][0]                  \n",
      "                                                                 attention_sequence_pooling_layer[\n",
      "__________________________________________________________________________________________________\n",
      "sim0 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_diff0 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "word_diff0 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sim_max (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sim_min (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sim_sum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sim_mean (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "score (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rank (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_size (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_diff_mean (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "active_level (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_time_hob1 (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_time_hob2 (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "words_hbo (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "words_count (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 352)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "no_mask_3 (NoMask)              (None, 1)            0           sim0[0][0]                       \n",
      "                                                                 time_diff0[0][0]                 \n",
      "                                                                 word_diff0[0][0]                 \n",
      "                                                                 sim_max[0][0]                    \n",
      "                                                                 sim_min[0][0]                    \n",
      "                                                                 sim_sum[0][0]                    \n",
      "                                                                 sim_mean[0][0]                   \n",
      "                                                                 score[0][0]                      \n",
      "                                                                 rank[0][0]                       \n",
      "                                                                 click_size[0][0]                 \n",
      "                                                                 time_diff_mean[0][0]             \n",
      "                                                                 active_level[0][0]               \n",
      "                                                                 user_time_hob1[0][0]             \n",
      "                                                                 user_time_hob2[0][0]             \n",
      "                                                                 words_hbo[0][0]                  \n",
      "                                                                 words_count[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "no_mask_2 (NoMask)              (None, 352)          0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 16)           0           no_mask_3[0][0]                  \n",
      "                                                                 no_mask_3[1][0]                  \n",
      "                                                                 no_mask_3[2][0]                  \n",
      "                                                                 no_mask_3[3][0]                  \n",
      "                                                                 no_mask_3[4][0]                  \n",
      "                                                                 no_mask_3[5][0]                  \n",
      "                                                                 no_mask_3[6][0]                  \n",
      "                                                                 no_mask_3[7][0]                  \n",
      "                                                                 no_mask_3[8][0]                  \n",
      "                                                                 no_mask_3[9][0]                  \n",
      "                                                                 no_mask_3[10][0]                 \n",
      "                                                                 no_mask_3[11][0]                 \n",
      "                                                                 no_mask_3[12][0]                 \n",
      "                                                                 no_mask_3[13][0]                 \n",
      "                                                                 no_mask_3[14][0]                 \n",
      "                                                                 no_mask_3[15][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 352)          0           no_mask_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 16)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "no_mask_4 (NoMask)              multiple             0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 368)          0           no_mask_4[0][0]                  \n",
      "                                                                 no_mask_4[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dnn (DNN)                       (None, 80)           89880       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            80          dnn[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "prediction_layer (PredictionLay (None, 1)            1           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 2,203,762\n",
      "Trainable params: 2,203,522\n",
      "Non-trainable params: 240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 建立模型\n",
    "model = DIN(dnn_feature_columns, behavior_fea)\n",
    "\n",
    "# 查看模型结构\n",
    "model.summary()\n",
    "\n",
    "# 模型编译\n",
    "model.compile('adam', 'binary_crossentropy',metrics=['binary_crossentropy', tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 893372 samples\n",
      "Epoch 1/2\n",
      "   256/893372 [..............................] - ETA: 4:53"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument:  indices[0,0] = 123376 is not in [0, 15310)\n\t [[node model/sparse_seq_emb_hist_click_article_id/embedding_lookup (defined at /home/nekomoon/anaconda3/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]\n\t [[VariableShape_4/_158]]\n  (1) Invalid argument:  indices[0,0] = 123376 is not in [0, 15310)\n\t [[node model/sparse_seq_emb_hist_click_article_id/embedding_lookup (defined at /home/nekomoon/anaconda3/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_5777]\n\nFunction call stack:\ndistributed_function -> distributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-a1ddaec98eb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# 也可以使用上面的语句用自己采样出来的验证集\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# history = model.fit(x_trn, y_trn, verbose=1, epochs=3, validation_split=0.3, batch_size=256)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.0/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  indices[0,0] = 123376 is not in [0, 15310)\n\t [[node model/sparse_seq_emb_hist_click_article_id/embedding_lookup (defined at /home/nekomoon/anaconda3/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]\n\t [[VariableShape_4/_158]]\n  (1) Invalid argument:  indices[0,0] = 123376 is not in [0, 15310)\n\t [[node model/sparse_seq_emb_hist_click_article_id/embedding_lookup (defined at /home/nekomoon/anaconda3/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_5777]\n\nFunction call stack:\ndistributed_function -> distributed_function\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "if offline:\n",
    "    history = model.fit(x_trn, y_trn, verbose=1, epochs=10, validation_data=(x_val, y_val) , batch_size=256)\n",
    "else:\n",
    "    # 也可以使用上面的语句用自己采样出来的验证集\n",
    "    # history = model.fit(x_trn, y_trn, verbose=1, epochs=3, validation_split=0.3, batch_size=256)\n",
    "    history = model.fit(x_trn, y_trn, verbose=1, epochs=2, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这边不知道出什么问题了，还没有解决"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "tst_user_item_feats_df_din_model['pred_score'] = model.predict(x_tst, verbose=1, batch_size=256)\n",
    "tst_user_item_feats_df_din_model[['user_id', 'click_article_id', 'pred_score']].to_csv(save_path + 'din_rank_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "rank_results = tst_user_item_feats_df_din_model[['user_id', 'click_article_id', 'pred_score']]\n",
    "submit(rank_results, topk=5, model_name='din')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 五折交叉验证，这里的五折交叉是以用户为目标进行五折划分\n",
    "#  这一部分与前面的单独训练和验证是分开的\n",
    "def get_kfold_users(trn_df, n=5):\n",
    "    user_ids = trn_df['user_id'].unique()\n",
    "    user_set = [user_ids[i::n] for i in range(n)]\n",
    "    return user_set\n",
    "\n",
    "k_fold = 5\n",
    "trn_df = trn_user_item_feats_df_din_model\n",
    "user_set = get_kfold_users(trn_df, n=k_fold)\n",
    "\n",
    "score_list = []\n",
    "score_df = trn_df[['user_id', 'click_article_id', 'label']]\n",
    "sub_preds = np.zeros(tst_user_item_feats_df_rank_model.shape[0])\n",
    "\n",
    "dense_fea = [x for x in dense_fea if x != 'label']\n",
    "x_tst, dnn_feature_columns = get_din_feats_columns(tst_user_item_feats_df_din_model, dense_fea, \n",
    "                                                   sparse_fea, behavior_fea, hist_behavior_fea, max_len=50)\n",
    "\n",
    "# 五折交叉验证，并将中间结果保存用于staking\n",
    "for n_fold, valid_user in enumerate(user_set):\n",
    "    train_idx = trn_df[~trn_df['user_id'].isin(valid_user)] # add slide user\n",
    "    valid_idx = trn_df[trn_df['user_id'].isin(valid_user)]\n",
    "    \n",
    "    # 准备训练数据\n",
    "    x_trn, dnn_feature_columns = get_din_feats_columns(train_idx, dense_fea, \n",
    "                                                       sparse_fea, behavior_fea, hist_behavior_fea, max_len=50)\n",
    "    y_trn = train_idx['label'].values\n",
    "\n",
    "    # 准备验证数据\n",
    "    x_val, dnn_feature_columns = get_din_feats_columns(valid_idx, dense_fea, \n",
    "                                                   sparse_fea, behavior_fea, hist_behavior_fea, max_len=50)\n",
    "    y_val = valid_idx['label'].values\n",
    "    \n",
    "    history = model.fit(x_trn, y_trn, verbose=1, epochs=2, validation_data=(x_val, y_val) , batch_size=256)\n",
    "    \n",
    "    # 预测验证集结果\n",
    "    valid_idx['pred_score'] = model.predict(x_val, verbose=1, batch_size=256)   \n",
    "    \n",
    "    valid_idx.sort_values(by=['user_id', 'pred_score'])\n",
    "    valid_idx['pred_rank'] = valid_idx.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    \n",
    "    # 将验证集的预测结果放到一个列表中，后面进行拼接\n",
    "    score_list.append(valid_idx[['user_id', 'click_article_id', 'pred_score', 'pred_rank']])\n",
    "    \n",
    "    # 如果是线上测试，需要计算每次交叉验证的结果相加，最后求平均\n",
    "    if not offline:\n",
    "        sub_preds += model.predict(x_tst, verbose=1, batch_size=256)[:, 0]   \n",
    "    \n",
    "score_df_ = pd.concat(score_list, axis=0)\n",
    "score_df = score_df.merge(score_df_, how='left', on=['user_id', 'click_article_id'])\n",
    "# 保存训练集交叉验证产生的新特征\n",
    "score_df[['user_id', 'click_article_id', 'pred_score', 'pred_rank', 'label']].to_csv(save_path + 'trn_din_cls_feats.csv', index=False)\n",
    "    \n",
    "# 测试集的预测结果，多次交叉验证求平均,将预测的score和对应的rank特征保存，可以用于后面的staking，这里还可以构造其他更多的特征\n",
    "tst_user_item_feats_df_din_model['pred_score'] = sub_preds / k_fold\n",
    "tst_user_item_feats_df_din_model['pred_score'] = tst_user_item_feats_df_din_model['pred_score'].transform(lambda x: norm_sim(x))\n",
    "tst_user_item_feats_df_din_model.sort_values(by=['user_id', 'pred_score'])\n",
    "tst_user_item_feats_df_din_model['pred_rank'] = tst_user_item_feats_df_din_model.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "\n",
    "# 保存测试集交叉验证的新特征\n",
    "tst_user_item_feats_df_din_model[['user_id', 'click_article_id', 'pred_score', 'pred_rank']].to_csv(save_path + 'tst_din_cls_feats.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.模型融合\n",
    "\n",
    "#### 2.1.加权融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取多个模型的排序结果文件\n",
    "lgb_ranker = pd.read_csv(save_path + 'lgb_ranker_score.csv')\n",
    "lgb_cls = pd.read_csv(save_path + 'lgb_cls_score.csv')\n",
    "din_ranker = pd.read_csv(save_path + 'din_rank_score.csv')\n",
    "\n",
    "# 这里也可以换成交叉验证输出的测试结果进行加权融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_model = {'lgb_ranker': lgb_ranker, \n",
    "              'lgb_cls': lgb_cls, \n",
    "              'din_ranker': din_ranker}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensumble_predict_topk(rank_model, topk=5):\n",
    "    final_recall = rank_model['lgb_cls'].append(rank_model['din_ranker'])\n",
    "    rank_model['lgb_ranker']['pred_score'] = rank_model['lgb_ranker']['pred_score'].transform(lambda x: norm_sim(x))\n",
    "    \n",
    "    final_recall = final_recall.append(rank_model['lgb_ranker'])\n",
    "    final_recall = final_recall.groupby(['user_id', 'click_article_id'])['pred_score'].sum().reset_index()\n",
    "    \n",
    "    submit(final_recall, topk=topk, model_name='ensemble_fuse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ensumble_predict_topk(rank_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.Stacking融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取多个模型的交叉验证生成的结果文件\n",
    "# 训练集\n",
    "trn_lgb_ranker_feats = pd.read_csv(save_path + 'trn_lgb_ranker_feats.csv')\n",
    "trn_lgb_cls_feats = pd.read_csv(save_path + 'trn_lgb_cls_feats.csv')\n",
    "trn_din_cls_feats = pd.read_csv(save_path + 'trn_din_cls_feats.csv')\n",
    "\n",
    "# 测试集\n",
    "tst_lgb_ranker_feats = pd.read_csv(save_path + 'tst_lgb_ranker_feats.csv')\n",
    "tst_lgb_cls_feats = pd.read_csv(save_path + 'tst_lgb_cls_feats.csv')\n",
    "tst_din_cls_feats = pd.read_csv(save_path + 'tst_din_cls_feats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将多个模型输出的特征进行拼接\n",
    "\n",
    "finall_trn_ranker_feats = trn_lgb_ranker_feats[['user_id', 'click_article_id', 'label']]\n",
    "finall_tst_ranker_feats = tst_lgb_ranker_feats[['user_id', 'click_article_id']]\n",
    "\n",
    "for idx, trn_model in enumerate([trn_lgb_ranker_feats, trn_lgb_cls_feats, trn_din_cls_feats]):\n",
    "    for feat in [ 'pred_score', 'pred_rank']:\n",
    "        col_name = feat + '_' + str(idx)\n",
    "        finall_trn_ranker_feats[col_name] = trn_model[feat]\n",
    "\n",
    "for idx, tst_model in enumerate([tst_lgb_ranker_feats, tst_lgb_cls_feats, tst_din_cls_feats]):\n",
    "    for feat in [ 'pred_score', 'pred_rank']:\n",
    "        col_name = feat + '_' + str(idx)\n",
    "        finall_tst_ranker_feats[col_name] = tst_model[feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个逻辑回归模型再次拟合交叉验证产生的特征对测试集进行预测\n",
    "# 这里需要注意的是，在做交叉验证的时候可以构造多一些与输出预测值相关的特征，来丰富这里简单模型的特征\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "feat_cols = ['pred_score_0', 'pred_rank_0', 'pred_score_1', 'pred_rank_1', 'pred_score_2', 'pred_rank_2']\n",
    "\n",
    "trn_x = finall_trn_ranker_feats[feat_cols]\n",
    "trn_y = finall_trn_ranker_feats['label']\n",
    "\n",
    "tst_x = finall_tst_ranker_feats[feat_cols]\n",
    "\n",
    "# 定义模型\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# 模型训练\n",
    "lr.fit(trn_x, trn_y)\n",
    "\n",
    "# 模型预测\n",
    "finall_tst_ranker_feats['pred_score'] = lr.predict_proba(tst_x)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "rank_results = finall_tst_ranker_feats[['user_id', 'click_article_id', 'pred_score']]\n",
    "submit(rank_results, topk=5, model_name='ensumble_staking')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.0",
   "language": "python",
   "name": "tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
