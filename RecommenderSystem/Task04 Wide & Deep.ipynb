{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task04 Wide&Deep\n",
    "\n",
    "### 1.Wide&Deep模型\n",
    "\n",
    "#### 1.1.原理简介\n",
    "\n",
    "Wide&Deep模型是由单层的Wide部分和多层的Deep部分组成的混合模型：\n",
    "* Wide部分：通过线性模型来处理大量历史的行为特征，使模型具有“记忆能力”。但其通常依赖于更多的特征工程。\n",
    "\n",
    "* Deep部分：通过对稀疏特征的embedding进行学习，模型可以较好地推广到不可见的深度特征组合，让模型具有“泛化能力”。但如果数据过于稀疏，那么神经网络会过度泛化，即过拟合。\n",
    "\n",
    "Wide和Deep优势的结合使模型兼具了逻辑回归和深度神经网络的优点，能够快速处理并记忆大量历史行为特征，并且具有强大的表达能力。\n",
    "\n",
    "**关于记忆能力与泛化能力的理解：**\n",
    "\n",
    "* 记忆能力（memorization）： 模型直接学习并利用（exploiting）历史数据中物品或特征“贡献频率”的能力。\n",
    "\n",
    "* 泛化能力（generalization）： 基于特征传递的相关性，探索（exploring）过去从未或很少发生的新特征组合。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.Wide 部分\n",
    "\n",
    "Wide部分善于处理大量稀疏的id类特征，通常由一个广义线性模型构成：\n",
    "<div align=center><font size=3 width=\"50%\" height=\"50%\">$y=\\mathbf{w}^T\\mathbf{x}+b$</font></div>\n",
    "\n",
    "其中特征$\\mathbf{x}=[x_1,x_2,\\dots,x_n]$由原生输入特征和经过**交叉乘积变换**（cross-product transformation）的组合特征构成。\n",
    "\n",
    "什么是cross-product transformation：\n",
    "\n",
    "<div align=center><font size=3 width=\"50%\" height=\"50%\">$\\phi_k(\\mathbf{x})=\\prod\\limits_{i=1}^d x_i^{c_{ki}}\\quad c_{ki}\\in\\{0,1\\}   $</font></div>\n",
    "\n",
    "$c_{ki}$是一个布尔变量，当第$i$个特征属于第个$k$特征组合时，$c_{ki}$值为1，否则为0。这能捕获两个二元特征之间的交互，并为广义线性模型添加非线性。\n",
    "\n",
    "对于wide部分训练时候使用的优化器是带$L1$正则的FTRL算法(Follow-the-regularized-leader)，而L1 FTLR是非常注重模型稀疏性质的，也就是说W&D模型采用L1 FTRL是想让Wide部分变得更加的稀疏，即Wide部分的大部分参数都为0，这就大大压缩了模型权重及特征向量的维度。Wide部分模型训练完之后留下来的特征都是非常重要的，那么模型的“记忆能力”就可以理解为发现\"直接的\"，“暴力的”，“显然的”关联规则的能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.Deep部分\n",
    "\n",
    "该部分主要是一个Embedding+MLP的神经网络模型。大规模稀疏特征通过embedding转化为低维密集型特征。然后特征进行拼接输入到MLP中，挖掘藏在特征背后的数据模式。数学形式为：\n",
    "\n",
    "<div align=center><font size=3 width=\"50%\" height=\"50%\">$a^{(l+1)}=f(\\mathbf{W}^{(l)}a^{(l)}+b^{(l)})   $</font></div>\n",
    "\n",
    "Deep部分使用的优化器是AdaGrad。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.Joint Training of Wide and Deep Model\n",
    " \n",
    "Wide部分和Deep部分的输出进行加权求和作为最后的输出。模型的最终预测为：\n",
    "\n",
    "<div align=center><font size=3 width=\"50%\" height=\"50%\">$P(Y=1|x) =\\sigma\\left(\\mathbf{w}^T_{wide}[\\mathbf{x}, \\phi(\\mathbf{x})] + \\mathbf{w}^T_{deep} a^{(l_f)}+b \\right) $</font></div>\n",
    "\n",
    "其中$\\sigma(\\cdot)$为sigmoid函数，$\\mathbf{w}^T_{wide}$和$\\mathbf{w}^T_{deep}$分别是Wide部分和Deep部分的权重。\n",
    "\n",
    "（论文中对Wide部分和Deep部分训练使用的优化器是不同的，但对于普通的场景，或者说实验【一些公共数据集上】，在一些复现代码，直接采用了单个优化器，参考[2]。）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 代码实现\n",
    "\n",
    "用tensorflow 2.1实现Wide & Deep 模型，数据集使用sample criteo dataset（Task03中也使用过）。\n",
    "\n",
    "#### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#返回稀疏特征的字典\n",
    "\n",
    "def sparseFeature(feat, feat_num, embed_dim=8):\n",
    "    \"\"\"\n",
    "    create dictionary for sparse feature\n",
    "    :param feat: feature name\n",
    "    :param feat_num: the total number of sparse features that do not repeat\n",
    "    :param embed_dim: embedding dimension\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return {'feat': feat, 'feat_num': feat_num, 'embed_dim': embed_dim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#返回dense特征的字典\n",
    "\n",
    "def denseFeature(feat):\n",
    "    \"\"\"\n",
    "    create dictionary for dense feature\n",
    "    :param feat: dense feature name\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return {'feat': feat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_criteo_dataset(embed_dim=8, test_size=0.2):\n",
    "    \"\"\"\n",
    "    a example about creating criteo dataset\n",
    "    :param embed_dim: the embedding dimension of sparse features\n",
    "    :param test_size: ratio of test dataset\n",
    "    :return: feature columns, train, test\n",
    "    \"\"\"\n",
    "    names = ['label', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10', 'I11',\n",
    "             'I12', 'I13', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11',\n",
    "             'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'C22',\n",
    "             'C23', 'C24', 'C25', 'C26']\n",
    "\n",
    "    data_df = pd.read_table('G:\\Datasets\\dac_sample.tar\\dac_sample.txt', header=None, names=names)\n",
    "    \n",
    "    sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "    dense_features = ['I' + str(i) for i in range(1, 14)]\n",
    "\n",
    "    data_df[sparse_features] = data_df[sparse_features].fillna('-1')\n",
    "    data_df[dense_features] = data_df[dense_features].fillna(0)\n",
    "\n",
    "    for feat in sparse_features:\n",
    "        le = LabelEncoder()\n",
    "        data_df[feat] = le.fit_transform(data_df[feat])\n",
    "\n",
    "    # ==============Feature Engineering===================\n",
    "\n",
    "    # ====================================================\n",
    "    dense_features = [feat for feat in data_df.columns if feat not in sparse_features + ['label']]\n",
    "\n",
    "    mms = MinMaxScaler(feature_range=(0, 1))\n",
    "    data_df[dense_features] = mms.fit_transform(data_df[dense_features])\n",
    "\n",
    "    feature_columns = [[denseFeature(feat) for feat in dense_features]] + \\\n",
    "                      [[sparseFeature(feat, len(data_df[feat].unique()), embed_dim=embed_dim)\n",
    "                        for feat in sparse_features]]\n",
    "\n",
    "    train, test = train_test_split(data_df, test_size=test_size)\n",
    "\n",
    "    train_X = [train[dense_features].values, train[sparse_features].values.astype('int32')]\n",
    "    train_y = train['label'].values.astype('int32')\n",
    "    test_X = [test[dense_features].values, test[sparse_features].values.astype('int32')]\n",
    "    test_y = test['label'].values.astype('int32')\n",
    "\n",
    "    return feature_columns, (train_X, train_y), (test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns, train, test = create_criteo_dataset(embed_dim=8, test_size=0.2)\n",
    "train_X, train_y = train\n",
    "test_X, test_y = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建模型 \n",
    "\n",
    "model: Wide & Deep Learning for Recommender Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Embedding, Concatenate, Dropout, Input, Layer\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Layer):\n",
    "    \"\"\"\n",
    "    Linear Part\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Linear, self).__init__()\n",
    "        self.dense = Dense(1, activation=None)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        result = self.dense(inputs)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(Layer):\n",
    "    \"\"\"\n",
    "    Deep Neural Network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_units, activation='relu', dropout=0.):\n",
    "        \"\"\"\n",
    "        :param hidden_units: A list. Neural network hidden units.\n",
    "        :param activation: A string. Activation function of dnn.\n",
    "        :param dropout: A scalar. Dropout number.\n",
    "        \"\"\"\n",
    "        super(DNN, self).__init__()\n",
    "        self.dnn_network = [Dense(units=unit, activation=activation) for unit in hidden_units]\n",
    "        self.dropout = Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        x = inputs\n",
    "        for dnn in self.dnn_network:\n",
    "            x = dnn(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideDeep(tf.keras.Model):\n",
    "    def __init__(self, feature_columns, hidden_units, activation='relu',\n",
    "                 dnn_dropout=0., embed_reg=1e-4):\n",
    "        \"\"\"\n",
    "        Wide&Deep\n",
    "        :param feature_columns: A list. dense_feature_columns + sparse_feature_columns\n",
    "        :param hidden_units: A list. Neural network hidden units.\n",
    "        :param activation: A string. Activation function of dnn.\n",
    "        :param dnn_dropout: A scalar. Dropout of dnn.\n",
    "        :param embed_reg: A scalar. The regularizer of embedding.\n",
    "        \"\"\"\n",
    "        super(WideDeep, self).__init__()\n",
    "        self.dense_feature_columns, self.sparse_feature_columns = feature_columns\n",
    "        self.embed_layers = {\n",
    "            'embed_' + str(i): Embedding(input_dim=feat['feat_num'],\n",
    "                                         input_length=1,\n",
    "                                         output_dim=feat['embed_dim'],\n",
    "                                         embeddings_initializer='random_uniform',\n",
    "                                         embeddings_regularizer=l2(embed_reg))\n",
    "            for i, feat in enumerate(self.sparse_feature_columns)\n",
    "        }\n",
    "        self.dnn_network = DNN(hidden_units, activation, dnn_dropout)\n",
    "        self.linear = Linear()\n",
    "        self.final_dense = Dense(1, activation=None)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        dense_inputs, sparse_inputs = inputs\n",
    "        sparse_embed = tf.concat([self.embed_layers['embed_{}'.format(i)](sparse_inputs[:, i])\n",
    "                                  for i in range(sparse_inputs.shape[1])], axis=-1)\n",
    "        x = tf.concat([sparse_embed, dense_inputs], axis=-1)\n",
    "\n",
    "        # Wide\n",
    "        wide_out = self.linear(dense_inputs)\n",
    "        # Deep\n",
    "        deep_out = self.dnn_network(x)\n",
    "        deep_out = self.final_dense(deep_out)\n",
    "        # out\n",
    "        outputs = tf.nn.sigmoid(0.5 * (wide_out + deep_out))\n",
    "        return outputs\n",
    "\n",
    "    def summary(self, **kwargs):\n",
    "        dense_inputs = Input(shape=(len(self.dense_feature_columns),), dtype=tf.float32)\n",
    "        sparse_inputs = Input(shape=(len(self.sparse_feature_columns),), dtype=tf.int32)\n",
    "        keras.Model(inputs=[dense_inputs, sparse_inputs],\n",
    "                    outputs=self.call([dense_inputs, sparse_inputs])).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideDeep(feature_columns, hidden_units=[256, 128, 64], dnn_dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 26)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_7 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_8 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_9 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_10 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_11 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_12 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_13 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_14 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_15 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_16 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_17 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_18 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_19 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_20 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_21 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_22 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_23 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_24 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_25 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 8)            4328        tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 8)            3976        tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 8)            350960      tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 8)            201472      tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 8)            1160        tf_op_layer_strided_slice_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 8)            96          tf_op_layer_strided_slice_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 8)            60984       tf_op_layer_strided_slice_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 8)            2056        tf_op_layer_strided_slice_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 8)            24          tf_op_layer_strided_slice_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 8)            87976       tf_op_layer_strided_slice_9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 8)            30392       tf_op_layer_strided_slice_10[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 8)            330496      tf_op_layer_strided_slice_11[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 8)            22368       tf_op_layer_strided_slice_12[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 8)            208         tf_op_layer_strided_slice_13[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 8)            41904       tf_op_layer_strided_slice_14[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 8)            276936      tf_op_layer_strided_slice_15[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_16 (Embedding)        (None, 8)            80          tf_op_layer_strided_slice_16[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 8)            20384       tf_op_layer_strided_slice_17[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 8)            10424       tf_op_layer_strided_slice_18[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 8)            32          tf_op_layer_strided_slice_19[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 8)            308944      tf_op_layer_strided_slice_20[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 8)            88          tf_op_layer_strided_slice_21[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)        (None, 8)            112         tf_op_layer_strided_slice_22[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 8)            98680       tf_op_layer_strided_slice_23[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)        (None, 8)            408         tf_op_layer_strided_slice_24[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_25 (Embedding)        (None, 8)            76216       tf_op_layer_strided_slice_25[0][0\n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 13)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(None, 208)]        0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "                                                                 embedding_3[0][0]                \n",
      "                                                                 embedding_4[0][0]                \n",
      "                                                                 embedding_5[0][0]                \n",
      "                                                                 embedding_6[0][0]                \n",
      "                                                                 embedding_7[0][0]                \n",
      "                                                                 embedding_8[0][0]                \n",
      "                                                                 embedding_9[0][0]                \n",
      "                                                                 embedding_10[0][0]               \n",
      "                                                                 embedding_11[0][0]               \n",
      "                                                                 embedding_12[0][0]               \n",
      "                                                                 embedding_13[0][0]               \n",
      "                                                                 embedding_14[0][0]               \n",
      "                                                                 embedding_15[0][0]               \n",
      "                                                                 embedding_16[0][0]               \n",
      "                                                                 embedding_17[0][0]               \n",
      "                                                                 embedding_18[0][0]               \n",
      "                                                                 embedding_19[0][0]               \n",
      "                                                                 embedding_20[0][0]               \n",
      "                                                                 embedding_21[0][0]               \n",
      "                                                                 embedding_22[0][0]               \n",
      "                                                                 embedding_23[0][0]               \n",
      "                                                                 embedding_24[0][0]               \n",
      "                                                                 embedding_25[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_1 (TensorFlo [(None, 221)]        0           tf_op_layer_concat[0][0]         \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dnn (DNN)                       (None, 64)           97984       tf_op_layer_concat_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "linear (Linear)                 (None, 1)            14          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            65          dnn[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add (TensorFlowOpLa [(None, 1)]          0           linear[0][0]                     \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul (TensorFlowOpLa [(None, 1)]          0           tf_op_layer_add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sigmoid (TensorFlow [(None, 1)]          0           tf_op_layer_mul[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 2,028,767\n",
      "Trainable params: 2,028,767\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=binary_crossentropy, \n",
    "              optimizer=Adam(learning_rate=0.001),\n",
    "              metrics=[AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Application\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72000/72000 [==============================] - 6s 83us/sample - loss: 0.5338 - auc: 0.6724 - val_loss: 0.4702 - val_auc: 0.7541\n",
      "Epoch 2/5\n",
      "72000/72000 [==============================] - 3s 36us/sample - loss: 0.4285 - auc: 0.8250 - val_loss: 0.4926 - val_auc: 0.7544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e7769fafc8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "        train_X,\n",
    "        train_y,\n",
    "        epochs=5,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True)],  # checkpoint\n",
    "        batch_size=512,\n",
    "        validation_split=0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 6s 315us/sample - loss: 0.4765 - auc: 0.7478\n",
      "test AUC: 0.747843\n"
     ]
    }
   ],
   "source": [
    "print('test AUC: %f' % model.evaluate(test_X, test_y)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************************************\n",
    "\n",
    "参考资料：\n",
    "\n",
    "[1] 王喆-《深度学习推荐系统》\n",
    "\n",
    "[2] [【论文导读】Wide&Deep模型的深入理解](https://mp.weixin.qq.com/s/LRghf8mj1hjUYri_m3AzBg)\n",
    "\n",
    "[3] [见微知著，你真的搞懂Google的Wide&Deep模型了吗？](https://zhuanlan.zhihu.com/p/142958834)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2]",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
